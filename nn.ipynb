{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with optimizer: SGD\n",
      "Epoch 1, Train Loss: 754.5484008789062, Test Loss: 27141.7890625, Accuracy: 0.7656\n",
      "Epoch 2, Train Loss: 29574.125, Test Loss: 26330132.0, Accuracy: 0.2344\n",
      "Epoch 3, Train Loss: 25857896.0, Test Loss: 111624.4375, Accuracy: 0.7656\n",
      "Epoch 4, Train Loss: 114204.09375, Test Loss: 324880640.0, Accuracy: 0.2344\n",
      "Epoch 5, Train Loss: 324413248.0, Test Loss: 982643621494784.0, Accuracy: 0.7656\n",
      "Epoch 6, Train Loss: 1013837700530176.0, Test Loss: 125887.078125, Accuracy: 0.2344\n",
      "Epoch 7, Train Loss: 124373.8203125, Test Loss: 24728.712890625, Accuracy: 0.7656\n",
      "Epoch 8, Train Loss: 25348.375, Test Loss: 16537.44140625, Accuracy: 0.7656\n",
      "Epoch 9, Train Loss: 16884.15234375, Test Loss: 8378.89453125, Accuracy: 0.7656\n",
      "Epoch 10, Train Loss: 8613.9111328125, Test Loss: 163.7344970703125, Accuracy: 0.7656\n",
      "Epoch 11, Train Loss: 167.9480438232422, Test Loss: 0.6720032095909119, Accuracy: 0.7656\n",
      "Epoch 12, Train Loss: 0.6725071668624878, Test Loss: 0.6718862652778625, Accuracy: 0.7656\n",
      "Epoch 13, Train Loss: 0.6723932027816772, Test Loss: 0.6717694401741028, Accuracy: 0.7656\n",
      "Epoch 14, Train Loss: 0.6722792983055115, Test Loss: 0.6716526746749878, Accuracy: 0.7656\n",
      "Epoch 15, Train Loss: 0.6721653342247009, Test Loss: 0.6715362668037415, Accuracy: 0.7656\n",
      "Epoch 16, Train Loss: 0.6720518469810486, Test Loss: 0.6714197397232056, Accuracy: 0.7656\n",
      "Epoch 17, Train Loss: 0.6719383001327515, Test Loss: 0.671303391456604, Accuracy: 0.7656\n",
      "Epoch 18, Train Loss: 0.6718246936798096, Test Loss: 0.6711870431900024, Accuracy: 0.7656\n",
      "Epoch 19, Train Loss: 0.671711266040802, Test Loss: 0.6710709929466248, Accuracy: 0.7656\n",
      "Epoch 20, Train Loss: 0.6715981960296631, Test Loss: 0.6709549427032471, Accuracy: 0.7656\n",
      "Epoch 21, Train Loss: 0.6714849472045898, Test Loss: 0.6708390712738037, Accuracy: 0.7656\n",
      "Epoch 22, Train Loss: 0.6713720560073853, Test Loss: 0.6707233190536499, Accuracy: 0.7656\n",
      "Epoch 23, Train Loss: 0.6712592840194702, Test Loss: 0.6706078052520752, Accuracy: 0.7656\n",
      "Epoch 24, Train Loss: 0.6711465120315552, Test Loss: 0.6704921126365662, Accuracy: 0.7656\n",
      "Epoch 25, Train Loss: 0.6710337996482849, Test Loss: 0.670376718044281, Accuracy: 0.7656\n",
      "Epoch 26, Train Loss: 0.6709212064743042, Test Loss: 0.6702612042427063, Accuracy: 0.7656\n",
      "Epoch 27, Train Loss: 0.670808732509613, Test Loss: 0.6701460480690002, Accuracy: 0.7656\n",
      "Epoch 28, Train Loss: 0.6706963777542114, Test Loss: 0.6700310707092285, Accuracy: 0.7656\n",
      "Epoch 29, Train Loss: 0.6705842018127441, Test Loss: 0.6699160933494568, Accuracy: 0.7656\n",
      "Epoch 30, Train Loss: 0.6704720854759216, Test Loss: 0.6698011159896851, Accuracy: 0.7656\n",
      "Epoch 31, Train Loss: 0.6703600287437439, Test Loss: 0.6696863770484924, Accuracy: 0.7656\n",
      "Epoch 32, Train Loss: 0.67024827003479, Test Loss: 0.6695716977119446, Accuracy: 0.7656\n",
      "Epoch 33, Train Loss: 0.6701363921165466, Test Loss: 0.6694572567939758, Accuracy: 0.7656\n",
      "Epoch 34, Train Loss: 0.6700248718261719, Test Loss: 0.6693427562713623, Accuracy: 0.7656\n",
      "Epoch 35, Train Loss: 0.6699131727218628, Test Loss: 0.6692284941673279, Accuracy: 0.7656\n",
      "Epoch 36, Train Loss: 0.6698018312454224, Test Loss: 0.6691142320632935, Accuracy: 0.7656\n",
      "Epoch 37, Train Loss: 0.6696904301643372, Test Loss: 0.6690000891685486, Accuracy: 0.7656\n",
      "Epoch 38, Train Loss: 0.6695791482925415, Test Loss: 0.6688862442970276, Accuracy: 0.7656\n",
      "Epoch 39, Train Loss: 0.6694681644439697, Test Loss: 0.6687723398208618, Accuracy: 0.7656\n",
      "Epoch 40, Train Loss: 0.6693570613861084, Test Loss: 0.6686585545539856, Accuracy: 0.7656\n",
      "Epoch 41, Train Loss: 0.6692463159561157, Test Loss: 0.6685448884963989, Accuracy: 0.7656\n",
      "Epoch 42, Train Loss: 0.6691355109214783, Test Loss: 0.668431282043457, Accuracy: 0.7656\n",
      "Epoch 43, Train Loss: 0.6690247654914856, Test Loss: 0.6683180928230286, Accuracy: 0.7656\n",
      "Epoch 44, Train Loss: 0.6689143180847168, Test Loss: 0.6682047247886658, Accuracy: 0.7656\n",
      "Epoch 45, Train Loss: 0.6688037514686584, Test Loss: 0.6680914759635925, Accuracy: 0.7656\n",
      "Epoch 46, Train Loss: 0.6686934232711792, Test Loss: 0.6679782867431641, Accuracy: 0.7656\n",
      "Epoch 47, Train Loss: 0.6685832142829895, Test Loss: 0.6678653955459595, Accuracy: 0.7656\n",
      "Epoch 48, Train Loss: 0.6684730648994446, Test Loss: 0.6677526831626892, Accuracy: 0.7656\n",
      "Epoch 49, Train Loss: 0.6683632731437683, Test Loss: 0.6676398515701294, Accuracy: 0.7656\n",
      "Epoch 50, Train Loss: 0.6682533025741577, Test Loss: 0.6675271987915039, Accuracy: 0.7656\n",
      "Epoch 51, Train Loss: 0.6681434512138367, Test Loss: 0.667414665222168, Accuracy: 0.7656\n",
      "Epoch 52, Train Loss: 0.6680338382720947, Test Loss: 0.6673023700714111, Accuracy: 0.7656\n",
      "Epoch 53, Train Loss: 0.6679242253303528, Test Loss: 0.66718989610672, Accuracy: 0.7656\n",
      "Epoch 54, Train Loss: 0.6678146719932556, Test Loss: 0.6670779585838318, Accuracy: 0.7656\n",
      "Epoch 55, Train Loss: 0.6677054762840271, Test Loss: 0.6669657230377197, Accuracy: 0.7656\n",
      "Epoch 56, Train Loss: 0.6675961017608643, Test Loss: 0.6668539047241211, Accuracy: 0.7656\n",
      "Epoch 57, Train Loss: 0.6674872040748596, Test Loss: 0.6667419672012329, Accuracy: 0.7656\n",
      "Epoch 58, Train Loss: 0.6673780679702759, Test Loss: 0.666630208492279, Accuracy: 0.7656\n",
      "Epoch 59, Train Loss: 0.6672691702842712, Test Loss: 0.6665183901786804, Accuracy: 0.7656\n",
      "Epoch 60, Train Loss: 0.6671602725982666, Test Loss: 0.6664071083068848, Accuracy: 0.7656\n",
      "Epoch 61, Train Loss: 0.6670517325401306, Test Loss: 0.6662954688072205, Accuracy: 0.7656\n",
      "Epoch 62, Train Loss: 0.6669430136680603, Test Loss: 0.6661842465400696, Accuracy: 0.7656\n",
      "Epoch 63, Train Loss: 0.6668345928192139, Test Loss: 0.6660730838775635, Accuracy: 0.7656\n",
      "Epoch 64, Train Loss: 0.6667262315750122, Test Loss: 0.6659619212150574, Accuracy: 0.7656\n",
      "Epoch 65, Train Loss: 0.6666179299354553, Test Loss: 0.6658509969711304, Accuracy: 0.7656\n",
      "Epoch 66, Train Loss: 0.6665098667144775, Test Loss: 0.6657401919364929, Accuracy: 0.7656\n",
      "Epoch 67, Train Loss: 0.6664018630981445, Test Loss: 0.665629506111145, Accuracy: 0.7656\n",
      "Epoch 68, Train Loss: 0.6662939786911011, Test Loss: 0.6655187606811523, Accuracy: 0.7656\n",
      "Epoch 69, Train Loss: 0.6661860942840576, Test Loss: 0.6654080152511597, Accuracy: 0.7656\n",
      "Epoch 70, Train Loss: 0.6660781502723694, Test Loss: 0.6652976870536804, Accuracy: 0.7656\n",
      "Epoch 71, Train Loss: 0.6659706830978394, Test Loss: 0.6651875376701355, Accuracy: 0.7656\n",
      "Epoch 72, Train Loss: 0.6658632755279541, Test Loss: 0.665077269077301, Accuracy: 0.7656\n",
      "Epoch 73, Train Loss: 0.6657556891441345, Test Loss: 0.6649670600891113, Accuracy: 0.7656\n",
      "Epoch 74, Train Loss: 0.6656485199928284, Test Loss: 0.6648571491241455, Accuracy: 0.7656\n",
      "Epoch 75, Train Loss: 0.665541410446167, Test Loss: 0.6647472381591797, Accuracy: 0.7656\n",
      "Epoch 76, Train Loss: 0.6654343605041504, Test Loss: 0.6646374464035034, Accuracy: 0.7656\n",
      "Epoch 77, Train Loss: 0.6653273105621338, Test Loss: 0.6645278334617615, Accuracy: 0.7656\n",
      "Epoch 78, Train Loss: 0.6652204990386963, Test Loss: 0.6644182205200195, Accuracy: 0.7656\n",
      "Epoch 79, Train Loss: 0.665113627910614, Test Loss: 0.6643086671829224, Accuracy: 0.7656\n",
      "Epoch 80, Train Loss: 0.6650068759918213, Test Loss: 0.6641994118690491, Accuracy: 0.7656\n",
      "Epoch 81, Train Loss: 0.6649004817008972, Test Loss: 0.664090096950531, Accuracy: 0.7656\n",
      "Epoch 82, Train Loss: 0.6647940278053284, Test Loss: 0.6639809012413025, Accuracy: 0.7656\n",
      "Epoch 83, Train Loss: 0.6646876931190491, Test Loss: 0.6638720035552979, Accuracy: 0.7656\n",
      "Epoch 84, Train Loss: 0.6645815372467041, Test Loss: 0.6637629270553589, Accuracy: 0.7656\n",
      "Epoch 85, Train Loss: 0.6644752621650696, Test Loss: 0.6636542081832886, Accuracy: 0.7656\n",
      "Epoch 86, Train Loss: 0.6643692851066589, Test Loss: 0.6635454893112183, Accuracy: 0.7656\n",
      "Epoch 87, Train Loss: 0.6642633676528931, Test Loss: 0.6634368896484375, Accuracy: 0.7656\n",
      "Epoch 88, Train Loss: 0.6641576290130615, Test Loss: 0.6633282899856567, Accuracy: 0.7656\n",
      "Epoch 89, Train Loss: 0.6640518307685852, Test Loss: 0.6632200479507446, Accuracy: 0.7656\n",
      "Epoch 90, Train Loss: 0.6639463901519775, Test Loss: 0.663111686706543, Accuracy: 0.7656\n",
      "Epoch 91, Train Loss: 0.6638407707214355, Test Loss: 0.6630035042762756, Accuracy: 0.7656\n",
      "Epoch 92, Train Loss: 0.6637353897094727, Test Loss: 0.6628953814506531, Accuracy: 0.7656\n",
      "Epoch 93, Train Loss: 0.6636301279067993, Test Loss: 0.6627875566482544, Accuracy: 0.7656\n",
      "Epoch 94, Train Loss: 0.6635251045227051, Test Loss: 0.6626797318458557, Accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95, Train Loss: 0.6634199023246765, Test Loss: 0.6625717878341675, Accuracy: 0.7656\n",
      "Epoch 96, Train Loss: 0.663314938545227, Test Loss: 0.6624642610549927, Accuracy: 0.7656\n",
      "Epoch 97, Train Loss: 0.6632100939750671, Test Loss: 0.6623567342758179, Accuracy: 0.7656\n",
      "Epoch 98, Train Loss: 0.6631053686141968, Test Loss: 0.6622491478919983, Accuracy: 0.7656\n",
      "Epoch 99, Train Loss: 0.6630005836486816, Test Loss: 0.6621420979499817, Accuracy: 0.7656\n",
      "Epoch 100, Train Loss: 0.6628962755203247, Test Loss: 0.662034809589386, Accuracy: 0.7656\n",
      "Epoch 101, Train Loss: 0.6627916693687439, Test Loss: 0.6619276404380798, Accuracy: 0.7656\n",
      "Epoch 102, Train Loss: 0.662687361240387, Test Loss: 0.661820650100708, Accuracy: 0.7656\n",
      "Epoch 103, Train Loss: 0.6625832319259644, Test Loss: 0.6617136597633362, Accuracy: 0.7656\n",
      "Epoch 104, Train Loss: 0.6624789834022522, Test Loss: 0.6616067886352539, Accuracy: 0.7656\n",
      "Epoch 105, Train Loss: 0.6623749136924744, Test Loss: 0.6615001559257507, Accuracy: 0.7656\n",
      "Epoch 106, Train Loss: 0.6622711420059204, Test Loss: 0.6613937020301819, Accuracy: 0.7656\n",
      "Epoch 107, Train Loss: 0.6621673107147217, Test Loss: 0.6612871885299683, Accuracy: 0.7656\n",
      "Epoch 108, Train Loss: 0.662063479423523, Test Loss: 0.6611806750297546, Accuracy: 0.7656\n",
      "Epoch 109, Train Loss: 0.6619598269462585, Test Loss: 0.6610744595527649, Accuracy: 0.7656\n",
      "Epoch 110, Train Loss: 0.6618564128875732, Test Loss: 0.6609682440757751, Accuracy: 0.7656\n",
      "Epoch 111, Train Loss: 0.6617528796195984, Test Loss: 0.6608620882034302, Accuracy: 0.7656\n",
      "Epoch 112, Train Loss: 0.6616496443748474, Test Loss: 0.6607562899589539, Accuracy: 0.7656\n",
      "Epoch 113, Train Loss: 0.661546528339386, Test Loss: 0.660650372505188, Accuracy: 0.7656\n",
      "Epoch 114, Train Loss: 0.6614434719085693, Test Loss: 0.6605445146560669, Accuracy: 0.7656\n",
      "Epoch 115, Train Loss: 0.6613403558731079, Test Loss: 0.6604389548301697, Accuracy: 0.7656\n",
      "Epoch 116, Train Loss: 0.6612374782562256, Test Loss: 0.6603332757949829, Accuracy: 0.7656\n",
      "Epoch 117, Train Loss: 0.661134660243988, Test Loss: 0.6602280735969543, Accuracy: 0.7656\n",
      "Epoch 118, Train Loss: 0.6610321402549744, Test Loss: 0.6601226329803467, Accuracy: 0.7656\n",
      "Epoch 119, Train Loss: 0.6609293818473816, Test Loss: 0.6600173115730286, Accuracy: 0.7656\n",
      "Epoch 120, Train Loss: 0.6608268618583679, Test Loss: 0.6599122881889343, Accuracy: 0.7656\n",
      "Epoch 121, Train Loss: 0.6607245802879333, Test Loss: 0.6598071455955505, Accuracy: 0.7656\n",
      "Epoch 122, Train Loss: 0.660622239112854, Test Loss: 0.6597023606300354, Accuracy: 0.7656\n",
      "Epoch 123, Train Loss: 0.660520076751709, Test Loss: 0.6595973372459412, Accuracy: 0.7656\n",
      "Epoch 124, Train Loss: 0.6604178547859192, Test Loss: 0.6594926714897156, Accuracy: 0.7656\n",
      "Epoch 125, Train Loss: 0.6603159308433533, Test Loss: 0.6593881249427795, Accuracy: 0.7656\n",
      "Epoch 126, Train Loss: 0.6602142453193665, Test Loss: 0.6592835783958435, Accuracy: 0.7656\n",
      "Epoch 127, Train Loss: 0.6601123213768005, Test Loss: 0.6591792106628418, Accuracy: 0.7656\n",
      "Epoch 128, Train Loss: 0.6600107550621033, Test Loss: 0.6590749025344849, Accuracy: 0.7656\n",
      "Epoch 129, Train Loss: 0.659909188747406, Test Loss: 0.6589707136154175, Accuracy: 0.7656\n",
      "Epoch 130, Train Loss: 0.6598078608512878, Test Loss: 0.6588665246963501, Accuracy: 0.7656\n",
      "Epoch 131, Train Loss: 0.6597062945365906, Test Loss: 0.6587624549865723, Accuracy: 0.7656\n",
      "Epoch 132, Train Loss: 0.6596050262451172, Test Loss: 0.6586586833000183, Accuracy: 0.7656\n",
      "Epoch 133, Train Loss: 0.6595038175582886, Test Loss: 0.6585548520088196, Accuracy: 0.7656\n",
      "Epoch 134, Train Loss: 0.6594027876853943, Test Loss: 0.6584510803222656, Accuracy: 0.7656\n",
      "Epoch 135, Train Loss: 0.6593017578125, Test Loss: 0.6583475470542908, Accuracy: 0.7656\n",
      "Epoch 136, Train Loss: 0.6592009663581848, Test Loss: 0.6582439541816711, Accuracy: 0.7656\n",
      "Epoch 137, Train Loss: 0.6591001152992249, Test Loss: 0.6581407189369202, Accuracy: 0.7656\n",
      "Epoch 138, Train Loss: 0.6589996218681335, Test Loss: 0.6580373644828796, Accuracy: 0.7656\n",
      "Epoch 139, Train Loss: 0.6588990092277527, Test Loss: 0.6579342484474182, Accuracy: 0.7656\n",
      "Epoch 140, Train Loss: 0.6587986946105957, Test Loss: 0.6578310132026672, Accuracy: 0.7656\n",
      "Epoch 141, Train Loss: 0.6586981415748596, Test Loss: 0.6577279567718506, Accuracy: 0.7656\n",
      "Epoch 142, Train Loss: 0.6585978269577026, Test Loss: 0.6576251983642578, Accuracy: 0.7656\n",
      "Epoch 143, Train Loss: 0.6584976315498352, Test Loss: 0.6575224995613098, Accuracy: 0.7656\n",
      "Epoch 144, Train Loss: 0.6583976745605469, Test Loss: 0.6574196815490723, Accuracy: 0.7656\n",
      "Epoch 145, Train Loss: 0.6582977771759033, Test Loss: 0.6573171615600586, Accuracy: 0.7656\n",
      "Epoch 146, Train Loss: 0.6581978797912598, Test Loss: 0.6572145819664001, Accuracy: 0.7656\n",
      "Epoch 147, Train Loss: 0.6580979228019714, Test Loss: 0.6571122407913208, Accuracy: 0.7656\n",
      "Epoch 148, Train Loss: 0.6579983234405518, Test Loss: 0.6570098996162415, Accuracy: 0.7656\n",
      "Epoch 149, Train Loss: 0.6578987836837769, Test Loss: 0.6569077968597412, Accuracy: 0.7656\n",
      "Epoch 150, Train Loss: 0.6577993035316467, Test Loss: 0.6568057537078857, Accuracy: 0.7656\n",
      "Epoch 151, Train Loss: 0.6577001214027405, Test Loss: 0.656703770160675, Accuracy: 0.7656\n",
      "Epoch 152, Train Loss: 0.6576008200645447, Test Loss: 0.6566019058227539, Accuracy: 0.7656\n",
      "Epoch 153, Train Loss: 0.6575016379356384, Test Loss: 0.6565001606941223, Accuracy: 0.7656\n",
      "Epoch 154, Train Loss: 0.6574026346206665, Test Loss: 0.6563984751701355, Accuracy: 0.7656\n",
      "Epoch 155, Train Loss: 0.6573035717010498, Test Loss: 0.6562967896461487, Accuracy: 0.7656\n",
      "Epoch 156, Train Loss: 0.6572046875953674, Test Loss: 0.6561952829360962, Accuracy: 0.7656\n",
      "Epoch 157, Train Loss: 0.6571058034896851, Test Loss: 0.6560940742492676, Accuracy: 0.7656\n",
      "Epoch 158, Train Loss: 0.6570072770118713, Test Loss: 0.6559926271438599, Accuracy: 0.7656\n",
      "Epoch 159, Train Loss: 0.6569085717201233, Test Loss: 0.6558913588523865, Accuracy: 0.7656\n",
      "Epoch 160, Train Loss: 0.6568100452423096, Test Loss: 0.655790388584137, Accuracy: 0.7656\n",
      "Epoch 161, Train Loss: 0.656711757183075, Test Loss: 0.6556894183158875, Accuracy: 0.7656\n",
      "Epoch 162, Train Loss: 0.6566134095191956, Test Loss: 0.655588686466217, Accuracy: 0.7656\n",
      "Epoch 163, Train Loss: 0.6565153002738953, Test Loss: 0.6554877161979675, Accuracy: 0.7656\n",
      "Epoch 164, Train Loss: 0.6564171314239502, Test Loss: 0.6553871631622314, Accuracy: 0.7656\n",
      "Epoch 165, Train Loss: 0.6563191413879395, Test Loss: 0.6552865505218506, Accuracy: 0.7656\n",
      "Epoch 166, Train Loss: 0.6562212705612183, Test Loss: 0.655185878276825, Accuracy: 0.7656\n",
      "Epoch 167, Train Loss: 0.6561233401298523, Test Loss: 0.6550853848457336, Accuracy: 0.7656\n",
      "Epoch 168, Train Loss: 0.6560255885124207, Test Loss: 0.654985249042511, Accuracy: 0.7656\n",
      "Epoch 169, Train Loss: 0.6559281349182129, Test Loss: 0.6548852324485779, Accuracy: 0.7656\n",
      "Epoch 170, Train Loss: 0.6558306813240051, Test Loss: 0.6547849178314209, Accuracy: 0.7656\n",
      "Epoch 171, Train Loss: 0.6557331681251526, Test Loss: 0.6546850204467773, Accuracy: 0.7656\n",
      "Epoch 172, Train Loss: 0.6556358337402344, Test Loss: 0.6545851230621338, Accuracy: 0.7656\n",
      "Epoch 173, Train Loss: 0.6555386781692505, Test Loss: 0.654485285282135, Accuracy: 0.7656\n",
      "Epoch 174, Train Loss: 0.6554415822029114, Test Loss: 0.654385507106781, Accuracy: 0.7656\n",
      "Epoch 175, Train Loss: 0.6553444266319275, Test Loss: 0.6542859077453613, Accuracy: 0.7656\n",
      "Epoch 176, Train Loss: 0.6552475094795227, Test Loss: 0.654186487197876, Accuracy: 0.7656\n",
      "Epoch 177, Train Loss: 0.6551507711410522, Test Loss: 0.6540868878364563, Accuracy: 0.7656\n",
      "Epoch 178, Train Loss: 0.6550538539886475, Test Loss: 0.65398770570755, Accuracy: 0.7656\n",
      "Epoch 179, Train Loss: 0.6549573540687561, Test Loss: 0.6538883447647095, Accuracy: 0.7656\n",
      "Epoch 180, Train Loss: 0.6548607349395752, Test Loss: 0.6537894010543823, Accuracy: 0.7656\n",
      "Epoch 181, Train Loss: 0.6547644138336182, Test Loss: 0.6536903977394104, Accuracy: 0.7656\n",
      "Epoch 182, Train Loss: 0.6546680927276611, Test Loss: 0.6535914540290833, Accuracy: 0.7656\n",
      "Epoch 183, Train Loss: 0.6545718312263489, Test Loss: 0.6534926891326904, Accuracy: 0.7656\n",
      "Epoch 184, Train Loss: 0.6544756293296814, Test Loss: 0.6533938050270081, Accuracy: 0.7656\n",
      "Epoch 185, Train Loss: 0.6543794274330139, Test Loss: 0.6532952189445496, Accuracy: 0.7656\n",
      "Epoch 186, Train Loss: 0.6542835235595703, Test Loss: 0.6531967520713806, Accuracy: 0.7656\n",
      "Epoch 187, Train Loss: 0.6541876792907715, Test Loss: 0.6530982255935669, Accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188, Train Loss: 0.6540919542312622, Test Loss: 0.6529999375343323, Accuracy: 0.7656\n",
      "Epoch 189, Train Loss: 0.6539962887763977, Test Loss: 0.6529015302658081, Accuracy: 0.7656\n",
      "Epoch 190, Train Loss: 0.6539006233215332, Test Loss: 0.6528035402297974, Accuracy: 0.7656\n",
      "Epoch 191, Train Loss: 0.6538052558898926, Test Loss: 0.6527054905891418, Accuracy: 0.7656\n",
      "Epoch 192, Train Loss: 0.6537097692489624, Test Loss: 0.6526073813438416, Accuracy: 0.7656\n",
      "Epoch 193, Train Loss: 0.6536142826080322, Test Loss: 0.6525096893310547, Accuracy: 0.7656\n",
      "Epoch 194, Train Loss: 0.6535192728042603, Test Loss: 0.652411937713623, Accuracy: 0.7656\n",
      "Epoch 195, Train Loss: 0.6534242033958435, Test Loss: 0.6523140668869019, Accuracy: 0.7656\n",
      "Epoch 196, Train Loss: 0.6533290147781372, Test Loss: 0.6522165536880493, Accuracy: 0.7656\n",
      "Epoch 197, Train Loss: 0.6532341837882996, Test Loss: 0.6521191000938416, Accuracy: 0.7656\n",
      "Epoch 198, Train Loss: 0.6531394124031067, Test Loss: 0.6520217061042786, Accuracy: 0.7656\n",
      "Epoch 199, Train Loss: 0.653044581413269, Test Loss: 0.6519243121147156, Accuracy: 0.7656\n",
      "Epoch 200, Train Loss: 0.652949869632721, Test Loss: 0.6518271565437317, Accuracy: 0.7656\n",
      "Optimizer: SGD\n",
      "Final Test Accuracy: 0.7656\n",
      "Training Time: 10.61 seconds\n",
      "Final Train Loss: 0.6529\n",
      "Final Test Loss: 0.6518\n",
      "\n",
      "Training with optimizer: SGD + Momentum\n",
      "Epoch 1, Train Loss: 1057.0743408203125, Test Loss: 10362765312.0, Accuracy: 0.7656\n",
      "Epoch 2, Train Loss: 10706152448.0, Test Loss: 7662798848.0, Accuracy: 0.7656\n",
      "Epoch 3, Train Loss: 7881062912.0, Test Loss: 6.310486898727348e+19, Accuracy: 0.2344\n",
      "Epoch 4, Train Loss: 6.2631665570957754e+19, Test Loss: 805167300608.0, Accuracy: 0.7656\n",
      "Epoch 5, Train Loss: 828830449664.0, Test Loss: 0.7341709136962891, Accuracy: 0.2344\n",
      "Epoch 6, Train Loss: 0.7332910299301147, Test Loss: 0.7298967242240906, Accuracy: 0.2344\n",
      "Epoch 7, Train Loss: 0.7291035056114197, Test Loss: 0.7243744730949402, Accuracy: 0.2344\n",
      "Epoch 8, Train Loss: 0.723694920539856, Test Loss: 0.7178202867507935, Accuracy: 0.2344\n",
      "Epoch 9, Train Loss: 0.717278003692627, Test Loss: 0.7104400992393494, Accuracy: 0.2344\n",
      "Epoch 10, Train Loss: 0.710055410861969, Test Loss: 0.7024281024932861, Accuracy: 0.2344\n",
      "Epoch 11, Train Loss: 0.7022188901901245, Test Loss: 0.6939631104469299, Accuracy: 0.2344\n",
      "Epoch 12, Train Loss: 0.69394451379776, Test Loss: 0.6852083206176758, Accuracy: 0.7656\n",
      "Epoch 13, Train Loss: 0.6853926777839661, Test Loss: 0.6763079166412354, Accuracy: 0.7656\n",
      "Epoch 14, Train Loss: 0.6767058372497559, Test Loss: 0.6673899292945862, Accuracy: 0.7656\n",
      "Epoch 15, Train Loss: 0.6680097579956055, Test Loss: 0.6585637331008911, Accuracy: 0.7656\n",
      "Epoch 16, Train Loss: 0.6594114899635315, Test Loss: 0.6499220132827759, Accuracy: 0.7656\n",
      "Epoch 17, Train Loss: 0.6510022878646851, Test Loss: 0.6415407061576843, Accuracy: 0.7656\n",
      "Epoch 18, Train Loss: 0.6428565382957458, Test Loss: 0.6334806680679321, Accuracy: 0.7656\n",
      "Epoch 19, Train Loss: 0.635033369064331, Test Loss: 0.6257891058921814, Accuracy: 0.7656\n",
      "Epoch 20, Train Loss: 0.6275790333747864, Test Loss: 0.6185000538825989, Accuracy: 0.7656\n",
      "Epoch 21, Train Loss: 0.6205260753631592, Test Loss: 0.611636221408844, Accuracy: 0.7656\n",
      "Epoch 22, Train Loss: 0.6138962507247925, Test Loss: 0.6052111983299255, Accuracy: 0.7656\n",
      "Epoch 23, Train Loss: 0.6077022552490234, Test Loss: 0.599229633808136, Accuracy: 0.7656\n",
      "Epoch 24, Train Loss: 0.6019478440284729, Test Loss: 0.5936889052391052, Accuracy: 0.7656\n",
      "Epoch 25, Train Loss: 0.5966299772262573, Test Loss: 0.5885811448097229, Accuracy: 0.7656\n",
      "Epoch 26, Train Loss: 0.5917396545410156, Test Loss: 0.583892822265625, Accuracy: 0.7656\n",
      "Epoch 27, Train Loss: 0.5872632265090942, Test Loss: 0.5796082019805908, Accuracy: 0.7656\n",
      "Epoch 28, Train Loss: 0.583184540271759, Test Loss: 0.5757073760032654, Accuracy: 0.7656\n",
      "Epoch 29, Train Loss: 0.5794832706451416, Test Loss: 0.5721695423126221, Accuracy: 0.7656\n",
      "Epoch 30, Train Loss: 0.5761382579803467, Test Loss: 0.5689719319343567, Accuracy: 0.7656\n",
      "Epoch 31, Train Loss: 0.5731265544891357, Test Loss: 0.5660919547080994, Accuracy: 0.7656\n",
      "Epoch 32, Train Loss: 0.5704255104064941, Test Loss: 0.5635061860084534, Accuracy: 0.7656\n",
      "Epoch 33, Train Loss: 0.5680115818977356, Test Loss: 0.561191737651825, Accuracy: 0.7656\n",
      "Epoch 34, Train Loss: 0.5658617615699768, Test Loss: 0.5591264367103577, Accuracy: 0.7656\n",
      "Epoch 35, Train Loss: 0.5639538764953613, Test Loss: 0.5572885274887085, Accuracy: 0.7656\n",
      "Epoch 36, Train Loss: 0.5622662901878357, Test Loss: 0.5556577444076538, Accuracy: 0.7656\n",
      "Epoch 37, Train Loss: 0.5607789158821106, Test Loss: 0.5542142987251282, Accuracy: 0.7656\n",
      "Epoch 38, Train Loss: 0.5594719052314758, Test Loss: 0.5529404282569885, Accuracy: 0.7656\n",
      "Epoch 39, Train Loss: 0.5583274960517883, Test Loss: 0.55181884765625, Accuracy: 0.7656\n",
      "Epoch 40, Train Loss: 0.5573287606239319, Test Loss: 0.5508337020874023, Accuracy: 0.7656\n",
      "Epoch 41, Train Loss: 0.5564600229263306, Test Loss: 0.5499709248542786, Accuracy: 0.7656\n",
      "Epoch 42, Train Loss: 0.5557070970535278, Test Loss: 0.5492168068885803, Accuracy: 0.7656\n",
      "Epoch 43, Train Loss: 0.5550569295883179, Test Loss: 0.5485594868659973, Accuracy: 0.7656\n",
      "Epoch 44, Train Loss: 0.5544974207878113, Test Loss: 0.5479876399040222, Accuracy: 0.7656\n",
      "Epoch 45, Train Loss: 0.5540177822113037, Test Loss: 0.5474916100502014, Accuracy: 0.7656\n",
      "Epoch 46, Train Loss: 0.5536083579063416, Test Loss: 0.5470620393753052, Accuracy: 0.7656\n",
      "Epoch 47, Train Loss: 0.5532600283622742, Test Loss: 0.5466912984848022, Accuracy: 0.7656\n",
      "Epoch 48, Train Loss: 0.5529654026031494, Test Loss: 0.5463716983795166, Accuracy: 0.7656\n",
      "Epoch 49, Train Loss: 0.5527171492576599, Test Loss: 0.5460971593856812, Accuracy: 0.7656\n",
      "Epoch 50, Train Loss: 0.5525090098381042, Test Loss: 0.5458617210388184, Accuracy: 0.7656\n",
      "Epoch 51, Train Loss: 0.552335798740387, Test Loss: 0.5456601977348328, Accuracy: 0.7656\n",
      "Epoch 52, Train Loss: 0.5521920919418335, Test Loss: 0.5454883575439453, Accuracy: 0.7656\n",
      "Epoch 53, Train Loss: 0.5520738959312439, Test Loss: 0.5453418493270874, Accuracy: 0.7656\n",
      "Epoch 54, Train Loss: 0.5519773960113525, Test Loss: 0.5452174544334412, Accuracy: 0.7656\n",
      "Epoch 55, Train Loss: 0.5518993139266968, Test Loss: 0.545112133026123, Accuracy: 0.7656\n",
      "Epoch 56, Train Loss: 0.5518367886543274, Test Loss: 0.5450231432914734, Accuracy: 0.7656\n",
      "Epoch 57, Train Loss: 0.5517873167991638, Test Loss: 0.5449477434158325, Accuracy: 0.7656\n",
      "Epoch 58, Train Loss: 0.5517483949661255, Test Loss: 0.5448846220970154, Accuracy: 0.7656\n",
      "Epoch 59, Train Loss: 0.5517187118530273, Test Loss: 0.5448315739631653, Accuracy: 0.7656\n",
      "Epoch 60, Train Loss: 0.5516964197158813, Test Loss: 0.5447870492935181, Accuracy: 0.7656\n",
      "Epoch 61, Train Loss: 0.5516800284385681, Test Loss: 0.5447498559951782, Accuracy: 0.7656\n",
      "Epoch 62, Train Loss: 0.5516685247421265, Test Loss: 0.5447189211845398, Accuracy: 0.7656\n",
      "Epoch 63, Train Loss: 0.5516610145568848, Test Loss: 0.5446931719779968, Accuracy: 0.7656\n",
      "Epoch 64, Train Loss: 0.5516565442085266, Test Loss: 0.5446717143058777, Accuracy: 0.7656\n",
      "Epoch 65, Train Loss: 0.5516543388366699, Test Loss: 0.5446538329124451, Accuracy: 0.7656\n",
      "Epoch 66, Train Loss: 0.5516539216041565, Test Loss: 0.5446391701698303, Accuracy: 0.7656\n",
      "Epoch 67, Train Loss: 0.5516548156738281, Test Loss: 0.5446270108222961, Accuracy: 0.7656\n",
      "Epoch 68, Train Loss: 0.5516568422317505, Test Loss: 0.5446170568466187, Accuracy: 0.7656\n",
      "Epoch 69, Train Loss: 0.5516592264175415, Test Loss: 0.5446088314056396, Accuracy: 0.7656\n",
      "Epoch 70, Train Loss: 0.5516620874404907, Test Loss: 0.54460209608078, Accuracy: 0.7656\n",
      "Epoch 71, Train Loss: 0.5516650080680847, Test Loss: 0.5445964336395264, Accuracy: 0.7656\n",
      "Epoch 72, Train Loss: 0.5516679883003235, Test Loss: 0.5445919632911682, Accuracy: 0.7656\n",
      "Epoch 73, Train Loss: 0.5516709089279175, Test Loss: 0.5445883274078369, Accuracy: 0.7656\n",
      "Epoch 74, Train Loss: 0.5516735315322876, Test Loss: 0.5445854663848877, Accuracy: 0.7656\n",
      "Epoch 75, Train Loss: 0.5516760349273682, Test Loss: 0.5445831418037415, Accuracy: 0.7656\n",
      "Epoch 76, Train Loss: 0.5516782999038696, Test Loss: 0.5445812344551086, Accuracy: 0.7656\n",
      "Epoch 77, Train Loss: 0.5516800880432129, Test Loss: 0.5445798635482788, Accuracy: 0.7656\n",
      "Epoch 78, Train Loss: 0.551681637763977, Test Loss: 0.5445787310600281, Accuracy: 0.7656\n",
      "Epoch 79, Train Loss: 0.5516828298568726, Test Loss: 0.5445778965950012, Accuracy: 0.7656\n",
      "Epoch 80, Train Loss: 0.5516836047172546, Test Loss: 0.5445773601531982, Accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81, Train Loss: 0.5516843199729919, Test Loss: 0.5445771813392639, Accuracy: 0.7656\n",
      "Epoch 82, Train Loss: 0.551684558391571, Test Loss: 0.5445771217346191, Accuracy: 0.7656\n",
      "Epoch 83, Train Loss: 0.5516846179962158, Test Loss: 0.5445772409439087, Accuracy: 0.7656\n",
      "Epoch 84, Train Loss: 0.5516844391822815, Test Loss: 0.5445774793624878, Accuracy: 0.7656\n",
      "Epoch 85, Train Loss: 0.5516840815544128, Test Loss: 0.5445781350135803, Accuracy: 0.7656\n",
      "Epoch 86, Train Loss: 0.5516836047172546, Test Loss: 0.5445786714553833, Accuracy: 0.7656\n",
      "Epoch 87, Train Loss: 0.5516828298568726, Test Loss: 0.5445793867111206, Accuracy: 0.7656\n",
      "Epoch 88, Train Loss: 0.5516819357872009, Test Loss: 0.5445802211761475, Accuracy: 0.7656\n",
      "Epoch 89, Train Loss: 0.5516809821128845, Test Loss: 0.5445811748504639, Accuracy: 0.7656\n",
      "Epoch 90, Train Loss: 0.5516800880432129, Test Loss: 0.5445823669433594, Accuracy: 0.7656\n",
      "Epoch 91, Train Loss: 0.5516789555549622, Test Loss: 0.5445835590362549, Accuracy: 0.7656\n",
      "Epoch 92, Train Loss: 0.5516778826713562, Test Loss: 0.5445847511291504, Accuracy: 0.7656\n",
      "Epoch 93, Train Loss: 0.5516766309738159, Test Loss: 0.5445861220359802, Accuracy: 0.7656\n",
      "Epoch 94, Train Loss: 0.5516753792762756, Test Loss: 0.5445876717567444, Accuracy: 0.7656\n",
      "Epoch 95, Train Loss: 0.5516743063926697, Test Loss: 0.5445891618728638, Accuracy: 0.7656\n",
      "Epoch 96, Train Loss: 0.5516730546951294, Test Loss: 0.5445907115936279, Accuracy: 0.7656\n",
      "Epoch 97, Train Loss: 0.5516718626022339, Test Loss: 0.5445923209190369, Accuracy: 0.7656\n",
      "Epoch 98, Train Loss: 0.5516707301139832, Test Loss: 0.544593870639801, Accuracy: 0.7656\n",
      "Epoch 99, Train Loss: 0.5516695380210876, Test Loss: 0.5445957183837891, Accuracy: 0.7656\n",
      "Epoch 100, Train Loss: 0.5516684055328369, Test Loss: 0.5445975661277771, Accuracy: 0.7656\n",
      "Epoch 101, Train Loss: 0.5516674518585205, Test Loss: 0.5445994138717651, Accuracy: 0.7656\n",
      "Epoch 102, Train Loss: 0.5516663789749146, Test Loss: 0.5446012020111084, Accuracy: 0.7656\n",
      "Epoch 103, Train Loss: 0.5516654849052429, Test Loss: 0.5446029901504517, Accuracy: 0.7656\n",
      "Epoch 104, Train Loss: 0.5516645908355713, Test Loss: 0.5446048378944397, Accuracy: 0.7656\n",
      "Epoch 105, Train Loss: 0.5516637563705444, Test Loss: 0.5446067452430725, Accuracy: 0.7656\n",
      "Epoch 106, Train Loss: 0.5516628623008728, Test Loss: 0.5446087121963501, Accuracy: 0.7656\n",
      "Epoch 107, Train Loss: 0.5516621470451355, Test Loss: 0.5446103811264038, Accuracy: 0.7656\n",
      "Epoch 108, Train Loss: 0.5516613721847534, Test Loss: 0.5446123480796814, Accuracy: 0.7656\n",
      "Epoch 109, Train Loss: 0.5516607761383057, Test Loss: 0.5446140766143799, Accuracy: 0.7656\n",
      "Epoch 110, Train Loss: 0.5516601204872131, Test Loss: 0.5446160435676575, Accuracy: 0.7656\n",
      "Epoch 111, Train Loss: 0.5516594648361206, Test Loss: 0.5446177124977112, Accuracy: 0.7656\n",
      "Epoch 112, Train Loss: 0.5516590476036072, Test Loss: 0.5446196794509888, Accuracy: 0.7656\n",
      "Epoch 113, Train Loss: 0.5516586899757385, Test Loss: 0.5446212887763977, Accuracy: 0.7656\n",
      "Epoch 114, Train Loss: 0.5516580939292908, Test Loss: 0.5446229577064514, Accuracy: 0.7656\n",
      "Epoch 115, Train Loss: 0.5516576170921326, Test Loss: 0.5446248054504395, Accuracy: 0.7656\n",
      "Epoch 116, Train Loss: 0.5516574382781982, Test Loss: 0.5446262359619141, Accuracy: 0.7656\n",
      "Epoch 117, Train Loss: 0.5516568422317505, Test Loss: 0.5446279644966125, Accuracy: 0.7656\n",
      "Epoch 118, Train Loss: 0.5516566634178162, Test Loss: 0.5446295738220215, Accuracy: 0.7656\n",
      "Epoch 119, Train Loss: 0.5516563057899475, Test Loss: 0.5446310043334961, Accuracy: 0.7656\n",
      "Epoch 120, Train Loss: 0.5516560673713684, Test Loss: 0.5446324348449707, Accuracy: 0.7656\n",
      "Epoch 121, Train Loss: 0.5516557097434998, Test Loss: 0.5446337461471558, Accuracy: 0.7656\n",
      "Epoch 122, Train Loss: 0.5516554117202759, Test Loss: 0.5446350574493408, Accuracy: 0.7656\n",
      "Epoch 123, Train Loss: 0.5516552925109863, Test Loss: 0.5446365475654602, Accuracy: 0.7656\n",
      "Epoch 124, Train Loss: 0.5516551733016968, Test Loss: 0.5446377992630005, Accuracy: 0.7656\n",
      "Epoch 125, Train Loss: 0.5516550540924072, Test Loss: 0.5446390509605408, Accuracy: 0.7656\n",
      "Epoch 126, Train Loss: 0.5516548752784729, Test Loss: 0.5446402430534363, Accuracy: 0.7656\n",
      "Epoch 127, Train Loss: 0.5516548156738281, Test Loss: 0.5446412563323975, Accuracy: 0.7656\n",
      "Epoch 128, Train Loss: 0.5516546368598938, Test Loss: 0.544642448425293, Accuracy: 0.7656\n",
      "Epoch 129, Train Loss: 0.5516546368598938, Test Loss: 0.5446434617042542, Accuracy: 0.7656\n",
      "Epoch 130, Train Loss: 0.551654577255249, Test Loss: 0.5446445345878601, Accuracy: 0.7656\n",
      "Epoch 131, Train Loss: 0.5516544580459595, Test Loss: 0.5446453094482422, Accuracy: 0.7656\n",
      "Epoch 132, Train Loss: 0.5516543388366699, Test Loss: 0.5446463823318481, Accuracy: 0.7656\n",
      "Epoch 133, Train Loss: 0.5516543388366699, Test Loss: 0.5446470975875854, Accuracy: 0.7656\n",
      "Epoch 134, Train Loss: 0.5516542792320251, Test Loss: 0.5446480512619019, Accuracy: 0.7656\n",
      "Epoch 135, Train Loss: 0.5516543388366699, Test Loss: 0.5446486473083496, Accuracy: 0.7656\n",
      "Epoch 136, Train Loss: 0.551654040813446, Test Loss: 0.5446495413780212, Accuracy: 0.7656\n",
      "Epoch 137, Train Loss: 0.5516542196273804, Test Loss: 0.5446503162384033, Accuracy: 0.7656\n",
      "Epoch 138, Train Loss: 0.5516541600227356, Test Loss: 0.5446508526802063, Accuracy: 0.7656\n",
      "Epoch 139, Train Loss: 0.5516541600227356, Test Loss: 0.5446513891220093, Accuracy: 0.7656\n",
      "Epoch 140, Train Loss: 0.551654040813446, Test Loss: 0.5446520447731018, Accuracy: 0.7656\n",
      "Epoch 141, Train Loss: 0.551654040813446, Test Loss: 0.5446524620056152, Accuracy: 0.7656\n",
      "Epoch 142, Train Loss: 0.5516539216041565, Test Loss: 0.544653058052063, Accuracy: 0.7656\n",
      "Epoch 143, Train Loss: 0.551654040813446, Test Loss: 0.5446535348892212, Accuracy: 0.7656\n",
      "Epoch 144, Train Loss: 0.551654040813446, Test Loss: 0.5446539521217346, Accuracy: 0.7656\n",
      "Epoch 145, Train Loss: 0.5516539812088013, Test Loss: 0.5446544885635376, Accuracy: 0.7656\n",
      "Epoch 146, Train Loss: 0.551654040813446, Test Loss: 0.5446548461914062, Accuracy: 0.7656\n",
      "Epoch 147, Train Loss: 0.551654040813446, Test Loss: 0.5446552634239197, Accuracy: 0.7656\n",
      "Epoch 148, Train Loss: 0.551654040813446, Test Loss: 0.544655442237854, Accuracy: 0.7656\n",
      "Epoch 149, Train Loss: 0.5516539216041565, Test Loss: 0.5446557998657227, Accuracy: 0.7656\n",
      "Epoch 150, Train Loss: 0.5516539812088013, Test Loss: 0.5446560382843018, Accuracy: 0.7656\n",
      "Epoch 151, Train Loss: 0.5516539216041565, Test Loss: 0.5446562767028809, Accuracy: 0.7656\n",
      "Epoch 152, Train Loss: 0.5516539216041565, Test Loss: 0.5446566939353943, Accuracy: 0.7656\n",
      "Epoch 153, Train Loss: 0.551654040813446, Test Loss: 0.5446568727493286, Accuracy: 0.7656\n",
      "Epoch 154, Train Loss: 0.5516539812088013, Test Loss: 0.5446569919586182, Accuracy: 0.7656\n",
      "Epoch 155, Train Loss: 0.5516539216041565, Test Loss: 0.5446572303771973, Accuracy: 0.7656\n",
      "Epoch 156, Train Loss: 0.5516538619995117, Test Loss: 0.5446573495864868, Accuracy: 0.7656\n",
      "Epoch 157, Train Loss: 0.5516539216041565, Test Loss: 0.5446575284004211, Accuracy: 0.7656\n",
      "Epoch 158, Train Loss: 0.5516539216041565, Test Loss: 0.544657826423645, Accuracy: 0.7656\n",
      "Epoch 159, Train Loss: 0.551654040813446, Test Loss: 0.5446579456329346, Accuracy: 0.7656\n",
      "Epoch 160, Train Loss: 0.5516539812088013, Test Loss: 0.5446579456329346, Accuracy: 0.7656\n",
      "Epoch 161, Train Loss: 0.5516538619995117, Test Loss: 0.5446581840515137, Accuracy: 0.7656\n",
      "Epoch 162, Train Loss: 0.551654040813446, Test Loss: 0.5446582436561584, Accuracy: 0.7656\n",
      "Epoch 163, Train Loss: 0.551654040813446, Test Loss: 0.5446583032608032, Accuracy: 0.7656\n",
      "Epoch 164, Train Loss: 0.5516539812088013, Test Loss: 0.544658362865448, Accuracy: 0.7656\n",
      "Epoch 165, Train Loss: 0.5516539216041565, Test Loss: 0.5446585416793823, Accuracy: 0.7656\n",
      "Epoch 166, Train Loss: 0.551654040813446, Test Loss: 0.5446584224700928, Accuracy: 0.7656\n",
      "Epoch 167, Train Loss: 0.5516538619995117, Test Loss: 0.5446585416793823, Accuracy: 0.7656\n",
      "Epoch 168, Train Loss: 0.551654040813446, Test Loss: 0.5446586012840271, Accuracy: 0.7656\n",
      "Epoch 169, Train Loss: 0.5516539216041565, Test Loss: 0.5446586012840271, Accuracy: 0.7656\n",
      "Epoch 170, Train Loss: 0.5516539216041565, Test Loss: 0.5446587800979614, Accuracy: 0.7656\n",
      "Epoch 171, Train Loss: 0.5516539812088013, Test Loss: 0.5446587204933167, Accuracy: 0.7656\n",
      "Epoch 172, Train Loss: 0.5516539812088013, Test Loss: 0.544658899307251, Accuracy: 0.7656\n",
      "Epoch 173, Train Loss: 0.551654040813446, Test Loss: 0.544658899307251, Accuracy: 0.7656\n",
      "Epoch 174, Train Loss: 0.551654040813446, Test Loss: 0.5446588397026062, Accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175, Train Loss: 0.5516539812088013, Test Loss: 0.5446588397026062, Accuracy: 0.7656\n",
      "Epoch 176, Train Loss: 0.551654040813446, Test Loss: 0.5446587204933167, Accuracy: 0.7656\n",
      "Epoch 177, Train Loss: 0.5516538023948669, Test Loss: 0.5446587204933167, Accuracy: 0.7656\n",
      "Epoch 178, Train Loss: 0.5516538023948669, Test Loss: 0.5446585416793823, Accuracy: 0.7656\n",
      "Epoch 179, Train Loss: 0.5516537427902222, Test Loss: 0.5446587204933167, Accuracy: 0.7656\n",
      "Epoch 180, Train Loss: 0.5516538023948669, Test Loss: 0.5446587204933167, Accuracy: 0.7656\n",
      "Epoch 181, Train Loss: 0.5516538023948669, Test Loss: 0.544658899307251, Accuracy: 0.7656\n",
      "Epoch 182, Train Loss: 0.551654040813446, Test Loss: 0.5446587800979614, Accuracy: 0.7656\n",
      "Epoch 183, Train Loss: 0.5516538023948669, Test Loss: 0.5446587800979614, Accuracy: 0.7656\n",
      "Epoch 184, Train Loss: 0.5516538619995117, Test Loss: 0.5446587800979614, Accuracy: 0.7656\n",
      "Epoch 185, Train Loss: 0.5516539812088013, Test Loss: 0.5446587800979614, Accuracy: 0.7656\n",
      "Epoch 186, Train Loss: 0.5516539216041565, Test Loss: 0.5446587800979614, Accuracy: 0.7656\n",
      "Epoch 187, Train Loss: 0.551654040813446, Test Loss: 0.5446587800979614, Accuracy: 0.7656\n",
      "Epoch 188, Train Loss: 0.5516539812088013, Test Loss: 0.5446587800979614, Accuracy: 0.7656\n",
      "Epoch 189, Train Loss: 0.5516539812088013, Test Loss: 0.5446586012840271, Accuracy: 0.7656\n",
      "Epoch 190, Train Loss: 0.5516539216041565, Test Loss: 0.5446586012840271, Accuracy: 0.7656\n",
      "Epoch 191, Train Loss: 0.5516539216041565, Test Loss: 0.5446585416793823, Accuracy: 0.7656\n",
      "Epoch 192, Train Loss: 0.5516539216041565, Test Loss: 0.5446586012840271, Accuracy: 0.7656\n",
      "Epoch 193, Train Loss: 0.5516539812088013, Test Loss: 0.5446587204933167, Accuracy: 0.7656\n",
      "Epoch 194, Train Loss: 0.5516539812088013, Test Loss: 0.5446586012840271, Accuracy: 0.7656\n",
      "Epoch 195, Train Loss: 0.5516539216041565, Test Loss: 0.5446587204933167, Accuracy: 0.7656\n",
      "Epoch 196, Train Loss: 0.551654040813446, Test Loss: 0.5446586012840271, Accuracy: 0.7656\n",
      "Epoch 197, Train Loss: 0.551654040813446, Test Loss: 0.5446585416793823, Accuracy: 0.7656\n",
      "Epoch 198, Train Loss: 0.5516539216041565, Test Loss: 0.5446585416793823, Accuracy: 0.7656\n",
      "Epoch 199, Train Loss: 0.5516539812088013, Test Loss: 0.5446585416793823, Accuracy: 0.7656\n",
      "Epoch 200, Train Loss: 0.5516539812088013, Test Loss: 0.5446585416793823, Accuracy: 0.7656\n",
      "Optimizer: SGD + Momentum\n",
      "Final Test Accuracy: 0.7656\n",
      "Training Time: 10.44 seconds\n",
      "Final Train Loss: 0.5517\n",
      "Final Test Loss: 0.5447\n",
      "\n",
      "Training with optimizer: Adam\n",
      "Epoch 1, Train Loss: 1015.0826416015625, Test Loss: 691.4869995117188, Accuracy: 0.7656\n",
      "Epoch 2, Train Loss: 841.4082641601562, Test Loss: 445.2377014160156, Accuracy: 0.7656\n",
      "Epoch 3, Train Loss: 752.6525268554688, Test Loss: 248.3443603515625, Accuracy: 0.7656\n",
      "Epoch 4, Train Loss: 737.7373046875, Test Loss: 150.79747009277344, Accuracy: 0.7656\n",
      "Epoch 5, Train Loss: 761.97607421875, Test Loss: 140.41213989257812, Accuracy: 0.7656\n",
      "Epoch 6, Train Loss: 741.26806640625, Test Loss: 181.70510864257812, Accuracy: 0.7656\n",
      "Epoch 7, Train Loss: 673.0433959960938, Test Loss: 242.6954345703125, Accuracy: 0.7656\n",
      "Epoch 8, Train Loss: 617.39599609375, Test Loss: 307.988037109375, Accuracy: 0.7656\n",
      "Epoch 9, Train Loss: 588.2262573242188, Test Loss: 365.85162353515625, Accuracy: 0.7657\n",
      "Epoch 10, Train Loss: 557.5574340820312, Test Loss: 407.9754943847656, Accuracy: 0.7660\n",
      "Epoch 11, Train Loss: 545.0, Test Loss: 428.5063781738281, Accuracy: 0.7663\n",
      "Epoch 12, Train Loss: 520.7576293945312, Test Loss: 431.20074462890625, Accuracy: 0.7665\n",
      "Epoch 13, Train Loss: 495.7870788574219, Test Loss: 418.4347839355469, Accuracy: 0.7673\n",
      "Epoch 14, Train Loss: 467.31195068359375, Test Loss: 392.7533874511719, Accuracy: 0.7682\n",
      "Epoch 15, Train Loss: 439.08453369140625, Test Loss: 346.27142333984375, Accuracy: 0.7688\n",
      "Epoch 16, Train Loss: 409.8652038574219, Test Loss: 296.85546875, Accuracy: 0.7695\n",
      "Epoch 17, Train Loss: 382.0838623046875, Test Loss: 248.83937072753906, Accuracy: 0.7707\n",
      "Epoch 18, Train Loss: 356.7261657714844, Test Loss: 206.26510620117188, Accuracy: 0.7711\n",
      "Epoch 19, Train Loss: 343.6352233886719, Test Loss: 174.24134826660156, Accuracy: 0.7716\n",
      "Epoch 20, Train Loss: 329.0343017578125, Test Loss: 155.57867431640625, Accuracy: 0.7720\n",
      "Epoch 21, Train Loss: 311.9147644042969, Test Loss: 149.18704223632812, Accuracy: 0.7723\n",
      "Epoch 22, Train Loss: 289.3271484375, Test Loss: 148.24398803710938, Accuracy: 0.7725\n",
      "Epoch 23, Train Loss: 267.8565673828125, Test Loss: 139.33055114746094, Accuracy: 0.7725\n",
      "Epoch 24, Train Loss: 249.95700073242188, Test Loss: 130.45660400390625, Accuracy: 0.7725\n",
      "Epoch 25, Train Loss: 230.56248474121094, Test Loss: 120.67687225341797, Accuracy: 0.7725\n",
      "Epoch 26, Train Loss: 220.61114501953125, Test Loss: 107.8275375366211, Accuracy: 0.7725\n",
      "Epoch 27, Train Loss: 208.78761291503906, Test Loss: 91.0724868774414, Accuracy: 0.7724\n",
      "Epoch 28, Train Loss: 189.36053466796875, Test Loss: 78.26768493652344, Accuracy: 0.7729\n",
      "Epoch 29, Train Loss: 178.08209228515625, Test Loss: 66.73655700683594, Accuracy: 0.7734\n",
      "Epoch 30, Train Loss: 166.58274841308594, Test Loss: 52.56605529785156, Accuracy: 0.7743\n",
      "Epoch 31, Train Loss: 153.67889404296875, Test Loss: 37.32170104980469, Accuracy: 0.7783\n",
      "Epoch 32, Train Loss: 142.73782348632812, Test Loss: 22.886402130126953, Accuracy: 0.7807\n",
      "Epoch 33, Train Loss: 131.32435607910156, Test Loss: 11.666614532470703, Accuracy: 0.7856\n",
      "Epoch 34, Train Loss: 125.14688110351562, Test Loss: 10.698175430297852, Accuracy: 0.7870\n",
      "Epoch 35, Train Loss: 115.21087646484375, Test Loss: 12.042003631591797, Accuracy: 0.7858\n",
      "Epoch 36, Train Loss: 107.96389770507812, Test Loss: 14.651724815368652, Accuracy: 0.7821\n",
      "Epoch 37, Train Loss: 101.89991760253906, Test Loss: 17.581256866455078, Accuracy: 0.7805\n",
      "Epoch 38, Train Loss: 95.45307159423828, Test Loss: 19.8875675201416, Accuracy: 0.7798\n",
      "Epoch 39, Train Loss: 88.87861633300781, Test Loss: 20.936031341552734, Accuracy: 0.7812\n",
      "Epoch 40, Train Loss: 82.49268341064453, Test Loss: 20.60348892211914, Accuracy: 0.7829\n",
      "Epoch 41, Train Loss: 75.97627258300781, Test Loss: 18.25176429748535, Accuracy: 0.7859\n",
      "Epoch 42, Train Loss: 72.5978012084961, Test Loss: 14.759772300720215, Accuracy: 0.7887\n",
      "Epoch 43, Train Loss: 64.13335418701172, Test Loss: 10.808279991149902, Accuracy: 0.7915\n",
      "Epoch 44, Train Loss: 62.24683380126953, Test Loss: 6.868326187133789, Accuracy: 0.7992\n",
      "Epoch 45, Train Loss: 57.12504196166992, Test Loss: 3.73622727394104, Accuracy: 0.7989\n",
      "Epoch 46, Train Loss: 52.43955993652344, Test Loss: 1.4204353094100952, Accuracy: 0.7885\n",
      "Epoch 47, Train Loss: 48.60209274291992, Test Loss: 2.734102487564087, Accuracy: 0.2325\n",
      "Epoch 48, Train Loss: 44.592552185058594, Test Loss: 6.930373668670654, Accuracy: 0.2344\n",
      "Epoch 49, Train Loss: 41.09297180175781, Test Loss: 7.892609119415283, Accuracy: 0.2344\n",
      "Epoch 50, Train Loss: 37.366939544677734, Test Loss: 7.816029071807861, Accuracy: 0.2344\n",
      "Epoch 51, Train Loss: 33.70166015625, Test Loss: 7.281476974487305, Accuracy: 0.2344\n",
      "Epoch 52, Train Loss: 31.119524002075195, Test Loss: 4.334483623504639, Accuracy: 0.2344\n",
      "Epoch 53, Train Loss: 29.487085342407227, Test Loss: 1.9224505424499512, Accuracy: 0.2344\n",
      "Epoch 54, Train Loss: 26.194862365722656, Test Loss: 0.6139125227928162, Accuracy: 0.7242\n",
      "Epoch 55, Train Loss: 23.865428924560547, Test Loss: 0.6935652494430542, Accuracy: 0.7723\n",
      "Epoch 56, Train Loss: 21.524402618408203, Test Loss: 0.9016932845115662, Accuracy: 0.7720\n",
      "Epoch 57, Train Loss: 20.756332397460938, Test Loss: 1.009411096572876, Accuracy: 0.7718\n",
      "Epoch 58, Train Loss: 19.322072982788086, Test Loss: 1.0188429355621338, Accuracy: 0.7717\n",
      "Epoch 59, Train Loss: 16.906557083129883, Test Loss: 0.9539034366607666, Accuracy: 0.7716\n",
      "Epoch 60, Train Loss: 15.503443717956543, Test Loss: 0.8407579064369202, Accuracy: 0.7716\n",
      "Epoch 61, Train Loss: 14.159682273864746, Test Loss: 0.7130782008171082, Accuracy: 0.7716\n",
      "Epoch 62, Train Loss: 13.228240013122559, Test Loss: 0.608794629573822, Accuracy: 0.7716\n",
      "Epoch 63, Train Loss: 11.733393669128418, Test Loss: 0.5873343348503113, Accuracy: 0.7546\n",
      "Epoch 64, Train Loss: 10.802112579345703, Test Loss: 0.7281434535980225, Accuracy: 0.2344\n",
      "Epoch 65, Train Loss: 9.750941276550293, Test Loss: 0.9375739693641663, Accuracy: 0.2344\n",
      "Epoch 66, Train Loss: 9.347207069396973, Test Loss: 1.0101251602172852, Accuracy: 0.2344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, Train Loss: 8.264030456542969, Test Loss: 0.9344059824943542, Accuracy: 0.2340\n",
      "Epoch 68, Train Loss: 8.006122589111328, Test Loss: 0.8022468686103821, Accuracy: 0.2337\n",
      "Epoch 69, Train Loss: 7.431619167327881, Test Loss: 0.7006075978279114, Accuracy: 0.3806\n",
      "Epoch 70, Train Loss: 6.5757222175598145, Test Loss: 0.6602455377578735, Accuracy: 0.6868\n",
      "Epoch 71, Train Loss: 6.16567850112915, Test Loss: 0.652959942817688, Accuracy: 0.6992\n",
      "Epoch 72, Train Loss: 5.502842426300049, Test Loss: 0.6603229641914368, Accuracy: 0.6894\n",
      "Epoch 73, Train Loss: 5.393552780151367, Test Loss: 0.6726605892181396, Accuracy: 0.6487\n",
      "Epoch 74, Train Loss: 5.008502960205078, Test Loss: 0.6886669993400574, Accuracy: 0.5456\n",
      "Epoch 75, Train Loss: 4.631441116333008, Test Loss: 0.7114271521568298, Accuracy: 0.2459\n",
      "Epoch 76, Train Loss: 4.177613735198975, Test Loss: 0.7383176684379578, Accuracy: 0.2344\n",
      "Epoch 77, Train Loss: 4.147636890411377, Test Loss: 0.7424908876419067, Accuracy: 0.2344\n",
      "Epoch 78, Train Loss: 4.243714332580566, Test Loss: 0.7222407460212708, Accuracy: 0.2344\n",
      "Epoch 79, Train Loss: 3.732937812805176, Test Loss: 0.6995401382446289, Accuracy: 0.3332\n",
      "Epoch 80, Train Loss: 3.435204267501831, Test Loss: 0.6903363466262817, Accuracy: 0.5158\n",
      "Epoch 81, Train Loss: 3.2791099548339844, Test Loss: 0.6915280818939209, Accuracy: 0.5142\n",
      "Epoch 82, Train Loss: 3.077667474746704, Test Loss: 0.698299765586853, Accuracy: 0.3829\n",
      "Epoch 83, Train Loss: 3.2022106647491455, Test Loss: 0.7059018611907959, Accuracy: 0.2623\n",
      "Epoch 84, Train Loss: 2.932218074798584, Test Loss: 0.7128795981407166, Accuracy: 0.2238\n",
      "Epoch 85, Train Loss: 2.513904571533203, Test Loss: 0.7190772891044617, Accuracy: 0.2331\n",
      "Epoch 86, Train Loss: 2.4792468547821045, Test Loss: 0.7219252586364746, Accuracy: 0.2340\n",
      "Epoch 87, Train Loss: 2.6559982299804688, Test Loss: 0.7196306586265564, Accuracy: 0.2335\n",
      "Epoch 88, Train Loss: 2.2830233573913574, Test Loss: 0.7167021036148071, Accuracy: 0.2324\n",
      "Epoch 89, Train Loss: 2.2745492458343506, Test Loss: 0.7162073254585266, Accuracy: 0.2199\n",
      "Epoch 90, Train Loss: 2.105966567993164, Test Loss: 0.7165519595146179, Accuracy: 0.2167\n",
      "Epoch 91, Train Loss: 2.211660623550415, Test Loss: 0.7167331576347351, Accuracy: 0.2215\n",
      "Epoch 92, Train Loss: 1.9561415910720825, Test Loss: 0.7163798809051514, Accuracy: 0.2275\n",
      "Epoch 93, Train Loss: 2.0466315746307373, Test Loss: 0.7153061032295227, Accuracy: 0.2301\n",
      "Epoch 94, Train Loss: 1.736026406288147, Test Loss: 0.7137465476989746, Accuracy: 0.2317\n",
      "Epoch 95, Train Loss: 1.8206738233566284, Test Loss: 0.712488055229187, Accuracy: 0.2328\n",
      "Epoch 96, Train Loss: 1.7718636989593506, Test Loss: 0.711725652217865, Accuracy: 0.2327\n",
      "Epoch 97, Train Loss: 1.6909924745559692, Test Loss: 0.7112190127372742, Accuracy: 0.2307\n",
      "Epoch 98, Train Loss: 1.5373876094818115, Test Loss: 0.7105669379234314, Accuracy: 0.2296\n",
      "Epoch 99, Train Loss: 1.5325983762741089, Test Loss: 0.7096573114395142, Accuracy: 0.2270\n",
      "Epoch 100, Train Loss: 1.5247719287872314, Test Loss: 0.7086467742919922, Accuracy: 0.2262\n",
      "Epoch 101, Train Loss: 1.453878402709961, Test Loss: 0.7076931595802307, Accuracy: 0.2228\n",
      "Epoch 102, Train Loss: 1.5113017559051514, Test Loss: 0.7068490982055664, Accuracy: 0.2210\n",
      "Epoch 103, Train Loss: 1.38058602809906, Test Loss: 0.7059148550033569, Accuracy: 0.2237\n",
      "Epoch 104, Train Loss: 1.3770184516906738, Test Loss: 0.7049523591995239, Accuracy: 0.2293\n",
      "Epoch 105, Train Loss: 1.4742087125778198, Test Loss: 0.7038970589637756, Accuracy: 0.2312\n",
      "Epoch 106, Train Loss: 1.6233329772949219, Test Loss: 0.7029951214790344, Accuracy: 0.2318\n",
      "Epoch 107, Train Loss: 1.5123119354248047, Test Loss: 0.7022887468338013, Accuracy: 0.2301\n",
      "Epoch 108, Train Loss: 1.385884404182434, Test Loss: 0.7016476392745972, Accuracy: 0.2223\n",
      "Epoch 109, Train Loss: 1.2759889364242554, Test Loss: 0.7012780904769897, Accuracy: 0.2164\n",
      "Epoch 110, Train Loss: 1.3178906440734863, Test Loss: 0.7004149556159973, Accuracy: 0.2137\n",
      "Epoch 111, Train Loss: 1.454515814781189, Test Loss: 0.6994180679321289, Accuracy: 0.2124\n",
      "Epoch 112, Train Loss: 1.2689064741134644, Test Loss: 0.6984034776687622, Accuracy: 0.2124\n",
      "Epoch 113, Train Loss: 1.2868499755859375, Test Loss: 0.697450578212738, Accuracy: 0.2134\n",
      "Epoch 114, Train Loss: 1.2312521934509277, Test Loss: 0.6967324018478394, Accuracy: 0.2145\n",
      "Epoch 115, Train Loss: 1.2561951875686646, Test Loss: 0.696105420589447, Accuracy: 0.2122\n",
      "Epoch 116, Train Loss: 1.2239573001861572, Test Loss: 0.6955860257148743, Accuracy: 0.2081\n",
      "Epoch 117, Train Loss: 1.1895357370376587, Test Loss: 0.6947909593582153, Accuracy: 0.2040\n",
      "Epoch 118, Train Loss: 1.1182646751403809, Test Loss: 0.6939193606376648, Accuracy: 0.2021\n",
      "Epoch 119, Train Loss: 1.0679023265838623, Test Loss: 0.693023681640625, Accuracy: 0.2014\n",
      "Epoch 120, Train Loss: 1.134502649307251, Test Loss: 0.6924253702163696, Accuracy: 0.2033\n",
      "Epoch 121, Train Loss: 1.087120532989502, Test Loss: 0.6919256448745728, Accuracy: 0.7693\n",
      "Epoch 122, Train Loss: 1.1012758016586304, Test Loss: 0.6910477876663208, Accuracy: 0.7693\n",
      "Epoch 123, Train Loss: 1.033795952796936, Test Loss: 0.6898062825202942, Accuracy: 0.7693\n",
      "Epoch 124, Train Loss: 1.196667194366455, Test Loss: 0.6886948347091675, Accuracy: 0.7693\n",
      "Epoch 125, Train Loss: 1.1202527284622192, Test Loss: 0.6881776452064514, Accuracy: 0.7693\n",
      "Epoch 126, Train Loss: 1.0438227653503418, Test Loss: 0.6880181431770325, Accuracy: 0.7693\n",
      "Epoch 127, Train Loss: 1.1763230562210083, Test Loss: 0.6874298453330994, Accuracy: 0.7693\n",
      "Epoch 128, Train Loss: 1.0970937013626099, Test Loss: 0.6863340735435486, Accuracy: 0.7693\n",
      "Epoch 129, Train Loss: 1.0461759567260742, Test Loss: 0.6852609515190125, Accuracy: 0.7693\n",
      "Epoch 130, Train Loss: 1.1238800287246704, Test Loss: 0.6847927570343018, Accuracy: 0.7692\n",
      "Epoch 131, Train Loss: 1.0297062397003174, Test Loss: 0.6845946311950684, Accuracy: 0.7692\n",
      "Epoch 132, Train Loss: 0.9481010437011719, Test Loss: 0.6838873028755188, Accuracy: 0.7692\n",
      "Epoch 133, Train Loss: 1.075488805770874, Test Loss: 0.6828274726867676, Accuracy: 0.7692\n",
      "Epoch 134, Train Loss: 1.0731186866760254, Test Loss: 0.6818361878395081, Accuracy: 0.7692\n",
      "Epoch 135, Train Loss: 1.0250788927078247, Test Loss: 0.6815051436424255, Accuracy: 0.7690\n",
      "Epoch 136, Train Loss: 0.9745856523513794, Test Loss: 0.6812847852706909, Accuracy: 0.7690\n",
      "Epoch 137, Train Loss: 1.0106936693191528, Test Loss: 0.680519700050354, Accuracy: 0.7690\n",
      "Epoch 138, Train Loss: 1.0260870456695557, Test Loss: 0.6796911954879761, Accuracy: 0.7690\n",
      "Epoch 139, Train Loss: 0.8987725377082825, Test Loss: 0.6791700720787048, Accuracy: 0.7689\n",
      "Epoch 140, Train Loss: 0.9729325771331787, Test Loss: 0.6787018179893494, Accuracy: 0.7689\n",
      "Epoch 141, Train Loss: 0.9628021717071533, Test Loss: 0.6777037382125854, Accuracy: 0.7689\n",
      "Epoch 142, Train Loss: 1.0773744583129883, Test Loss: 0.6766313910484314, Accuracy: 0.7689\n",
      "Epoch 143, Train Loss: 0.9528685808181763, Test Loss: 0.6757856011390686, Accuracy: 0.7689\n",
      "Epoch 144, Train Loss: 1.128080129623413, Test Loss: 0.6753169894218445, Accuracy: 0.7689\n",
      "Epoch 145, Train Loss: 0.9800405502319336, Test Loss: 0.6745030879974365, Accuracy: 0.7689\n",
      "Epoch 146, Train Loss: 0.8426501154899597, Test Loss: 0.6733862161636353, Accuracy: 0.7689\n",
      "Epoch 147, Train Loss: 0.9553880095481873, Test Loss: 0.672261118888855, Accuracy: 0.7689\n",
      "Epoch 148, Train Loss: 0.9328617453575134, Test Loss: 0.6713737845420837, Accuracy: 0.7689\n",
      "Epoch 149, Train Loss: 0.8873764872550964, Test Loss: 0.6708968281745911, Accuracy: 0.7689\n",
      "Epoch 150, Train Loss: 1.0020227432250977, Test Loss: 0.6702142953872681, Accuracy: 0.7689\n",
      "Epoch 151, Train Loss: 0.890971302986145, Test Loss: 0.6692854166030884, Accuracy: 0.7689\n",
      "Epoch 152, Train Loss: 1.0125033855438232, Test Loss: 0.6684446930885315, Accuracy: 0.7689\n",
      "Epoch 153, Train Loss: 0.8952688574790955, Test Loss: 0.6676766276359558, Accuracy: 0.7689\n",
      "Epoch 154, Train Loss: 0.9002817273139954, Test Loss: 0.6667267084121704, Accuracy: 0.7689\n",
      "Epoch 155, Train Loss: 0.8666365742683411, Test Loss: 0.6657673716545105, Accuracy: 0.7689\n",
      "Epoch 156, Train Loss: 0.9167457818984985, Test Loss: 0.6650795340538025, Accuracy: 0.7689\n",
      "Epoch 157, Train Loss: 0.9634703993797302, Test Loss: 0.6643548011779785, Accuracy: 0.7689\n",
      "Epoch 158, Train Loss: 0.9300214052200317, Test Loss: 0.6638199090957642, Accuracy: 0.7689\n",
      "Epoch 159, Train Loss: 0.9320878386497498, Test Loss: 0.6632457971572876, Accuracy: 0.7689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160, Train Loss: 0.8437817692756653, Test Loss: 0.6625422835350037, Accuracy: 0.7689\n",
      "Epoch 161, Train Loss: 0.8711722493171692, Test Loss: 0.6614817976951599, Accuracy: 0.7689\n",
      "Epoch 162, Train Loss: 0.8460565805435181, Test Loss: 0.6603552103042603, Accuracy: 0.7689\n",
      "Epoch 163, Train Loss: 0.8726882934570312, Test Loss: 0.6591963768005371, Accuracy: 0.7689\n",
      "Epoch 164, Train Loss: 0.9497600197792053, Test Loss: 0.6584526896476746, Accuracy: 0.7689\n",
      "Epoch 165, Train Loss: 0.8662099838256836, Test Loss: 0.6584689617156982, Accuracy: 0.7689\n",
      "Epoch 166, Train Loss: 0.8817487955093384, Test Loss: 0.6582334637641907, Accuracy: 0.7689\n",
      "Epoch 167, Train Loss: 0.8767126202583313, Test Loss: 0.6573575735092163, Accuracy: 0.7689\n",
      "Epoch 168, Train Loss: 0.8815667629241943, Test Loss: 0.6562314033508301, Accuracy: 0.7689\n",
      "Epoch 169, Train Loss: 0.8626565933227539, Test Loss: 0.6548693776130676, Accuracy: 0.7689\n",
      "Epoch 170, Train Loss: 0.8728196620941162, Test Loss: 0.6542993187904358, Accuracy: 0.7689\n",
      "Epoch 171, Train Loss: 0.8580302596092224, Test Loss: 0.6539162993431091, Accuracy: 0.7689\n",
      "Epoch 172, Train Loss: 0.8036547899246216, Test Loss: 0.6534245014190674, Accuracy: 0.7689\n",
      "Epoch 173, Train Loss: 0.7556504607200623, Test Loss: 0.6533323526382446, Accuracy: 0.7689\n",
      "Epoch 174, Train Loss: 0.8936752676963806, Test Loss: 0.6526943445205688, Accuracy: 0.7689\n",
      "Epoch 175, Train Loss: 0.8260707259178162, Test Loss: 0.651713490486145, Accuracy: 0.7689\n",
      "Epoch 176, Train Loss: 0.8424356579780579, Test Loss: 0.6502164602279663, Accuracy: 0.7689\n",
      "Epoch 177, Train Loss: 0.7958346009254456, Test Loss: 0.6494345664978027, Accuracy: 0.7689\n",
      "Epoch 178, Train Loss: 0.8124260902404785, Test Loss: 0.6490228772163391, Accuracy: 0.7689\n",
      "Epoch 179, Train Loss: 0.7897610664367676, Test Loss: 0.6489843726158142, Accuracy: 0.7689\n",
      "Epoch 180, Train Loss: 0.8072789311408997, Test Loss: 0.649638831615448, Accuracy: 0.7689\n",
      "Epoch 181, Train Loss: 0.8246992230415344, Test Loss: 0.6491456031799316, Accuracy: 0.7689\n",
      "Epoch 182, Train Loss: 0.8286162614822388, Test Loss: 0.6458898782730103, Accuracy: 0.7689\n",
      "Epoch 183, Train Loss: 0.8564528822898865, Test Loss: 0.6441611051559448, Accuracy: 0.7689\n",
      "Epoch 184, Train Loss: 0.744457483291626, Test Loss: 0.6443235278129578, Accuracy: 0.7689\n",
      "Epoch 185, Train Loss: 0.8187676072120667, Test Loss: 0.6458569169044495, Accuracy: 0.7689\n",
      "Epoch 186, Train Loss: 0.7570499777793884, Test Loss: 0.6458302736282349, Accuracy: 0.7689\n",
      "Epoch 187, Train Loss: 0.7861789464950562, Test Loss: 0.644977867603302, Accuracy: 0.7689\n",
      "Epoch 188, Train Loss: 0.8393867015838623, Test Loss: 0.6432326436042786, Accuracy: 0.7689\n",
      "Epoch 189, Train Loss: 0.8244044184684753, Test Loss: 0.6408004760742188, Accuracy: 0.7689\n",
      "Epoch 190, Train Loss: 0.854099690914154, Test Loss: 0.6422287821769714, Accuracy: 0.7689\n",
      "Epoch 191, Train Loss: 0.8549770712852478, Test Loss: 0.6436789035797119, Accuracy: 0.7689\n",
      "Epoch 192, Train Loss: 0.8007855415344238, Test Loss: 0.6415976881980896, Accuracy: 0.7689\n",
      "Epoch 193, Train Loss: 0.7852286100387573, Test Loss: 0.6406081318855286, Accuracy: 0.7689\n",
      "Epoch 194, Train Loss: 0.8768801093101501, Test Loss: 0.6381456851959229, Accuracy: 0.7688\n",
      "Epoch 195, Train Loss: 0.7129254937171936, Test Loss: 0.6378427743911743, Accuracy: 0.7688\n",
      "Epoch 196, Train Loss: 0.8020211458206177, Test Loss: 0.6403073668479919, Accuracy: 0.7688\n",
      "Epoch 197, Train Loss: 0.749177098274231, Test Loss: 0.642095685005188, Accuracy: 0.7687\n",
      "Epoch 198, Train Loss: 0.8673402667045593, Test Loss: 0.6384679675102234, Accuracy: 0.7687\n",
      "Epoch 199, Train Loss: 0.7695150375366211, Test Loss: 0.636483907699585, Accuracy: 0.7686\n",
      "Epoch 200, Train Loss: 0.7526784539222717, Test Loss: 0.6370184421539307, Accuracy: 0.7686\n",
      "Optimizer: Adam\n",
      "Final Test Accuracy: 0.7686\n",
      "Training Time: 10.59 seconds\n",
      "Final Train Loss: 0.7527\n",
      "Final Test Loss: 0.6370\n",
      "\n",
      "Training with optimizer: Adagrad\n",
      "Epoch 1, Train Loss: 1830.359130859375, Test Loss: 1462.0958251953125, Accuracy: 0.7656\n",
      "Epoch 2, Train Loss: 1505.8333740234375, Test Loss: 1236.6868896484375, Accuracy: 0.7656\n",
      "Epoch 3, Train Loss: 1277.781005859375, Test Loss: 1061.4801025390625, Accuracy: 0.7656\n",
      "Epoch 4, Train Loss: 1132.3067626953125, Test Loss: 922.4559326171875, Accuracy: 0.7656\n",
      "Epoch 5, Train Loss: 1038.61865234375, Test Loss: 814.623046875, Accuracy: 0.7656\n",
      "Epoch 6, Train Loss: 975.8695678710938, Test Loss: 730.224853515625, Accuracy: 0.7656\n",
      "Epoch 7, Train Loss: 942.2266235351562, Test Loss: 665.8041381835938, Accuracy: 0.7656\n",
      "Epoch 8, Train Loss: 901.9893188476562, Test Loss: 616.97509765625, Accuracy: 0.7656\n",
      "Epoch 9, Train Loss: 890.512939453125, Test Loss: 580.1329345703125, Accuracy: 0.7656\n",
      "Epoch 10, Train Loss: 879.8997802734375, Test Loss: 553.0654907226562, Accuracy: 0.7656\n",
      "Epoch 11, Train Loss: 862.3238525390625, Test Loss: 533.6353759765625, Accuracy: 0.7656\n",
      "Epoch 12, Train Loss: 862.7536010742188, Test Loss: 520.6484985351562, Accuracy: 0.7656\n",
      "Epoch 13, Train Loss: 854.7962646484375, Test Loss: 510.4237976074219, Accuracy: 0.7656\n",
      "Epoch 14, Train Loss: 851.4968872070312, Test Loss: 501.2845764160156, Accuracy: 0.7656\n",
      "Epoch 15, Train Loss: 826.3128662109375, Test Loss: 493.3597106933594, Accuracy: 0.7656\n",
      "Epoch 16, Train Loss: 821.786865234375, Test Loss: 482.6622619628906, Accuracy: 0.7656\n",
      "Epoch 17, Train Loss: 805.0057373046875, Test Loss: 475.5375061035156, Accuracy: 0.7657\n",
      "Epoch 18, Train Loss: 815.8775634765625, Test Loss: 472.19903564453125, Accuracy: 0.7657\n",
      "Epoch 19, Train Loss: 797.7532348632812, Test Loss: 466.6922912597656, Accuracy: 0.7658\n",
      "Epoch 20, Train Loss: 795.8921508789062, Test Loss: 461.951416015625, Accuracy: 0.7659\n",
      "Epoch 21, Train Loss: 779.6808471679688, Test Loss: 455.35931396484375, Accuracy: 0.7659\n",
      "Epoch 22, Train Loss: 779.011962890625, Test Loss: 447.99932861328125, Accuracy: 0.7661\n",
      "Epoch 23, Train Loss: 768.6527709960938, Test Loss: 442.68487548828125, Accuracy: 0.7670\n",
      "Epoch 24, Train Loss: 758.3007202148438, Test Loss: 435.23309326171875, Accuracy: 0.7672\n",
      "Epoch 25, Train Loss: 759.8289184570312, Test Loss: 430.7468566894531, Accuracy: 0.7674\n",
      "Epoch 26, Train Loss: 744.9476928710938, Test Loss: 426.22760009765625, Accuracy: 0.7679\n",
      "Epoch 27, Train Loss: 725.841796875, Test Loss: 421.2797546386719, Accuracy: 0.7680\n",
      "Epoch 28, Train Loss: 735.8914794921875, Test Loss: 414.4525451660156, Accuracy: 0.7682\n",
      "Epoch 29, Train Loss: 717.0728149414062, Test Loss: 409.90924072265625, Accuracy: 0.7685\n",
      "Epoch 30, Train Loss: 730.0593872070312, Test Loss: 407.8347473144531, Accuracy: 0.7686\n",
      "Epoch 31, Train Loss: 711.9850463867188, Test Loss: 400.3748474121094, Accuracy: 0.7686\n",
      "Epoch 32, Train Loss: 695.443115234375, Test Loss: 395.18707275390625, Accuracy: 0.7689\n",
      "Epoch 33, Train Loss: 690.9277954101562, Test Loss: 389.681396484375, Accuracy: 0.7689\n",
      "Epoch 34, Train Loss: 679.5562744140625, Test Loss: 386.3404541015625, Accuracy: 0.7689\n",
      "Epoch 35, Train Loss: 690.4981689453125, Test Loss: 382.68377685546875, Accuracy: 0.7692\n",
      "Epoch 36, Train Loss: 679.18017578125, Test Loss: 377.74627685546875, Accuracy: 0.7693\n",
      "Epoch 37, Train Loss: 671.0322875976562, Test Loss: 376.9360656738281, Accuracy: 0.7697\n",
      "Epoch 38, Train Loss: 675.9437255859375, Test Loss: 371.7627868652344, Accuracy: 0.7698\n",
      "Epoch 39, Train Loss: 653.9093627929688, Test Loss: 366.1595764160156, Accuracy: 0.7701\n",
      "Epoch 40, Train Loss: 661.4019165039062, Test Loss: 362.517333984375, Accuracy: 0.7703\n",
      "Epoch 41, Train Loss: 644.5093994140625, Test Loss: 361.2294921875, Accuracy: 0.7704\n",
      "Epoch 42, Train Loss: 655.0767211914062, Test Loss: 356.9344482421875, Accuracy: 0.7705\n",
      "Epoch 43, Train Loss: 650.182373046875, Test Loss: 351.9546813964844, Accuracy: 0.7706\n",
      "Epoch 44, Train Loss: 638.5317993164062, Test Loss: 349.4617004394531, Accuracy: 0.7708\n",
      "Epoch 45, Train Loss: 627.8233032226562, Test Loss: 346.48992919921875, Accuracy: 0.7709\n",
      "Epoch 46, Train Loss: 629.9116821289062, Test Loss: 344.0964660644531, Accuracy: 0.7709\n",
      "Epoch 47, Train Loss: 627.0764770507812, Test Loss: 340.98834228515625, Accuracy: 0.7709\n",
      "Epoch 48, Train Loss: 615.8114013671875, Test Loss: 332.6559753417969, Accuracy: 0.7710\n",
      "Epoch 49, Train Loss: 607.8123779296875, Test Loss: 328.71075439453125, Accuracy: 0.7711\n",
      "Epoch 50, Train Loss: 613.419677734375, Test Loss: 321.14697265625, Accuracy: 0.7713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Train Loss: 597.3702392578125, Test Loss: 317.5028381347656, Accuracy: 0.7714\n",
      "Epoch 52, Train Loss: 590.1895141601562, Test Loss: 314.8033142089844, Accuracy: 0.7716\n",
      "Epoch 53, Train Loss: 593.3326416015625, Test Loss: 309.4473571777344, Accuracy: 0.7716\n",
      "Epoch 54, Train Loss: 585.3675537109375, Test Loss: 303.8810119628906, Accuracy: 0.7716\n",
      "Epoch 55, Train Loss: 572.7162475585938, Test Loss: 294.7485656738281, Accuracy: 0.7716\n",
      "Epoch 56, Train Loss: 576.4910888671875, Test Loss: 288.9557189941406, Accuracy: 0.7716\n",
      "Epoch 57, Train Loss: 572.8162231445312, Test Loss: 287.04095458984375, Accuracy: 0.7717\n",
      "Epoch 58, Train Loss: 555.1942749023438, Test Loss: 282.9884033203125, Accuracy: 0.7717\n",
      "Epoch 59, Train Loss: 553.4867553710938, Test Loss: 279.3695373535156, Accuracy: 0.7717\n",
      "Epoch 60, Train Loss: 551.8101196289062, Test Loss: 273.06439208984375, Accuracy: 0.7718\n",
      "Epoch 61, Train Loss: 553.0040283203125, Test Loss: 271.56365966796875, Accuracy: 0.7719\n",
      "Epoch 62, Train Loss: 546.115234375, Test Loss: 266.9015197753906, Accuracy: 0.7720\n",
      "Epoch 63, Train Loss: 549.023681640625, Test Loss: 265.9193420410156, Accuracy: 0.7720\n",
      "Epoch 64, Train Loss: 531.75146484375, Test Loss: 260.8902587890625, Accuracy: 0.7720\n",
      "Epoch 65, Train Loss: 534.2142944335938, Test Loss: 254.97021484375, Accuracy: 0.7722\n",
      "Epoch 66, Train Loss: 522.6387329101562, Test Loss: 251.79299926757812, Accuracy: 0.7723\n",
      "Epoch 67, Train Loss: 529.5282592773438, Test Loss: 247.6283416748047, Accuracy: 0.7723\n",
      "Epoch 68, Train Loss: 521.1087646484375, Test Loss: 241.47671508789062, Accuracy: 0.7723\n",
      "Epoch 69, Train Loss: 520.2761840820312, Test Loss: 236.8746337890625, Accuracy: 0.7725\n",
      "Epoch 70, Train Loss: 517.0018920898438, Test Loss: 235.07907104492188, Accuracy: 0.7725\n",
      "Epoch 71, Train Loss: 504.5971984863281, Test Loss: 229.53396606445312, Accuracy: 0.7728\n",
      "Epoch 72, Train Loss: 499.0522766113281, Test Loss: 224.7150115966797, Accuracy: 0.7729\n",
      "Epoch 73, Train Loss: 497.5799560546875, Test Loss: 221.68988037109375, Accuracy: 0.7729\n",
      "Epoch 74, Train Loss: 501.6556091308594, Test Loss: 217.62596130371094, Accuracy: 0.7731\n",
      "Epoch 75, Train Loss: 501.64764404296875, Test Loss: 213.46435546875, Accuracy: 0.7732\n",
      "Epoch 76, Train Loss: 498.078369140625, Test Loss: 209.31777954101562, Accuracy: 0.7732\n",
      "Epoch 77, Train Loss: 493.07025146484375, Test Loss: 204.69598388671875, Accuracy: 0.7734\n",
      "Epoch 78, Train Loss: 485.3822937011719, Test Loss: 204.1468963623047, Accuracy: 0.7734\n",
      "Epoch 79, Train Loss: 480.3951721191406, Test Loss: 201.04466247558594, Accuracy: 0.7734\n",
      "Epoch 80, Train Loss: 477.1640319824219, Test Loss: 197.35630798339844, Accuracy: 0.7734\n",
      "Epoch 81, Train Loss: 474.10687255859375, Test Loss: 192.08163452148438, Accuracy: 0.7734\n",
      "Epoch 82, Train Loss: 472.18707275390625, Test Loss: 187.89002990722656, Accuracy: 0.7736\n",
      "Epoch 83, Train Loss: 459.01251220703125, Test Loss: 183.10894775390625, Accuracy: 0.7738\n",
      "Epoch 84, Train Loss: 458.8056640625, Test Loss: 181.92550659179688, Accuracy: 0.7739\n",
      "Epoch 85, Train Loss: 457.3642578125, Test Loss: 177.18350219726562, Accuracy: 0.7739\n",
      "Epoch 86, Train Loss: 449.7756652832031, Test Loss: 170.92684936523438, Accuracy: 0.7743\n",
      "Epoch 87, Train Loss: 448.4889221191406, Test Loss: 169.37026977539062, Accuracy: 0.7743\n",
      "Epoch 88, Train Loss: 446.3303527832031, Test Loss: 165.21456909179688, Accuracy: 0.7743\n",
      "Epoch 89, Train Loss: 440.751220703125, Test Loss: 163.40350341796875, Accuracy: 0.7743\n",
      "Epoch 90, Train Loss: 440.9549865722656, Test Loss: 157.59584045410156, Accuracy: 0.7747\n",
      "Epoch 91, Train Loss: 434.9477233886719, Test Loss: 156.19161987304688, Accuracy: 0.7746\n",
      "Epoch 92, Train Loss: 426.176025390625, Test Loss: 151.51255798339844, Accuracy: 0.7746\n",
      "Epoch 93, Train Loss: 423.29400634765625, Test Loss: 149.51235961914062, Accuracy: 0.7746\n",
      "Epoch 94, Train Loss: 425.9343566894531, Test Loss: 144.13861083984375, Accuracy: 0.7751\n",
      "Epoch 95, Train Loss: 420.7354431152344, Test Loss: 145.8137664794922, Accuracy: 0.7748\n",
      "Epoch 96, Train Loss: 413.74774169921875, Test Loss: 142.99777221679688, Accuracy: 0.7749\n",
      "Epoch 97, Train Loss: 413.86334228515625, Test Loss: 137.78086853027344, Accuracy: 0.7750\n",
      "Epoch 98, Train Loss: 405.7820129394531, Test Loss: 136.72210693359375, Accuracy: 0.7748\n",
      "Epoch 99, Train Loss: 405.8871765136719, Test Loss: 131.738525390625, Accuracy: 0.7752\n",
      "Epoch 100, Train Loss: 412.4179992675781, Test Loss: 127.72003173828125, Accuracy: 0.7753\n",
      "Epoch 101, Train Loss: 397.1656799316406, Test Loss: 124.87401580810547, Accuracy: 0.7753\n",
      "Epoch 102, Train Loss: 402.1150817871094, Test Loss: 121.09784698486328, Accuracy: 0.7754\n",
      "Epoch 103, Train Loss: 392.0188903808594, Test Loss: 120.99017333984375, Accuracy: 0.7748\n",
      "Epoch 104, Train Loss: 395.1935729980469, Test Loss: 116.69168853759766, Accuracy: 0.7753\n",
      "Epoch 105, Train Loss: 388.68017578125, Test Loss: 113.60633087158203, Accuracy: 0.7753\n",
      "Epoch 106, Train Loss: 393.29376220703125, Test Loss: 111.09303283691406, Accuracy: 0.7752\n",
      "Epoch 107, Train Loss: 383.22039794921875, Test Loss: 106.74950408935547, Accuracy: 0.7755\n",
      "Epoch 108, Train Loss: 384.13482666015625, Test Loss: 105.2433853149414, Accuracy: 0.7754\n",
      "Epoch 109, Train Loss: 377.62298583984375, Test Loss: 104.68709564208984, Accuracy: 0.7748\n",
      "Epoch 110, Train Loss: 376.85552978515625, Test Loss: 104.49197387695312, Accuracy: 0.7746\n",
      "Epoch 111, Train Loss: 375.6972961425781, Test Loss: 102.6028060913086, Accuracy: 0.7746\n",
      "Epoch 112, Train Loss: 373.9799499511719, Test Loss: 100.69200134277344, Accuracy: 0.7746\n",
      "Epoch 113, Train Loss: 366.06109619140625, Test Loss: 99.67866516113281, Accuracy: 0.7746\n",
      "Epoch 114, Train Loss: 369.00872802734375, Test Loss: 99.87946319580078, Accuracy: 0.7747\n",
      "Epoch 115, Train Loss: 363.64556884765625, Test Loss: 97.8597183227539, Accuracy: 0.7747\n",
      "Epoch 116, Train Loss: 361.8329162597656, Test Loss: 95.63663482666016, Accuracy: 0.7746\n",
      "Epoch 117, Train Loss: 356.42132568359375, Test Loss: 94.03587341308594, Accuracy: 0.7746\n",
      "Epoch 118, Train Loss: 353.0447692871094, Test Loss: 94.71367645263672, Accuracy: 0.7745\n",
      "Epoch 119, Train Loss: 360.26287841796875, Test Loss: 94.44342041015625, Accuracy: 0.7745\n",
      "Epoch 120, Train Loss: 355.0423278808594, Test Loss: 95.5313491821289, Accuracy: 0.7744\n",
      "Epoch 121, Train Loss: 348.550537109375, Test Loss: 93.98101043701172, Accuracy: 0.7747\n",
      "Epoch 122, Train Loss: 346.7724609375, Test Loss: 92.52175903320312, Accuracy: 0.7746\n",
      "Epoch 123, Train Loss: 341.2900085449219, Test Loss: 92.06018829345703, Accuracy: 0.7746\n",
      "Epoch 124, Train Loss: 340.564697265625, Test Loss: 92.86911010742188, Accuracy: 0.7746\n",
      "Epoch 125, Train Loss: 334.48590087890625, Test Loss: 93.69489288330078, Accuracy: 0.7746\n",
      "Epoch 126, Train Loss: 334.85052490234375, Test Loss: 95.45922088623047, Accuracy: 0.7746\n",
      "Epoch 127, Train Loss: 340.4222106933594, Test Loss: 93.2846908569336, Accuracy: 0.7746\n",
      "Epoch 128, Train Loss: 332.80657958984375, Test Loss: 92.73186492919922, Accuracy: 0.7747\n",
      "Epoch 129, Train Loss: 332.985595703125, Test Loss: 94.71076965332031, Accuracy: 0.7746\n",
      "Epoch 130, Train Loss: 327.0487976074219, Test Loss: 96.08382415771484, Accuracy: 0.7746\n",
      "Epoch 131, Train Loss: 325.439453125, Test Loss: 95.24466705322266, Accuracy: 0.7746\n",
      "Epoch 132, Train Loss: 319.89007568359375, Test Loss: 94.50480651855469, Accuracy: 0.7747\n",
      "Epoch 133, Train Loss: 312.51959228515625, Test Loss: 93.06505584716797, Accuracy: 0.7749\n",
      "Epoch 134, Train Loss: 317.49163818359375, Test Loss: 94.41606903076172, Accuracy: 0.7749\n",
      "Epoch 135, Train Loss: 309.96978759765625, Test Loss: 95.11483001708984, Accuracy: 0.7749\n",
      "Epoch 136, Train Loss: 313.23309326171875, Test Loss: 95.44850158691406, Accuracy: 0.7751\n",
      "Epoch 137, Train Loss: 308.1751708984375, Test Loss: 95.0368881225586, Accuracy: 0.7755\n",
      "Epoch 138, Train Loss: 314.6473693847656, Test Loss: 94.75788116455078, Accuracy: 0.7761\n",
      "Epoch 139, Train Loss: 301.552978515625, Test Loss: 95.40756225585938, Accuracy: 0.7761\n",
      "Epoch 140, Train Loss: 304.7059326171875, Test Loss: 95.57278442382812, Accuracy: 0.7763\n",
      "Epoch 141, Train Loss: 304.6448059082031, Test Loss: 96.77845001220703, Accuracy: 0.7763\n",
      "Epoch 142, Train Loss: 301.4200439453125, Test Loss: 95.13684844970703, Accuracy: 0.7766\n",
      "Epoch 143, Train Loss: 296.552734375, Test Loss: 94.30521392822266, Accuracy: 0.7773\n",
      "Epoch 144, Train Loss: 292.5753479003906, Test Loss: 94.80690002441406, Accuracy: 0.7774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145, Train Loss: 294.2804260253906, Test Loss: 94.65101623535156, Accuracy: 0.7777\n",
      "Epoch 146, Train Loss: 292.73724365234375, Test Loss: 94.24652862548828, Accuracy: 0.7781\n",
      "Epoch 147, Train Loss: 291.0513916015625, Test Loss: 93.06866455078125, Accuracy: 0.7782\n",
      "Epoch 148, Train Loss: 288.3070983886719, Test Loss: 91.93199920654297, Accuracy: 0.7783\n",
      "Epoch 149, Train Loss: 277.188720703125, Test Loss: 91.43376922607422, Accuracy: 0.7783\n",
      "Epoch 150, Train Loss: 285.808349609375, Test Loss: 89.44303131103516, Accuracy: 0.7785\n",
      "Epoch 151, Train Loss: 283.8505859375, Test Loss: 89.63993072509766, Accuracy: 0.7785\n",
      "Epoch 152, Train Loss: 281.11614990234375, Test Loss: 88.9620132446289, Accuracy: 0.7785\n",
      "Epoch 153, Train Loss: 281.6903381347656, Test Loss: 86.41036224365234, Accuracy: 0.7788\n",
      "Epoch 154, Train Loss: 272.1043395996094, Test Loss: 84.05999755859375, Accuracy: 0.7789\n",
      "Epoch 155, Train Loss: 273.3918762207031, Test Loss: 82.05030822753906, Accuracy: 0.7789\n",
      "Epoch 156, Train Loss: 267.07696533203125, Test Loss: 80.43932342529297, Accuracy: 0.7790\n",
      "Epoch 157, Train Loss: 270.4238586425781, Test Loss: 78.84624481201172, Accuracy: 0.7789\n",
      "Epoch 158, Train Loss: 268.9418029785156, Test Loss: 77.44331359863281, Accuracy: 0.7792\n",
      "Epoch 159, Train Loss: 268.22784423828125, Test Loss: 75.8628921508789, Accuracy: 0.7795\n",
      "Epoch 160, Train Loss: 263.08160400390625, Test Loss: 73.75302124023438, Accuracy: 0.7797\n",
      "Epoch 161, Train Loss: 262.2776184082031, Test Loss: 72.39729309082031, Accuracy: 0.7797\n",
      "Epoch 162, Train Loss: 262.44415283203125, Test Loss: 70.29532623291016, Accuracy: 0.7798\n",
      "Epoch 163, Train Loss: 260.3839111328125, Test Loss: 69.90597534179688, Accuracy: 0.7798\n",
      "Epoch 164, Train Loss: 258.80560302734375, Test Loss: 69.92622375488281, Accuracy: 0.7798\n",
      "Epoch 165, Train Loss: 253.1075897216797, Test Loss: 68.437255859375, Accuracy: 0.7801\n",
      "Epoch 166, Train Loss: 253.8125762939453, Test Loss: 66.780517578125, Accuracy: 0.7811\n",
      "Epoch 167, Train Loss: 254.62747192382812, Test Loss: 66.51206970214844, Accuracy: 0.7811\n",
      "Epoch 168, Train Loss: 255.5366668701172, Test Loss: 65.45040893554688, Accuracy: 0.7813\n",
      "Epoch 169, Train Loss: 253.65756225585938, Test Loss: 64.62858581542969, Accuracy: 0.7817\n",
      "Epoch 170, Train Loss: 251.63143920898438, Test Loss: 65.32416534423828, Accuracy: 0.7812\n",
      "Epoch 171, Train Loss: 245.7870635986328, Test Loss: 66.11282348632812, Accuracy: 0.7809\n",
      "Epoch 172, Train Loss: 245.09783935546875, Test Loss: 64.68754577636719, Accuracy: 0.7813\n",
      "Epoch 173, Train Loss: 247.11680603027344, Test Loss: 64.12930297851562, Accuracy: 0.7817\n",
      "Epoch 174, Train Loss: 243.91712951660156, Test Loss: 64.00042724609375, Accuracy: 0.7817\n",
      "Epoch 175, Train Loss: 240.5877685546875, Test Loss: 64.4834976196289, Accuracy: 0.7813\n",
      "Epoch 176, Train Loss: 238.9680633544922, Test Loss: 64.48155975341797, Accuracy: 0.7812\n",
      "Epoch 177, Train Loss: 238.0408477783203, Test Loss: 63.518585205078125, Accuracy: 0.7813\n",
      "Epoch 178, Train Loss: 233.1908416748047, Test Loss: 61.616172790527344, Accuracy: 0.7819\n",
      "Epoch 179, Train Loss: 236.12515258789062, Test Loss: 62.41355895996094, Accuracy: 0.7817\n",
      "Epoch 180, Train Loss: 232.86090087890625, Test Loss: 61.19325637817383, Accuracy: 0.7819\n",
      "Epoch 181, Train Loss: 233.17178344726562, Test Loss: 61.58838653564453, Accuracy: 0.7818\n",
      "Epoch 182, Train Loss: 227.27561950683594, Test Loss: 61.41416549682617, Accuracy: 0.7818\n",
      "Epoch 183, Train Loss: 229.870849609375, Test Loss: 61.79180908203125, Accuracy: 0.7815\n",
      "Epoch 184, Train Loss: 225.5738983154297, Test Loss: 61.15696334838867, Accuracy: 0.7817\n",
      "Epoch 185, Train Loss: 224.57382202148438, Test Loss: 59.938785552978516, Accuracy: 0.7819\n",
      "Epoch 186, Train Loss: 228.5230712890625, Test Loss: 59.178382873535156, Accuracy: 0.7819\n",
      "Epoch 187, Train Loss: 219.9123992919922, Test Loss: 60.06429672241211, Accuracy: 0.7817\n",
      "Epoch 188, Train Loss: 222.3889617919922, Test Loss: 59.716922760009766, Accuracy: 0.7815\n",
      "Epoch 189, Train Loss: 217.96713256835938, Test Loss: 57.592472076416016, Accuracy: 0.7821\n",
      "Epoch 190, Train Loss: 218.9603271484375, Test Loss: 57.562313079833984, Accuracy: 0.7819\n",
      "Epoch 191, Train Loss: 220.56716918945312, Test Loss: 56.95955276489258, Accuracy: 0.7820\n",
      "Epoch 192, Train Loss: 217.37905883789062, Test Loss: 57.283775329589844, Accuracy: 0.7818\n",
      "Epoch 193, Train Loss: 216.0482635498047, Test Loss: 57.379981994628906, Accuracy: 0.7815\n",
      "Epoch 194, Train Loss: 213.55662536621094, Test Loss: 56.95090866088867, Accuracy: 0.7817\n",
      "Epoch 195, Train Loss: 209.93360900878906, Test Loss: 56.32061767578125, Accuracy: 0.7817\n",
      "Epoch 196, Train Loss: 206.73419189453125, Test Loss: 55.71522903442383, Accuracy: 0.7817\n",
      "Epoch 197, Train Loss: 207.21640014648438, Test Loss: 54.84334945678711, Accuracy: 0.7819\n",
      "Epoch 198, Train Loss: 207.4413299560547, Test Loss: 54.66695785522461, Accuracy: 0.7819\n",
      "Epoch 199, Train Loss: 206.0443572998047, Test Loss: 53.87457275390625, Accuracy: 0.7819\n",
      "Epoch 200, Train Loss: 207.17237854003906, Test Loss: 54.556331634521484, Accuracy: 0.7810\n",
      "Optimizer: Adagrad\n",
      "Final Test Accuracy: 0.7810\n",
      "Training Time: 10.59 seconds\n",
      "Final Train Loss: 207.1724\n",
      "Final Test Loss: 54.5563\n",
      "\n",
      "Training with optimizer: Adamax\n",
      "Epoch 1, Train Loss: 1121.8106689453125, Test Loss: 160.53309631347656, Accuracy: 0.7656\n",
      "Epoch 2, Train Loss: 996.4470825195312, Test Loss: 266.78924560546875, Accuracy: 0.7656\n",
      "Epoch 3, Train Loss: 933.5675048828125, Test Loss: 326.2158508300781, Accuracy: 0.7656\n",
      "Epoch 4, Train Loss: 920.6507568359375, Test Loss: 354.9329528808594, Accuracy: 0.7658\n",
      "Epoch 5, Train Loss: 887.1618041992188, Test Loss: 363.0616455078125, Accuracy: 0.7660\n",
      "Epoch 6, Train Loss: 881.385498046875, Test Loss: 356.9112243652344, Accuracy: 0.7664\n",
      "Epoch 7, Train Loss: 860.1912231445312, Test Loss: 339.69635009765625, Accuracy: 0.7670\n",
      "Epoch 8, Train Loss: 824.2095947265625, Test Loss: 315.25848388671875, Accuracy: 0.7675\n",
      "Epoch 9, Train Loss: 795.43994140625, Test Loss: 288.9740905761719, Accuracy: 0.7682\n",
      "Epoch 10, Train Loss: 779.7880249023438, Test Loss: 261.6906433105469, Accuracy: 0.7689\n",
      "Epoch 11, Train Loss: 750.8755493164062, Test Loss: 236.5249481201172, Accuracy: 0.7699\n",
      "Epoch 12, Train Loss: 728.8367919921875, Test Loss: 215.2864990234375, Accuracy: 0.7709\n",
      "Epoch 13, Train Loss: 696.9806518554688, Test Loss: 195.94432067871094, Accuracy: 0.7713\n",
      "Epoch 14, Train Loss: 688.9415893554688, Test Loss: 179.96217346191406, Accuracy: 0.7716\n",
      "Epoch 15, Train Loss: 661.6080322265625, Test Loss: 167.5354766845703, Accuracy: 0.7720\n",
      "Epoch 16, Train Loss: 655.3876342773438, Test Loss: 158.14405822753906, Accuracy: 0.7723\n",
      "Epoch 17, Train Loss: 633.087646484375, Test Loss: 151.8166046142578, Accuracy: 0.7725\n",
      "Epoch 18, Train Loss: 615.9844970703125, Test Loss: 148.52354431152344, Accuracy: 0.7729\n",
      "Epoch 19, Train Loss: 595.343505859375, Test Loss: 147.9163818359375, Accuracy: 0.7731\n",
      "Epoch 20, Train Loss: 590.2805786132812, Test Loss: 149.94906616210938, Accuracy: 0.7732\n",
      "Epoch 21, Train Loss: 563.4209594726562, Test Loss: 153.72903442382812, Accuracy: 0.7734\n",
      "Epoch 22, Train Loss: 535.4119873046875, Test Loss: 158.6262664794922, Accuracy: 0.7735\n",
      "Epoch 23, Train Loss: 535.4841918945312, Test Loss: 164.2023162841797, Accuracy: 0.7734\n",
      "Epoch 24, Train Loss: 517.1271362304688, Test Loss: 169.88609313964844, Accuracy: 0.7733\n",
      "Epoch 25, Train Loss: 503.1687927246094, Test Loss: 177.10470581054688, Accuracy: 0.7735\n",
      "Epoch 26, Train Loss: 492.6142883300781, Test Loss: 183.18919372558594, Accuracy: 0.7735\n",
      "Epoch 27, Train Loss: 476.3909606933594, Test Loss: 187.39195251464844, Accuracy: 0.7738\n",
      "Epoch 28, Train Loss: 470.03302001953125, Test Loss: 189.838623046875, Accuracy: 0.7739\n",
      "Epoch 29, Train Loss: 453.1906433105469, Test Loss: 189.09349060058594, Accuracy: 0.7739\n",
      "Epoch 30, Train Loss: 449.2966613769531, Test Loss: 185.7512969970703, Accuracy: 0.7744\n",
      "Epoch 31, Train Loss: 438.71588134765625, Test Loss: 179.84056091308594, Accuracy: 0.7746\n",
      "Epoch 32, Train Loss: 415.15728759765625, Test Loss: 171.72802734375, Accuracy: 0.7754\n",
      "Epoch 33, Train Loss: 410.246826171875, Test Loss: 162.21461486816406, Accuracy: 0.7766\n",
      "Epoch 34, Train Loss: 406.5001525878906, Test Loss: 151.6825408935547, Accuracy: 0.7780\n",
      "Epoch 35, Train Loss: 393.28167724609375, Test Loss: 141.14959716796875, Accuracy: 0.7787\n",
      "Epoch 36, Train Loss: 372.9111022949219, Test Loss: 131.2379913330078, Accuracy: 0.7789\n",
      "Epoch 37, Train Loss: 368.7784118652344, Test Loss: 122.13541412353516, Accuracy: 0.7795\n",
      "Epoch 38, Train Loss: 364.2815856933594, Test Loss: 114.17388916015625, Accuracy: 0.7798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Train Loss: 351.0712890625, Test Loss: 108.00281524658203, Accuracy: 0.7813\n",
      "Epoch 40, Train Loss: 344.6152038574219, Test Loss: 103.36640930175781, Accuracy: 0.7830\n",
      "Epoch 41, Train Loss: 346.177490234375, Test Loss: 100.04045867919922, Accuracy: 0.7850\n",
      "Epoch 42, Train Loss: 328.36767578125, Test Loss: 97.22830200195312, Accuracy: 0.7858\n",
      "Epoch 43, Train Loss: 325.7691650390625, Test Loss: 95.89859008789062, Accuracy: 0.7862\n",
      "Epoch 44, Train Loss: 317.4088134765625, Test Loss: 95.29077911376953, Accuracy: 0.7868\n",
      "Epoch 45, Train Loss: 313.35980224609375, Test Loss: 95.10516357421875, Accuracy: 0.7870\n",
      "Epoch 46, Train Loss: 304.8154602050781, Test Loss: 94.6271743774414, Accuracy: 0.7881\n",
      "Epoch 47, Train Loss: 297.5029296875, Test Loss: 93.7000961303711, Accuracy: 0.7889\n",
      "Epoch 48, Train Loss: 291.7849426269531, Test Loss: 92.40494537353516, Accuracy: 0.7896\n",
      "Epoch 49, Train Loss: 289.85870361328125, Test Loss: 90.25992584228516, Accuracy: 0.7899\n",
      "Epoch 50, Train Loss: 285.7066650390625, Test Loss: 87.55799865722656, Accuracy: 0.7907\n",
      "Epoch 51, Train Loss: 275.2539978027344, Test Loss: 84.34156799316406, Accuracy: 0.7919\n",
      "Epoch 52, Train Loss: 274.9664611816406, Test Loss: 80.68911743164062, Accuracy: 0.7926\n",
      "Epoch 53, Train Loss: 266.4571838378906, Test Loss: 75.5366439819336, Accuracy: 0.7932\n",
      "Epoch 54, Train Loss: 259.1476745605469, Test Loss: 68.58261108398438, Accuracy: 0.7946\n",
      "Epoch 55, Train Loss: 258.9148254394531, Test Loss: 62.28185272216797, Accuracy: 0.7960\n",
      "Epoch 56, Train Loss: 253.53453063964844, Test Loss: 59.288291931152344, Accuracy: 0.7968\n",
      "Epoch 57, Train Loss: 246.7705078125, Test Loss: 56.85152816772461, Accuracy: 0.7971\n",
      "Epoch 58, Train Loss: 241.02993774414062, Test Loss: 55.15808868408203, Accuracy: 0.7977\n",
      "Epoch 59, Train Loss: 241.13873291015625, Test Loss: 54.006587982177734, Accuracy: 0.7983\n",
      "Epoch 60, Train Loss: 232.0021209716797, Test Loss: 53.18144607543945, Accuracy: 0.7983\n",
      "Epoch 61, Train Loss: 232.54151916503906, Test Loss: 52.69796371459961, Accuracy: 0.7984\n",
      "Epoch 62, Train Loss: 223.47695922851562, Test Loss: 52.55825424194336, Accuracy: 0.7982\n",
      "Epoch 63, Train Loss: 221.4350128173828, Test Loss: 52.716270446777344, Accuracy: 0.7971\n",
      "Epoch 64, Train Loss: 221.26123046875, Test Loss: 53.13596725463867, Accuracy: 0.7968\n",
      "Epoch 65, Train Loss: 211.19541931152344, Test Loss: 53.49979782104492, Accuracy: 0.7962\n",
      "Epoch 66, Train Loss: 209.9875030517578, Test Loss: 53.72046661376953, Accuracy: 0.7956\n",
      "Epoch 67, Train Loss: 208.8522186279297, Test Loss: 53.64122009277344, Accuracy: 0.7950\n",
      "Epoch 68, Train Loss: 202.25344848632812, Test Loss: 54.470008850097656, Accuracy: 0.7949\n",
      "Epoch 69, Train Loss: 198.905517578125, Test Loss: 55.42289352416992, Accuracy: 0.7946\n",
      "Epoch 70, Train Loss: 195.85777282714844, Test Loss: 55.826576232910156, Accuracy: 0.7942\n",
      "Epoch 71, Train Loss: 195.02703857421875, Test Loss: 56.050106048583984, Accuracy: 0.7943\n",
      "Epoch 72, Train Loss: 191.3432159423828, Test Loss: 56.457027435302734, Accuracy: 0.7943\n",
      "Epoch 73, Train Loss: 187.36276245117188, Test Loss: 56.94675064086914, Accuracy: 0.7943\n",
      "Epoch 74, Train Loss: 183.35507202148438, Test Loss: 56.52914810180664, Accuracy: 0.7942\n",
      "Epoch 75, Train Loss: 180.51783752441406, Test Loss: 54.525909423828125, Accuracy: 0.7939\n",
      "Epoch 76, Train Loss: 179.53549194335938, Test Loss: 52.535301208496094, Accuracy: 0.7932\n",
      "Epoch 77, Train Loss: 177.1219024658203, Test Loss: 50.76502990722656, Accuracy: 0.7930\n",
      "Epoch 78, Train Loss: 174.1857452392578, Test Loss: 49.15304946899414, Accuracy: 0.7926\n",
      "Epoch 79, Train Loss: 167.37815856933594, Test Loss: 47.536285400390625, Accuracy: 0.7921\n",
      "Epoch 80, Train Loss: 168.71090698242188, Test Loss: 45.915382385253906, Accuracy: 0.7915\n",
      "Epoch 81, Train Loss: 163.3526153564453, Test Loss: 44.34626388549805, Accuracy: 0.7909\n",
      "Epoch 82, Train Loss: 164.3816375732422, Test Loss: 42.822837829589844, Accuracy: 0.7909\n",
      "Epoch 83, Train Loss: 159.10812377929688, Test Loss: 41.219295501708984, Accuracy: 0.7912\n",
      "Epoch 84, Train Loss: 155.433349609375, Test Loss: 39.508514404296875, Accuracy: 0.7916\n",
      "Epoch 85, Train Loss: 153.906005859375, Test Loss: 37.79426956176758, Accuracy: 0.7921\n",
      "Epoch 86, Train Loss: 152.9666290283203, Test Loss: 36.05882263183594, Accuracy: 0.7926\n",
      "Epoch 87, Train Loss: 146.85800170898438, Test Loss: 34.253318786621094, Accuracy: 0.7930\n",
      "Epoch 88, Train Loss: 147.3755340576172, Test Loss: 32.467491149902344, Accuracy: 0.7938\n",
      "Epoch 89, Train Loss: 147.39991760253906, Test Loss: 30.599721908569336, Accuracy: 0.7948\n",
      "Epoch 90, Train Loss: 143.45176696777344, Test Loss: 28.875946044921875, Accuracy: 0.7963\n",
      "Epoch 91, Train Loss: 141.32510375976562, Test Loss: 27.263090133666992, Accuracy: 0.7969\n",
      "Epoch 92, Train Loss: 138.1021270751953, Test Loss: 25.678403854370117, Accuracy: 0.7970\n",
      "Epoch 93, Train Loss: 138.57901000976562, Test Loss: 24.373985290527344, Accuracy: 0.7970\n",
      "Epoch 94, Train Loss: 136.49925231933594, Test Loss: 23.208126068115234, Accuracy: 0.7970\n",
      "Epoch 95, Train Loss: 134.84246826171875, Test Loss: 22.15054702758789, Accuracy: 0.7970\n",
      "Epoch 96, Train Loss: 133.1519012451172, Test Loss: 21.392908096313477, Accuracy: 0.7970\n",
      "Epoch 97, Train Loss: 128.97576904296875, Test Loss: 21.309627532958984, Accuracy: 0.7971\n",
      "Epoch 98, Train Loss: 125.7905044555664, Test Loss: 21.186635971069336, Accuracy: 0.7972\n",
      "Epoch 99, Train Loss: 129.0645294189453, Test Loss: 21.054418563842773, Accuracy: 0.7973\n",
      "Epoch 100, Train Loss: 120.7896499633789, Test Loss: 20.882991790771484, Accuracy: 0.7972\n",
      "Epoch 101, Train Loss: 123.1603775024414, Test Loss: 20.76456069946289, Accuracy: 0.7970\n",
      "Epoch 102, Train Loss: 120.02554321289062, Test Loss: 20.673137664794922, Accuracy: 0.7971\n",
      "Epoch 103, Train Loss: 116.61827850341797, Test Loss: 20.63623809814453, Accuracy: 0.7971\n",
      "Epoch 104, Train Loss: 116.44596099853516, Test Loss: 20.613792419433594, Accuracy: 0.7970\n",
      "Epoch 105, Train Loss: 116.18474578857422, Test Loss: 20.558340072631836, Accuracy: 0.7971\n",
      "Epoch 106, Train Loss: 115.08895874023438, Test Loss: 20.402254104614258, Accuracy: 0.7970\n",
      "Epoch 107, Train Loss: 113.81726837158203, Test Loss: 20.190793991088867, Accuracy: 0.7965\n",
      "Epoch 108, Train Loss: 111.9930419921875, Test Loss: 20.048603057861328, Accuracy: 0.7957\n",
      "Epoch 109, Train Loss: 106.15253448486328, Test Loss: 19.891035079956055, Accuracy: 0.7949\n",
      "Epoch 110, Train Loss: 106.2266616821289, Test Loss: 19.715652465820312, Accuracy: 0.7941\n",
      "Epoch 111, Train Loss: 101.90692138671875, Test Loss: 19.527904510498047, Accuracy: 0.7931\n",
      "Epoch 112, Train Loss: 101.3707504272461, Test Loss: 19.349367141723633, Accuracy: 0.7926\n",
      "Epoch 113, Train Loss: 101.31837463378906, Test Loss: 19.201194763183594, Accuracy: 0.7919\n",
      "Epoch 114, Train Loss: 100.55419158935547, Test Loss: 19.06572151184082, Accuracy: 0.7909\n",
      "Epoch 115, Train Loss: 98.07654571533203, Test Loss: 18.894325256347656, Accuracy: 0.7907\n",
      "Epoch 116, Train Loss: 95.33738708496094, Test Loss: 18.747610092163086, Accuracy: 0.7903\n",
      "Epoch 117, Train Loss: 92.98416137695312, Test Loss: 18.642839431762695, Accuracy: 0.7899\n",
      "Epoch 118, Train Loss: 91.47856903076172, Test Loss: 18.540185928344727, Accuracy: 0.7899\n",
      "Epoch 119, Train Loss: 89.7360610961914, Test Loss: 18.45320701599121, Accuracy: 0.7893\n",
      "Epoch 120, Train Loss: 87.63689422607422, Test Loss: 18.530366897583008, Accuracy: 0.7888\n",
      "Epoch 121, Train Loss: 87.5358657836914, Test Loss: 17.79203224182129, Accuracy: 0.7880\n",
      "Epoch 122, Train Loss: 85.34239959716797, Test Loss: 17.073272705078125, Accuracy: 0.7869\n",
      "Epoch 123, Train Loss: 82.16785430908203, Test Loss: 16.3320255279541, Accuracy: 0.7860\n",
      "Epoch 124, Train Loss: 81.60370635986328, Test Loss: 15.577617645263672, Accuracy: 0.7852\n",
      "Epoch 125, Train Loss: 81.26287841796875, Test Loss: 14.826416969299316, Accuracy: 0.7833\n",
      "Epoch 126, Train Loss: 76.36212158203125, Test Loss: 14.314136505126953, Accuracy: 0.7819\n",
      "Epoch 127, Train Loss: 75.98384094238281, Test Loss: 13.760132789611816, Accuracy: 0.7806\n",
      "Epoch 128, Train Loss: 74.10774230957031, Test Loss: 13.217881202697754, Accuracy: 0.7797\n",
      "Epoch 129, Train Loss: 71.04422760009766, Test Loss: 12.66073989868164, Accuracy: 0.7796\n",
      "Epoch 130, Train Loss: 68.95507049560547, Test Loss: 12.075937271118164, Accuracy: 0.7791\n",
      "Epoch 131, Train Loss: 69.31446838378906, Test Loss: 11.472393989562988, Accuracy: 0.7789\n",
      "Epoch 132, Train Loss: 66.26829528808594, Test Loss: 10.851408004760742, Accuracy: 0.7788\n",
      "Epoch 133, Train Loss: 63.1257209777832, Test Loss: 10.20910358428955, Accuracy: 0.7785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134, Train Loss: 62.255760192871094, Test Loss: 9.551285743713379, Accuracy: 0.7781\n",
      "Epoch 135, Train Loss: 60.64982223510742, Test Loss: 8.88645076751709, Accuracy: 0.7774\n",
      "Epoch 136, Train Loss: 58.64387893676758, Test Loss: 8.21922492980957, Accuracy: 0.7765\n",
      "Epoch 137, Train Loss: 56.807682037353516, Test Loss: 7.549966812133789, Accuracy: 0.7760\n",
      "Epoch 138, Train Loss: 54.48735046386719, Test Loss: 6.877563953399658, Accuracy: 0.7752\n",
      "Epoch 139, Train Loss: 54.73006820678711, Test Loss: 6.203871726989746, Accuracy: 0.7747\n",
      "Epoch 140, Train Loss: 52.14150619506836, Test Loss: 5.528780937194824, Accuracy: 0.7745\n",
      "Epoch 141, Train Loss: 50.30586242675781, Test Loss: 4.858811855316162, Accuracy: 0.7739\n",
      "Epoch 142, Train Loss: 49.39996337890625, Test Loss: 4.197208404541016, Accuracy: 0.7735\n",
      "Epoch 143, Train Loss: 48.05198669433594, Test Loss: 3.5508384704589844, Accuracy: 0.7733\n",
      "Epoch 144, Train Loss: 46.431434631347656, Test Loss: 2.9200618267059326, Accuracy: 0.7729\n",
      "Epoch 145, Train Loss: 42.785743713378906, Test Loss: 2.3118531703948975, Accuracy: 0.7725\n",
      "Epoch 146, Train Loss: 43.17310333251953, Test Loss: 1.7469040155410767, Accuracy: 0.7723\n",
      "Epoch 147, Train Loss: 41.335723876953125, Test Loss: 1.2420419454574585, Accuracy: 0.7720\n",
      "Epoch 148, Train Loss: 41.099647521972656, Test Loss: 0.8270798325538635, Accuracy: 0.7721\n",
      "Epoch 149, Train Loss: 39.09613800048828, Test Loss: 0.5779292583465576, Accuracy: 0.7719\n",
      "Epoch 150, Train Loss: 36.59505844116211, Test Loss: 0.6066498160362244, Accuracy: 0.7717\n",
      "Epoch 151, Train Loss: 36.59779357910156, Test Loss: 0.789912223815918, Accuracy: 0.3234\n",
      "Epoch 152, Train Loss: 35.19425582885742, Test Loss: 0.7561939358711243, Accuracy: 0.3637\n",
      "Epoch 153, Train Loss: 34.698394775390625, Test Loss: 0.5910705924034119, Accuracy: 0.7716\n",
      "Epoch 154, Train Loss: 34.119781494140625, Test Loss: 0.5718294978141785, Accuracy: 0.7716\n",
      "Epoch 155, Train Loss: 32.19254684448242, Test Loss: 0.6459349393844604, Accuracy: 0.7716\n",
      "Epoch 156, Train Loss: 30.593076705932617, Test Loss: 0.6973187327384949, Accuracy: 0.7716\n",
      "Epoch 157, Train Loss: 30.35809326171875, Test Loss: 0.6971696019172668, Accuracy: 0.7714\n",
      "Epoch 158, Train Loss: 28.619123458862305, Test Loss: 0.6511260867118835, Accuracy: 0.7713\n",
      "Epoch 159, Train Loss: 28.41945457458496, Test Loss: 0.583869457244873, Accuracy: 0.7711\n",
      "Epoch 160, Train Loss: 27.568145751953125, Test Loss: 0.5676155090332031, Accuracy: 0.7710\n",
      "Epoch 161, Train Loss: 26.76502227783203, Test Loss: 0.7133790850639343, Accuracy: 0.4534\n",
      "Epoch 162, Train Loss: 25.101898193359375, Test Loss: 0.9278994202613831, Accuracy: 0.2815\n",
      "Epoch 163, Train Loss: 23.981843948364258, Test Loss: 0.9809082746505737, Accuracy: 0.2761\n",
      "Epoch 164, Train Loss: 23.992780685424805, Test Loss: 0.8419466018676758, Accuracy: 0.3005\n",
      "Epoch 165, Train Loss: 22.54717254638672, Test Loss: 0.6481682658195496, Accuracy: 0.7627\n",
      "Epoch 166, Train Loss: 22.191478729248047, Test Loss: 0.5601814985275269, Accuracy: 0.7709\n",
      "Epoch 167, Train Loss: 22.071128845214844, Test Loss: 0.5512718558311462, Accuracy: 0.7707\n",
      "Epoch 168, Train Loss: 20.393936157226562, Test Loss: 0.554546594619751, Accuracy: 0.7707\n",
      "Epoch 169, Train Loss: 19.880558013916016, Test Loss: 0.549561083316803, Accuracy: 0.7706\n",
      "Epoch 170, Train Loss: 20.215545654296875, Test Loss: 0.5518594980239868, Accuracy: 0.7705\n",
      "Epoch 171, Train Loss: 19.686511993408203, Test Loss: 0.5916564464569092, Accuracy: 0.7704\n",
      "Epoch 172, Train Loss: 19.13502311706543, Test Loss: 0.6633480191230774, Accuracy: 0.7084\n",
      "Epoch 173, Train Loss: 17.59149932861328, Test Loss: 0.6912937164306641, Accuracy: 0.5430\n",
      "Epoch 174, Train Loss: 17.578155517578125, Test Loss: 0.6386558413505554, Accuracy: 0.7679\n",
      "Epoch 175, Train Loss: 16.761198043823242, Test Loss: 0.5764179825782776, Accuracy: 0.7702\n",
      "Epoch 176, Train Loss: 16.588115692138672, Test Loss: 0.5526741743087769, Accuracy: 0.7699\n",
      "Epoch 177, Train Loss: 16.02931785583496, Test Loss: 0.553169846534729, Accuracy: 0.7699\n",
      "Epoch 178, Train Loss: 15.14995002746582, Test Loss: 0.5560444593429565, Accuracy: 0.7698\n",
      "Epoch 179, Train Loss: 15.861178398132324, Test Loss: 0.5551894307136536, Accuracy: 0.7698\n",
      "Epoch 180, Train Loss: 15.247411727905273, Test Loss: 0.5541576743125916, Accuracy: 0.7698\n",
      "Epoch 181, Train Loss: 14.060811996459961, Test Loss: 0.5553527474403381, Accuracy: 0.7698\n",
      "Epoch 182, Train Loss: 13.689251899719238, Test Loss: 0.5563121438026428, Accuracy: 0.7698\n",
      "Epoch 183, Train Loss: 14.334988594055176, Test Loss: 0.5544903874397278, Accuracy: 0.7694\n",
      "Epoch 184, Train Loss: 13.04228401184082, Test Loss: 0.5527393817901611, Accuracy: 0.7693\n",
      "Epoch 185, Train Loss: 13.256599426269531, Test Loss: 0.5526083111763, Accuracy: 0.7693\n",
      "Epoch 186, Train Loss: 12.2587308883667, Test Loss: 0.5525391697883606, Accuracy: 0.7692\n",
      "Epoch 187, Train Loss: 11.781440734863281, Test Loss: 0.5509313941001892, Accuracy: 0.7689\n",
      "Epoch 188, Train Loss: 11.916407585144043, Test Loss: 0.5502185225486755, Accuracy: 0.7689\n",
      "Epoch 189, Train Loss: 11.029391288757324, Test Loss: 0.5569418668746948, Accuracy: 0.7689\n",
      "Epoch 190, Train Loss: 11.77745246887207, Test Loss: 0.5718570947647095, Accuracy: 0.7689\n",
      "Epoch 191, Train Loss: 11.232959747314453, Test Loss: 0.5849022269248962, Accuracy: 0.7689\n",
      "Epoch 192, Train Loss: 11.20583724975586, Test Loss: 0.5845834612846375, Accuracy: 0.7689\n",
      "Epoch 193, Train Loss: 10.32236385345459, Test Loss: 0.5727937817573547, Accuracy: 0.7689\n",
      "Epoch 194, Train Loss: 10.983613014221191, Test Loss: 0.5621229410171509, Accuracy: 0.7689\n",
      "Epoch 195, Train Loss: 10.25270938873291, Test Loss: 0.5572651624679565, Accuracy: 0.7689\n",
      "Epoch 196, Train Loss: 9.999334335327148, Test Loss: 0.5569385886192322, Accuracy: 0.7686\n",
      "Epoch 197, Train Loss: 9.708544731140137, Test Loss: 0.558681309223175, Accuracy: 0.7686\n",
      "Epoch 198, Train Loss: 9.405149459838867, Test Loss: 0.5630092024803162, Accuracy: 0.7686\n",
      "Epoch 199, Train Loss: 8.993413925170898, Test Loss: 0.5693245530128479, Accuracy: 0.7686\n",
      "Epoch 200, Train Loss: 9.167584419250488, Test Loss: 0.5736713409423828, Accuracy: 0.7686\n",
      "Optimizer: Adamax\n",
      "Final Test Accuracy: 0.7686\n",
      "Training Time: 10.46 seconds\n",
      "Final Train Loss: 9.1676\n",
      "Final Test Loss: 0.5737\n",
      "\n",
      "Training with optimizer: RMSprop\n",
      "Epoch 1, Train Loss: 948.2259521484375, Test Loss: 6411.35205078125, Accuracy: 0.2344\n",
      "Epoch 2, Train Loss: 6589.33154296875, Test Loss: 542.7969360351562, Accuracy: 0.7661\n",
      "Epoch 3, Train Loss: 742.5879516601562, Test Loss: 261.20489501953125, Accuracy: 0.7671\n",
      "Epoch 4, Train Loss: 654.679931640625, Test Loss: 414.3812561035156, Accuracy: 0.7671\n",
      "Epoch 5, Train Loss: 625.20751953125, Test Loss: 112.54144287109375, Accuracy: 0.7723\n",
      "Epoch 6, Train Loss: 629.9026489257812, Test Loss: 427.8366394042969, Accuracy: 0.7689\n",
      "Epoch 7, Train Loss: 597.1627197265625, Test Loss: 111.29034423828125, Accuracy: 0.7737\n",
      "Epoch 8, Train Loss: 532.7789306640625, Test Loss: 316.7554016113281, Accuracy: 0.7716\n",
      "Epoch 9, Train Loss: 503.4591064453125, Test Loss: 93.03184509277344, Accuracy: 0.7783\n",
      "Epoch 10, Train Loss: 473.9446105957031, Test Loss: 248.81871032714844, Accuracy: 0.7734\n",
      "Epoch 11, Train Loss: 440.25469970703125, Test Loss: 36.72454071044922, Accuracy: 0.7941\n",
      "Epoch 12, Train Loss: 422.66796875, Test Loss: 276.4242248535156, Accuracy: 0.7739\n",
      "Epoch 13, Train Loss: 418.1443176269531, Test Loss: 9.563726425170898, Accuracy: 0.7903\n",
      "Epoch 14, Train Loss: 396.8359375, Test Loss: 269.7919006347656, Accuracy: 0.7764\n",
      "Epoch 15, Train Loss: 385.59881591796875, Test Loss: 11.71755313873291, Accuracy: 0.7889\n",
      "Epoch 16, Train Loss: 344.39849853515625, Test Loss: 229.45997619628906, Accuracy: 0.7780\n",
      "Epoch 17, Train Loss: 341.72100830078125, Test Loss: 23.473323822021484, Accuracy: 0.7980\n",
      "Epoch 18, Train Loss: 294.5533447265625, Test Loss: 156.01014709472656, Accuracy: 0.7797\n",
      "Epoch 19, Train Loss: 276.1105041503906, Test Loss: 33.71137237548828, Accuracy: 0.8006\n",
      "Epoch 20, Train Loss: 254.1637725830078, Test Loss: 123.93550872802734, Accuracy: 0.7821\n",
      "Epoch 21, Train Loss: 237.4276123046875, Test Loss: 44.46266174316406, Accuracy: 0.7989\n",
      "Epoch 22, Train Loss: 217.13211059570312, Test Loss: 103.82787322998047, Accuracy: 0.7868\n",
      "Epoch 23, Train Loss: 209.04849243164062, Test Loss: 48.03184127807617, Accuracy: 0.7983\n",
      "Epoch 24, Train Loss: 194.93896484375, Test Loss: 80.39353942871094, Accuracy: 0.7899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Train Loss: 186.8887481689453, Test Loss: 38.392578125, Accuracy: 0.8004\n",
      "Epoch 26, Train Loss: 180.31752014160156, Test Loss: 66.21402740478516, Accuracy: 0.7935\n",
      "Epoch 27, Train Loss: 171.14903259277344, Test Loss: 35.32440948486328, Accuracy: 0.8007\n",
      "Epoch 28, Train Loss: 158.041748046875, Test Loss: 53.918006896972656, Accuracy: 0.7988\n",
      "Epoch 29, Train Loss: 147.10086059570312, Test Loss: 28.192951202392578, Accuracy: 0.7986\n",
      "Epoch 30, Train Loss: 146.39378356933594, Test Loss: 29.825580596923828, Accuracy: 0.7999\n",
      "Epoch 31, Train Loss: 134.9944305419922, Test Loss: 17.66129493713379, Accuracy: 0.7951\n",
      "Epoch 32, Train Loss: 130.45816040039062, Test Loss: 12.531068801879883, Accuracy: 0.7946\n",
      "Epoch 33, Train Loss: 122.77755737304688, Test Loss: 5.745822906494141, Accuracy: 0.7885\n",
      "Epoch 34, Train Loss: 117.47246551513672, Test Loss: 1.8054856061935425, Accuracy: 0.7877\n",
      "Epoch 35, Train Loss: 110.04212951660156, Test Loss: 0.9870339035987854, Accuracy: 0.7002\n",
      "Epoch 36, Train Loss: 106.20985412597656, Test Loss: 6.421971321105957, Accuracy: 0.2343\n",
      "Epoch 37, Train Loss: 99.0499267578125, Test Loss: 3.377366304397583, Accuracy: 0.2340\n",
      "Epoch 38, Train Loss: 95.1903076171875, Test Loss: 2.4626595973968506, Accuracy: 0.2333\n",
      "Epoch 39, Train Loss: 93.45612335205078, Test Loss: 0.6581201553344727, Accuracy: 0.7783\n",
      "Epoch 40, Train Loss: 85.28016662597656, Test Loss: 0.9270521998405457, Accuracy: 0.7975\n",
      "Epoch 41, Train Loss: 79.23974609375, Test Loss: 1.6545870304107666, Accuracy: 0.7775\n",
      "Epoch 42, Train Loss: 75.30081176757812, Test Loss: 1.7057377099990845, Accuracy: 0.7887\n",
      "Epoch 43, Train Loss: 70.93385314941406, Test Loss: 1.6531258821487427, Accuracy: 0.7868\n",
      "Epoch 44, Train Loss: 68.49136352539062, Test Loss: 1.0958513021469116, Accuracy: 0.7872\n",
      "Epoch 45, Train Loss: 63.91535186767578, Test Loss: 1.1583681106567383, Accuracy: 0.7835\n",
      "Epoch 46, Train Loss: 59.74321746826172, Test Loss: 0.6771504282951355, Accuracy: 0.7854\n",
      "Epoch 47, Train Loss: 56.728206634521484, Test Loss: 1.0311590433120728, Accuracy: 0.7793\n",
      "Epoch 48, Train Loss: 53.94679260253906, Test Loss: 0.566106915473938, Accuracy: 0.7764\n",
      "Epoch 49, Train Loss: 51.02592849731445, Test Loss: 1.029836893081665, Accuracy: 0.7784\n",
      "Epoch 50, Train Loss: 48.283599853515625, Test Loss: 1.5080041885375977, Accuracy: 0.2345\n",
      "Epoch 51, Train Loss: 45.43805694580078, Test Loss: 3.8978397846221924, Accuracy: 0.7723\n",
      "Epoch 52, Train Loss: 42.98184585571289, Test Loss: 1.0622210502624512, Accuracy: 0.7746\n",
      "Epoch 53, Train Loss: 40.83283996582031, Test Loss: 1.1772472858428955, Accuracy: 0.2344\n",
      "Epoch 54, Train Loss: 38.511043548583984, Test Loss: 4.646078109741211, Accuracy: 0.7714\n",
      "Epoch 55, Train Loss: 37.942752838134766, Test Loss: 1.421270728111267, Accuracy: 0.7732\n",
      "Epoch 56, Train Loss: 35.39369201660156, Test Loss: 1.3869317770004272, Accuracy: 0.2344\n",
      "Epoch 57, Train Loss: 32.06428527832031, Test Loss: 7.065062999725342, Accuracy: 0.7709\n",
      "Epoch 58, Train Loss: 34.85336685180664, Test Loss: 2.6392929553985596, Accuracy: 0.7717\n",
      "Epoch 59, Train Loss: 31.348190307617188, Test Loss: 0.7463665008544922, Accuracy: 0.2344\n",
      "Epoch 60, Train Loss: 27.13606834411621, Test Loss: 6.016531467437744, Accuracy: 0.7707\n",
      "Epoch 61, Train Loss: 31.091657638549805, Test Loss: 1.7399898767471313, Accuracy: 0.7717\n",
      "Epoch 62, Train Loss: 25.747339248657227, Test Loss: 2.991588592529297, Accuracy: 0.2344\n",
      "Epoch 63, Train Loss: 25.330299377441406, Test Loss: 8.501300811767578, Accuracy: 0.7705\n",
      "Epoch 64, Train Loss: 28.24943733215332, Test Loss: 4.0299906730651855, Accuracy: 0.7705\n",
      "Epoch 65, Train Loss: 23.68400764465332, Test Loss: 0.926604151725769, Accuracy: 0.7718\n",
      "Epoch 66, Train Loss: 21.629810333251953, Test Loss: 2.016997814178467, Accuracy: 0.2344\n",
      "Epoch 67, Train Loss: 21.311763763427734, Test Loss: 6.820472240447998, Accuracy: 0.7704\n",
      "Epoch 68, Train Loss: 24.30747413635254, Test Loss: 2.8087353706359863, Accuracy: 0.7704\n",
      "Epoch 69, Train Loss: 21.32866859436035, Test Loss: 0.9115211963653564, Accuracy: 0.2344\n",
      "Epoch 70, Train Loss: 18.717267990112305, Test Loss: 6.581145763397217, Accuracy: 0.7702\n",
      "Epoch 71, Train Loss: 21.33670425415039, Test Loss: 2.730051279067993, Accuracy: 0.7703\n",
      "Epoch 72, Train Loss: 18.227022171020508, Test Loss: 1.0880231857299805, Accuracy: 0.2344\n",
      "Epoch 73, Train Loss: 16.378643035888672, Test Loss: 6.3986430168151855, Accuracy: 0.7699\n",
      "Epoch 74, Train Loss: 20.125057220458984, Test Loss: 2.794095754623413, Accuracy: 0.7699\n",
      "Epoch 75, Train Loss: 16.6789608001709, Test Loss: 0.6795978546142578, Accuracy: 0.5687\n",
      "Epoch 76, Train Loss: 15.25951862335205, Test Loss: 3.7760746479034424, Accuracy: 0.7698\n",
      "Epoch 77, Train Loss: 17.287189483642578, Test Loss: 0.8136383295059204, Accuracy: 0.7711\n",
      "Epoch 78, Train Loss: 14.011910438537598, Test Loss: 4.08389949798584, Accuracy: 0.2344\n",
      "Epoch 79, Train Loss: 14.85468578338623, Test Loss: 7.147343635559082, Accuracy: 0.7695\n",
      "Epoch 80, Train Loss: 18.44879150390625, Test Loss: 3.917246103286743, Accuracy: 0.7697\n",
      "Epoch 81, Train Loss: 15.1974458694458, Test Loss: 1.3197228908538818, Accuracy: 0.7704\n",
      "Epoch 82, Train Loss: 12.140098571777344, Test Loss: 2.0384409427642822, Accuracy: 0.2344\n",
      "Epoch 83, Train Loss: 12.705522537231445, Test Loss: 6.137058734893799, Accuracy: 0.7693\n",
      "Epoch 84, Train Loss: 16.40346908569336, Test Loss: 3.4567346572875977, Accuracy: 0.7694\n",
      "Epoch 85, Train Loss: 13.499051094055176, Test Loss: 1.3012522459030151, Accuracy: 0.7701\n",
      "Epoch 86, Train Loss: 11.223552703857422, Test Loss: 1.5020747184753418, Accuracy: 0.2344\n",
      "Epoch 87, Train Loss: 11.04844856262207, Test Loss: 5.26671028137207, Accuracy: 0.7692\n",
      "Epoch 88, Train Loss: 14.237515449523926, Test Loss: 2.955301523208618, Accuracy: 0.7693\n",
      "Epoch 89, Train Loss: 12.104771614074707, Test Loss: 1.1093770265579224, Accuracy: 0.7701\n",
      "Epoch 90, Train Loss: 9.780167579650879, Test Loss: 1.5714759826660156, Accuracy: 0.2344\n",
      "Epoch 91, Train Loss: 10.223526954650879, Test Loss: 4.439096450805664, Accuracy: 0.7689\n",
      "Epoch 92, Train Loss: 12.399480819702148, Test Loss: 2.5239293575286865, Accuracy: 0.7689\n",
      "Epoch 93, Train Loss: 10.804417610168457, Test Loss: 0.9567626714706421, Accuracy: 0.7700\n",
      "Epoch 94, Train Loss: 9.312552452087402, Test Loss: 1.4130654335021973, Accuracy: 0.2344\n",
      "Epoch 95, Train Loss: 8.828340530395508, Test Loss: 3.5315206050872803, Accuracy: 0.7689\n",
      "Epoch 96, Train Loss: 10.871341705322266, Test Loss: 1.9556933641433716, Accuracy: 0.7689\n",
      "Epoch 97, Train Loss: 9.297118186950684, Test Loss: 0.7572815418243408, Accuracy: 0.7700\n",
      "Epoch 98, Train Loss: 7.739380359649658, Test Loss: 1.293742060661316, Accuracy: 0.2344\n",
      "Epoch 99, Train Loss: 7.993311405181885, Test Loss: 2.9144530296325684, Accuracy: 0.7689\n",
      "Epoch 100, Train Loss: 9.835813522338867, Test Loss: 1.5830938816070557, Accuracy: 0.7689\n",
      "Epoch 101, Train Loss: 8.450823783874512, Test Loss: 0.6336519122123718, Accuracy: 0.7698\n",
      "Epoch 102, Train Loss: 7.304532527923584, Test Loss: 1.103628158569336, Accuracy: 0.2344\n",
      "Epoch 103, Train Loss: 7.009594917297363, Test Loss: 2.145662546157837, Accuracy: 0.7689\n",
      "Epoch 104, Train Loss: 8.864767074584961, Test Loss: 1.0512348413467407, Accuracy: 0.7689\n",
      "Epoch 105, Train Loss: 6.640994071960449, Test Loss: 0.6368371844291687, Accuracy: 0.7091\n",
      "Epoch 106, Train Loss: 6.793442726135254, Test Loss: 0.5976186394691467, Accuracy: 0.7693\n",
      "Epoch 107, Train Loss: 5.974008560180664, Test Loss: 1.377948522567749, Accuracy: 0.2344\n",
      "Epoch 108, Train Loss: 7.251147747039795, Test Loss: 2.461515188217163, Accuracy: 0.7687\n",
      "Epoch 109, Train Loss: 8.012160301208496, Test Loss: 1.4208661317825317, Accuracy: 0.7689\n",
      "Epoch 110, Train Loss: 6.811182022094727, Test Loss: 0.6694143414497375, Accuracy: 0.7691\n",
      "Epoch 111, Train Loss: 6.201359272003174, Test Loss: 0.955118715763092, Accuracy: 0.2344\n",
      "Epoch 112, Train Loss: 5.9353227615356445, Test Loss: 1.7766658067703247, Accuracy: 0.7689\n",
      "Epoch 113, Train Loss: 7.248489856719971, Test Loss: 0.9687339067459106, Accuracy: 0.7689\n",
      "Epoch 114, Train Loss: 6.267452239990234, Test Loss: 0.5772976875305176, Accuracy: 0.7629\n",
      "Epoch 115, Train Loss: 5.527017593383789, Test Loss: 0.7570134997367859, Accuracy: 0.2344\n",
      "Epoch 116, Train Loss: 5.572991371154785, Test Loss: 0.8974591493606567, Accuracy: 0.7689\n",
      "Epoch 117, Train Loss: 5.8450212478637695, Test Loss: 0.5871496796607971, Accuracy: 0.7558\n",
      "Epoch 118, Train Loss: 5.265260696411133, Test Loss: 0.648874819278717, Accuracy: 0.6992\n",
      "Epoch 119, Train Loss: 4.914239406585693, Test Loss: 0.5744268298149109, Accuracy: 0.7663\n",
      "Epoch 120, Train Loss: 5.277442455291748, Test Loss: 0.9213383793830872, Accuracy: 0.2340\n",
      "Epoch 121, Train Loss: 4.932754039764404, Test Loss: 1.5286825895309448, Accuracy: 0.7689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122, Train Loss: 6.099297046661377, Test Loss: 0.8511362671852112, Accuracy: 0.7693\n",
      "Epoch 123, Train Loss: 5.394648551940918, Test Loss: 0.5893232822418213, Accuracy: 0.7571\n",
      "Epoch 124, Train Loss: 4.773256778717041, Test Loss: 0.7278364896774292, Accuracy: 0.2338\n",
      "Epoch 125, Train Loss: 4.380806922912598, Test Loss: 0.8199968934059143, Accuracy: 0.7694\n",
      "Epoch 126, Train Loss: 4.718324184417725, Test Loss: 0.5856209397315979, Accuracy: 0.7609\n",
      "Epoch 127, Train Loss: 4.582314968109131, Test Loss: 0.7355690598487854, Accuracy: 0.2332\n",
      "Epoch 128, Train Loss: 4.360190391540527, Test Loss: 0.8444464802742004, Accuracy: 0.7694\n",
      "Epoch 129, Train Loss: 4.890131950378418, Test Loss: 0.5764977335929871, Accuracy: 0.7668\n",
      "Epoch 130, Train Loss: 3.9412434101104736, Test Loss: 0.8287740349769592, Accuracy: 0.2334\n",
      "Epoch 131, Train Loss: 4.486932754516602, Test Loss: 1.0616182088851929, Accuracy: 0.7694\n",
      "Epoch 132, Train Loss: 4.919851779937744, Test Loss: 0.6240181922912598, Accuracy: 0.7701\n",
      "Epoch 133, Train Loss: 4.024606227874756, Test Loss: 0.6979013681411743, Accuracy: 0.3574\n",
      "Epoch 134, Train Loss: 3.9915595054626465, Test Loss: 0.6917250156402588, Accuracy: 0.7698\n",
      "Epoch 135, Train Loss: 4.2344560623168945, Test Loss: 0.6241903305053711, Accuracy: 0.7367\n",
      "Epoch 136, Train Loss: 3.8203091621398926, Test Loss: 0.6352632641792297, Accuracy: 0.7259\n",
      "Epoch 137, Train Loss: 3.8253486156463623, Test Loss: 0.5952737927436829, Accuracy: 0.7603\n",
      "Epoch 138, Train Loss: 3.797027826309204, Test Loss: 0.7027088403701782, Accuracy: 0.2829\n",
      "Epoch 139, Train Loss: 3.5804054737091064, Test Loss: 0.6347491145133972, Accuracy: 0.7700\n",
      "Epoch 140, Train Loss: 3.79514741897583, Test Loss: 0.6912312507629395, Accuracy: 0.4789\n",
      "Epoch 141, Train Loss: 3.6754751205444336, Test Loss: 0.6685202717781067, Accuracy: 0.7699\n",
      "Epoch 142, Train Loss: 3.6816248893737793, Test Loss: 0.6394968628883362, Accuracy: 0.7262\n",
      "Epoch 143, Train Loss: 3.470348834991455, Test Loss: 0.6036263108253479, Accuracy: 0.7591\n",
      "Epoch 144, Train Loss: 3.7170889377593994, Test Loss: 0.6858049035072327, Accuracy: 0.5700\n",
      "Epoch 145, Train Loss: 3.3307204246520996, Test Loss: 0.608686089515686, Accuracy: 0.7698\n",
      "Epoch 146, Train Loss: 3.607844114303589, Test Loss: 0.7031529545783997, Accuracy: 0.2573\n",
      "Epoch 147, Train Loss: 3.4663262367248535, Test Loss: 0.6319013237953186, Accuracy: 0.7700\n",
      "Epoch 148, Train Loss: 3.490417718887329, Test Loss: 0.6680810451507568, Accuracy: 0.6909\n",
      "Epoch 149, Train Loss: 3.450685977935791, Test Loss: 0.5902248620986938, Accuracy: 0.7702\n",
      "Epoch 150, Train Loss: 3.190408706665039, Test Loss: 0.7505231499671936, Accuracy: 0.2332\n",
      "Epoch 151, Train Loss: 3.282395601272583, Test Loss: 0.7050250172615051, Accuracy: 0.7701\n",
      "Epoch 152, Train Loss: 3.504497528076172, Test Loss: 0.5787538290023804, Accuracy: 0.7710\n",
      "Epoch 153, Train Loss: 3.1212570667266846, Test Loss: 0.7212175726890564, Accuracy: 0.2333\n",
      "Epoch 154, Train Loss: 3.005398988723755, Test Loss: 0.627305269241333, Accuracy: 0.7702\n",
      "Epoch 155, Train Loss: 3.2719552516937256, Test Loss: 0.6303257346153259, Accuracy: 0.7446\n",
      "Epoch 156, Train Loss: 2.9869227409362793, Test Loss: 0.5816019773483276, Accuracy: 0.7712\n",
      "Epoch 157, Train Loss: 3.039792537689209, Test Loss: 0.7833227515220642, Accuracy: 0.2335\n",
      "Epoch 158, Train Loss: 3.055478811264038, Test Loss: 0.7590677738189697, Accuracy: 0.7700\n",
      "Epoch 159, Train Loss: 3.3819518089294434, Test Loss: 0.5644062757492065, Accuracy: 0.7713\n",
      "Epoch 160, Train Loss: 3.1813838481903076, Test Loss: 0.6891118288040161, Accuracy: 0.5374\n",
      "Epoch 161, Train Loss: 2.9834647178649902, Test Loss: 0.5694258809089661, Accuracy: 0.7706\n",
      "Epoch 162, Train Loss: 3.130978584289551, Test Loss: 0.7124539017677307, Accuracy: 0.2338\n",
      "Epoch 163, Train Loss: 2.7409141063690186, Test Loss: 0.6483662724494934, Accuracy: 0.7703\n",
      "Epoch 164, Train Loss: 3.3215503692626953, Test Loss: 0.5787813663482666, Accuracy: 0.7719\n",
      "Epoch 165, Train Loss: 2.6218454837799072, Test Loss: 0.7487167716026306, Accuracy: 0.2336\n",
      "Epoch 166, Train Loss: 2.9716556072235107, Test Loss: 0.6687523722648621, Accuracy: 0.7705\n",
      "Epoch 167, Train Loss: 3.288611650466919, Test Loss: 0.5658175349235535, Accuracy: 0.7719\n",
      "Epoch 168, Train Loss: 2.5430798530578613, Test Loss: 0.6905346512794495, Accuracy: 0.5023\n",
      "Epoch 169, Train Loss: 2.5448105335235596, Test Loss: 0.562287449836731, Accuracy: 0.7719\n",
      "Epoch 170, Train Loss: 2.772576093673706, Test Loss: 0.7136930227279663, Accuracy: 0.2336\n",
      "Epoch 171, Train Loss: 2.524260997772217, Test Loss: 0.6132030487060547, Accuracy: 0.7711\n",
      "Epoch 172, Train Loss: 2.9716601371765137, Test Loss: 0.5857407450675964, Accuracy: 0.7729\n",
      "Epoch 173, Train Loss: 2.6390860080718994, Test Loss: 0.7106731534004211, Accuracy: 0.2339\n",
      "Epoch 174, Train Loss: 2.6602015495300293, Test Loss: 0.595731794834137, Accuracy: 0.7712\n",
      "Epoch 175, Train Loss: 2.9772942066192627, Test Loss: 0.5925391912460327, Accuracy: 0.7735\n",
      "Epoch 176, Train Loss: 2.868467330932617, Test Loss: 0.7065250277519226, Accuracy: 0.2336\n",
      "Epoch 177, Train Loss: 2.6037721633911133, Test Loss: 0.5832681059837341, Accuracy: 0.7715\n",
      "Epoch 178, Train Loss: 2.7020177841186523, Test Loss: 0.6015900373458862, Accuracy: 0.7736\n",
      "Epoch 179, Train Loss: 2.2178425788879395, Test Loss: 0.6987736225128174, Accuracy: 0.2335\n",
      "Epoch 180, Train Loss: 2.396810293197632, Test Loss: 0.5666020512580872, Accuracy: 0.7724\n",
      "Epoch 181, Train Loss: 2.6750922203063965, Test Loss: 0.6167855262756348, Accuracy: 0.7743\n",
      "Epoch 182, Train Loss: 2.0889739990234375, Test Loss: 0.6710060238838196, Accuracy: 0.7419\n",
      "Epoch 183, Train Loss: 2.5164308547973633, Test Loss: 0.5638895034790039, Accuracy: 0.7722\n",
      "Epoch 184, Train Loss: 2.5149805545806885, Test Loss: 0.6832383871078491, Accuracy: 0.7070\n",
      "Epoch 185, Train Loss: 2.198554754257202, Test Loss: 0.5595452189445496, Accuracy: 0.7722\n",
      "Epoch 186, Train Loss: 2.55025053024292, Test Loss: 0.6763629913330078, Accuracy: 0.7428\n",
      "Epoch 187, Train Loss: 2.205643892288208, Test Loss: 0.5588680505752563, Accuracy: 0.7723\n",
      "Epoch 188, Train Loss: 2.4580764770507812, Test Loss: 0.6577649712562561, Accuracy: 0.7761\n",
      "Epoch 189, Train Loss: 2.322239637374878, Test Loss: 0.5999046564102173, Accuracy: 0.7739\n",
      "Epoch 190, Train Loss: 2.2773072719573975, Test Loss: 0.697884738445282, Accuracy: 0.2331\n",
      "Epoch 191, Train Loss: 2.122147798538208, Test Loss: 0.5609538555145264, Accuracy: 0.7724\n",
      "Epoch 192, Train Loss: 2.4944841861724854, Test Loss: 0.6130508184432983, Accuracy: 0.7752\n",
      "Epoch 193, Train Loss: 2.2666609287261963, Test Loss: 0.6732786893844604, Accuracy: 0.7758\n",
      "Epoch 194, Train Loss: 2.0921778678894043, Test Loss: 0.5644922852516174, Accuracy: 0.7737\n",
      "Epoch 195, Train Loss: 2.22503924369812, Test Loss: 0.680840253829956, Accuracy: 0.7698\n",
      "Epoch 196, Train Loss: 1.8760581016540527, Test Loss: 0.5607795715332031, Accuracy: 0.7695\n",
      "Epoch 197, Train Loss: 2.1617519855499268, Test Loss: 0.665742814540863, Accuracy: 0.7698\n",
      "Epoch 198, Train Loss: 1.8047194480895996, Test Loss: 0.5715664029121399, Accuracy: 0.7693\n",
      "Epoch 199, Train Loss: 2.2649900913238525, Test Loss: 0.6906613707542419, Accuracy: 0.5832\n",
      "Epoch 200, Train Loss: 2.300584316253662, Test Loss: 0.5555921196937561, Accuracy: 0.7693\n",
      "Optimizer: RMSprop\n",
      "Final Test Accuracy: 0.7693\n",
      "Training Time: 9.89 seconds\n",
      "Final Train Loss: 2.3006\n",
      "Final Test Loss: 0.5556\n",
      "\n",
      "Training with optimizer: Adadelta\n",
      "Epoch 1, Train Loss: 6775.548828125, Test Loss: 6607.0224609375, Accuracy: 0.2344\n",
      "Epoch 2, Train Loss: 6794.92724609375, Test Loss: 6603.83544921875, Accuracy: 0.2344\n",
      "Epoch 3, Train Loss: 6784.14404296875, Test Loss: 6600.6044921875, Accuracy: 0.2344\n",
      "Epoch 4, Train Loss: 6747.9853515625, Test Loss: 6597.33154296875, Accuracy: 0.2344\n",
      "Epoch 5, Train Loss: 6759.35009765625, Test Loss: 6594.0205078125, Accuracy: 0.2344\n",
      "Epoch 6, Train Loss: 6767.876953125, Test Loss: 6590.67236328125, Accuracy: 0.2344\n",
      "Epoch 7, Train Loss: 6755.3779296875, Test Loss: 6587.30712890625, Accuracy: 0.2344\n",
      "Epoch 8, Train Loss: 6754.44580078125, Test Loss: 6583.91748046875, Accuracy: 0.2344\n",
      "Epoch 9, Train Loss: 6772.0673828125, Test Loss: 6580.49853515625, Accuracy: 0.2344\n",
      "Epoch 10, Train Loss: 6740.4091796875, Test Loss: 6577.06396484375, Accuracy: 0.2344\n",
      "Epoch 11, Train Loss: 6795.400390625, Test Loss: 6573.59326171875, Accuracy: 0.2344\n",
      "Epoch 12, Train Loss: 6770.3037109375, Test Loss: 6570.1123046875, Accuracy: 0.2344\n",
      "Epoch 13, Train Loss: 6743.6953125, Test Loss: 6566.61474609375, Accuracy: 0.2344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train Loss: 6755.21923828125, Test Loss: 6563.095703125, Accuracy: 0.2344\n",
      "Epoch 15, Train Loss: 6740.69189453125, Test Loss: 6559.5693359375, Accuracy: 0.2344\n",
      "Epoch 16, Train Loss: 6738.1318359375, Test Loss: 6556.0224609375, Accuracy: 0.2344\n",
      "Epoch 17, Train Loss: 6743.0126953125, Test Loss: 6552.46533203125, Accuracy: 0.2344\n",
      "Epoch 18, Train Loss: 6731.06201171875, Test Loss: 6548.89599609375, Accuracy: 0.2344\n",
      "Epoch 19, Train Loss: 6720.07275390625, Test Loss: 6545.3095703125, Accuracy: 0.2344\n",
      "Epoch 20, Train Loss: 6715.7998046875, Test Loss: 6541.7119140625, Accuracy: 0.2344\n",
      "Epoch 21, Train Loss: 6725.6416015625, Test Loss: 6538.09423828125, Accuracy: 0.2344\n",
      "Epoch 22, Train Loss: 6719.87060546875, Test Loss: 6534.45703125, Accuracy: 0.2344\n",
      "Epoch 23, Train Loss: 6707.2119140625, Test Loss: 6530.81396484375, Accuracy: 0.2344\n",
      "Epoch 24, Train Loss: 6703.30712890625, Test Loss: 6527.158203125, Accuracy: 0.2344\n",
      "Epoch 25, Train Loss: 6713.77783203125, Test Loss: 6523.49267578125, Accuracy: 0.2344\n",
      "Epoch 26, Train Loss: 6718.732421875, Test Loss: 6519.89208984375, Accuracy: 0.2344\n",
      "Epoch 27, Train Loss: 6700.22802734375, Test Loss: 6516.4462890625, Accuracy: 0.2344\n",
      "Epoch 28, Train Loss: 6691.01708984375, Test Loss: 6512.994140625, Accuracy: 0.2344\n",
      "Epoch 29, Train Loss: 6698.11865234375, Test Loss: 6509.52197265625, Accuracy: 0.2344\n",
      "Epoch 30, Train Loss: 6671.5341796875, Test Loss: 6506.04296875, Accuracy: 0.2344\n",
      "Epoch 31, Train Loss: 6690.2568359375, Test Loss: 6502.5556640625, Accuracy: 0.2344\n",
      "Epoch 32, Train Loss: 6659.78076171875, Test Loss: 6499.0654296875, Accuracy: 0.2344\n",
      "Epoch 33, Train Loss: 6687.72216796875, Test Loss: 6495.552734375, Accuracy: 0.2344\n",
      "Epoch 34, Train Loss: 6684.6328125, Test Loss: 6492.02490234375, Accuracy: 0.2344\n",
      "Epoch 35, Train Loss: 6651.24365234375, Test Loss: 6488.50732421875, Accuracy: 0.2344\n",
      "Epoch 36, Train Loss: 6658.18798828125, Test Loss: 6484.97119140625, Accuracy: 0.2344\n",
      "Epoch 37, Train Loss: 6682.06640625, Test Loss: 6481.4189453125, Accuracy: 0.2344\n",
      "Epoch 38, Train Loss: 6672.32763671875, Test Loss: 6477.85400390625, Accuracy: 0.2344\n",
      "Epoch 39, Train Loss: 6645.0908203125, Test Loss: 6474.27978515625, Accuracy: 0.2344\n",
      "Epoch 40, Train Loss: 6675.2333984375, Test Loss: 6470.68017578125, Accuracy: 0.2344\n",
      "Epoch 41, Train Loss: 6628.74609375, Test Loss: 6467.0908203125, Accuracy: 0.2344\n",
      "Epoch 42, Train Loss: 6631.98193359375, Test Loss: 6463.4833984375, Accuracy: 0.2344\n",
      "Epoch 43, Train Loss: 6652.2353515625, Test Loss: 6459.857421875, Accuracy: 0.2344\n",
      "Epoch 44, Train Loss: 6636.19482421875, Test Loss: 6456.224609375, Accuracy: 0.2344\n",
      "Epoch 45, Train Loss: 6654.8134765625, Test Loss: 6452.57080078125, Accuracy: 0.2344\n",
      "Epoch 46, Train Loss: 6646.1494140625, Test Loss: 6448.9072265625, Accuracy: 0.2344\n",
      "Epoch 47, Train Loss: 6643.904296875, Test Loss: 6445.234375, Accuracy: 0.2344\n",
      "Epoch 48, Train Loss: 6610.83056640625, Test Loss: 6441.55859375, Accuracy: 0.2344\n",
      "Epoch 49, Train Loss: 6620.75439453125, Test Loss: 6437.873046875, Accuracy: 0.2344\n",
      "Epoch 50, Train Loss: 6645.62451171875, Test Loss: 6434.1689453125, Accuracy: 0.2344\n",
      "Epoch 51, Train Loss: 6640.57470703125, Test Loss: 6430.451171875, Accuracy: 0.2344\n",
      "Epoch 52, Train Loss: 6627.33935546875, Test Loss: 6426.724609375, Accuracy: 0.2344\n",
      "Epoch 53, Train Loss: 6598.15283203125, Test Loss: 6422.99755859375, Accuracy: 0.2344\n",
      "Epoch 54, Train Loss: 6612.79931640625, Test Loss: 6419.2587890625, Accuracy: 0.2344\n",
      "Epoch 55, Train Loss: 6614.6884765625, Test Loss: 6415.509765625, Accuracy: 0.2344\n",
      "Epoch 56, Train Loss: 6609.6806640625, Test Loss: 6411.75244140625, Accuracy: 0.2344\n",
      "Epoch 57, Train Loss: 6601.49853515625, Test Loss: 6407.97900390625, Accuracy: 0.2344\n",
      "Epoch 58, Train Loss: 6583.6416015625, Test Loss: 6404.1943359375, Accuracy: 0.2344\n",
      "Epoch 59, Train Loss: 6611.31689453125, Test Loss: 6400.39453125, Accuracy: 0.2344\n",
      "Epoch 60, Train Loss: 6593.9833984375, Test Loss: 6396.5869140625, Accuracy: 0.2344\n",
      "Epoch 61, Train Loss: 6560.291015625, Test Loss: 6392.78759765625, Accuracy: 0.2344\n",
      "Epoch 62, Train Loss: 6598.5205078125, Test Loss: 6388.95751953125, Accuracy: 0.2344\n",
      "Epoch 63, Train Loss: 6582.568359375, Test Loss: 6385.12060546875, Accuracy: 0.2344\n",
      "Epoch 64, Train Loss: 6565.42431640625, Test Loss: 6381.28955078125, Accuracy: 0.2344\n",
      "Epoch 65, Train Loss: 6584.337890625, Test Loss: 6377.4482421875, Accuracy: 0.2344\n",
      "Epoch 66, Train Loss: 6561.51025390625, Test Loss: 6373.5927734375, Accuracy: 0.2344\n",
      "Epoch 67, Train Loss: 6554.47802734375, Test Loss: 6369.736328125, Accuracy: 0.2344\n",
      "Epoch 68, Train Loss: 6561.74951171875, Test Loss: 6365.85498046875, Accuracy: 0.2344\n",
      "Epoch 69, Train Loss: 6549.3974609375, Test Loss: 6361.96630859375, Accuracy: 0.2344\n",
      "Epoch 70, Train Loss: 6554.763671875, Test Loss: 6358.07080078125, Accuracy: 0.2344\n",
      "Epoch 71, Train Loss: 6560.52392578125, Test Loss: 6354.154296875, Accuracy: 0.2344\n",
      "Epoch 72, Train Loss: 6540.7568359375, Test Loss: 6350.23583984375, Accuracy: 0.2344\n",
      "Epoch 73, Train Loss: 6545.45263671875, Test Loss: 6346.30419921875, Accuracy: 0.2344\n",
      "Epoch 74, Train Loss: 6520.65625, Test Loss: 6342.36669921875, Accuracy: 0.2344\n",
      "Epoch 75, Train Loss: 6548.69921875, Test Loss: 6338.40673828125, Accuracy: 0.2344\n",
      "Epoch 76, Train Loss: 6551.95263671875, Test Loss: 6334.44287109375, Accuracy: 0.2344\n",
      "Epoch 77, Train Loss: 6520.1875, Test Loss: 6330.4755859375, Accuracy: 0.2344\n",
      "Epoch 78, Train Loss: 6526.794921875, Test Loss: 6326.49609375, Accuracy: 0.2344\n",
      "Epoch 79, Train Loss: 6537.8837890625, Test Loss: 6322.49853515625, Accuracy: 0.2344\n",
      "Epoch 80, Train Loss: 6524.36083984375, Test Loss: 6318.48681640625, Accuracy: 0.2344\n",
      "Epoch 81, Train Loss: 6504.6259765625, Test Loss: 6314.482421875, Accuracy: 0.2344\n",
      "Epoch 82, Train Loss: 6505.5703125, Test Loss: 6310.46484375, Accuracy: 0.2344\n",
      "Epoch 83, Train Loss: 6512.28271484375, Test Loss: 6306.44140625, Accuracy: 0.2344\n",
      "Epoch 84, Train Loss: 6465.21044921875, Test Loss: 6302.41455078125, Accuracy: 0.2344\n",
      "Epoch 85, Train Loss: 6500.17236328125, Test Loss: 6298.373046875, Accuracy: 0.2344\n",
      "Epoch 86, Train Loss: 6490.79736328125, Test Loss: 6294.33251953125, Accuracy: 0.2344\n",
      "Epoch 87, Train Loss: 6484.0830078125, Test Loss: 6290.28125, Accuracy: 0.2344\n",
      "Epoch 88, Train Loss: 6445.02978515625, Test Loss: 6286.228515625, Accuracy: 0.2344\n",
      "Epoch 89, Train Loss: 6481.21728515625, Test Loss: 6282.1552734375, Accuracy: 0.2344\n",
      "Epoch 90, Train Loss: 6453.2109375, Test Loss: 6278.0712890625, Accuracy: 0.2344\n",
      "Epoch 91, Train Loss: 6486.88330078125, Test Loss: 6273.95703125, Accuracy: 0.2344\n",
      "Epoch 92, Train Loss: 6476.95458984375, Test Loss: 6269.84765625, Accuracy: 0.2344\n",
      "Epoch 93, Train Loss: 6478.1533203125, Test Loss: 6265.7197265625, Accuracy: 0.2344\n",
      "Epoch 94, Train Loss: 6487.498046875, Test Loss: 6261.5830078125, Accuracy: 0.2344\n",
      "Epoch 95, Train Loss: 6451.48779296875, Test Loss: 6257.4521484375, Accuracy: 0.2344\n",
      "Epoch 96, Train Loss: 6473.6884765625, Test Loss: 6253.2978515625, Accuracy: 0.2344\n",
      "Epoch 97, Train Loss: 6455.23095703125, Test Loss: 6249.12890625, Accuracy: 0.2344\n",
      "Epoch 98, Train Loss: 6442.70751953125, Test Loss: 6244.9697265625, Accuracy: 0.2344\n",
      "Epoch 99, Train Loss: 6454.919921875, Test Loss: 6240.79345703125, Accuracy: 0.2344\n",
      "Epoch 100, Train Loss: 6447.58984375, Test Loss: 6236.59912109375, Accuracy: 0.2344\n",
      "Epoch 101, Train Loss: 6425.103515625, Test Loss: 6232.40771484375, Accuracy: 0.2344\n",
      "Epoch 102, Train Loss: 6427.734375, Test Loss: 6228.2138671875, Accuracy: 0.2344\n",
      "Epoch 103, Train Loss: 6429.45458984375, Test Loss: 6223.99853515625, Accuracy: 0.2344\n",
      "Epoch 104, Train Loss: 6421.24658203125, Test Loss: 6219.78662109375, Accuracy: 0.2344\n",
      "Epoch 105, Train Loss: 6416.216796875, Test Loss: 6215.5712890625, Accuracy: 0.2344\n",
      "Epoch 106, Train Loss: 6436.298828125, Test Loss: 6211.333984375, Accuracy: 0.2344\n",
      "Epoch 107, Train Loss: 6397.33056640625, Test Loss: 6207.095703125, Accuracy: 0.2344\n",
      "Epoch 108, Train Loss: 6392.19482421875, Test Loss: 6202.83837890625, Accuracy: 0.2344\n",
      "Epoch 109, Train Loss: 6415.140625, Test Loss: 6198.578125, Accuracy: 0.2344\n",
      "Epoch 110, Train Loss: 6415.318359375, Test Loss: 6194.32373046875, Accuracy: 0.2344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111, Train Loss: 6423.755859375, Test Loss: 6190.0400390625, Accuracy: 0.2344\n",
      "Epoch 112, Train Loss: 6393.76611328125, Test Loss: 6185.7724609375, Accuracy: 0.2344\n",
      "Epoch 113, Train Loss: 6350.8388671875, Test Loss: 6181.50146484375, Accuracy: 0.2344\n",
      "Epoch 114, Train Loss: 6385.6591796875, Test Loss: 6177.19921875, Accuracy: 0.2344\n",
      "Epoch 115, Train Loss: 6374.3173828125, Test Loss: 6172.88916015625, Accuracy: 0.2344\n",
      "Epoch 116, Train Loss: 6367.00634765625, Test Loss: 6168.5693359375, Accuracy: 0.2344\n",
      "Epoch 117, Train Loss: 6361.12744140625, Test Loss: 6164.23681640625, Accuracy: 0.2344\n",
      "Epoch 118, Train Loss: 6352.68017578125, Test Loss: 6159.9072265625, Accuracy: 0.2344\n",
      "Epoch 119, Train Loss: 6339.98876953125, Test Loss: 6155.564453125, Accuracy: 0.2344\n",
      "Epoch 120, Train Loss: 6342.76513671875, Test Loss: 6151.21435546875, Accuracy: 0.2344\n",
      "Epoch 121, Train Loss: 6343.62890625, Test Loss: 6146.8544921875, Accuracy: 0.2344\n",
      "Epoch 122, Train Loss: 6353.7978515625, Test Loss: 6142.48193359375, Accuracy: 0.2344\n",
      "Epoch 123, Train Loss: 6344.97607421875, Test Loss: 6138.10107421875, Accuracy: 0.2344\n",
      "Epoch 124, Train Loss: 6363.70751953125, Test Loss: 6133.70556640625, Accuracy: 0.2344\n",
      "Epoch 125, Train Loss: 6312.51513671875, Test Loss: 6129.318359375, Accuracy: 0.2344\n",
      "Epoch 126, Train Loss: 6335.21435546875, Test Loss: 6124.9013671875, Accuracy: 0.2344\n",
      "Epoch 127, Train Loss: 6308.8837890625, Test Loss: 6120.4921875, Accuracy: 0.2344\n",
      "Epoch 128, Train Loss: 6311.19482421875, Test Loss: 6116.07958984375, Accuracy: 0.2344\n",
      "Epoch 129, Train Loss: 6309.78173828125, Test Loss: 6111.66650390625, Accuracy: 0.2344\n",
      "Epoch 130, Train Loss: 6291.6630859375, Test Loss: 6107.24560546875, Accuracy: 0.2344\n",
      "Epoch 131, Train Loss: 6305.98828125, Test Loss: 6102.80126953125, Accuracy: 0.2344\n",
      "Epoch 132, Train Loss: 6305.42333984375, Test Loss: 6098.34716796875, Accuracy: 0.2344\n",
      "Epoch 133, Train Loss: 6273.17822265625, Test Loss: 6093.900390625, Accuracy: 0.2344\n",
      "Epoch 134, Train Loss: 6299.7763671875, Test Loss: 6089.4267578125, Accuracy: 0.2344\n",
      "Epoch 135, Train Loss: 6271.67333984375, Test Loss: 6084.95458984375, Accuracy: 0.2344\n",
      "Epoch 136, Train Loss: 6303.87744140625, Test Loss: 6080.458984375, Accuracy: 0.2344\n",
      "Epoch 137, Train Loss: 6286.4013671875, Test Loss: 6075.951171875, Accuracy: 0.2344\n",
      "Epoch 138, Train Loss: 6254.69287109375, Test Loss: 6071.46630859375, Accuracy: 0.2344\n",
      "Epoch 139, Train Loss: 6260.97509765625, Test Loss: 6066.96728515625, Accuracy: 0.2344\n",
      "Epoch 140, Train Loss: 6283.86181640625, Test Loss: 6062.44970703125, Accuracy: 0.2344\n",
      "Epoch 141, Train Loss: 6270.79541015625, Test Loss: 6057.9228515625, Accuracy: 0.2344\n",
      "Epoch 142, Train Loss: 6282.68359375, Test Loss: 6053.3779296875, Accuracy: 0.2344\n",
      "Epoch 143, Train Loss: 6252.611328125, Test Loss: 6048.84033203125, Accuracy: 0.2344\n",
      "Epoch 144, Train Loss: 6256.5966796875, Test Loss: 6044.29052734375, Accuracy: 0.2344\n",
      "Epoch 145, Train Loss: 6248.47265625, Test Loss: 6039.7255859375, Accuracy: 0.2344\n",
      "Epoch 146, Train Loss: 6244.5771484375, Test Loss: 6035.1572265625, Accuracy: 0.2344\n",
      "Epoch 147, Train Loss: 6245.72119140625, Test Loss: 6030.57763671875, Accuracy: 0.2344\n",
      "Epoch 148, Train Loss: 6207.03076171875, Test Loss: 6026.0126953125, Accuracy: 0.2344\n",
      "Epoch 149, Train Loss: 6246.14697265625, Test Loss: 6021.41357421875, Accuracy: 0.2344\n",
      "Epoch 150, Train Loss: 6218.8046875, Test Loss: 6016.82421875, Accuracy: 0.2344\n",
      "Epoch 151, Train Loss: 6220.876953125, Test Loss: 6012.20654296875, Accuracy: 0.2344\n",
      "Epoch 152, Train Loss: 6213.119140625, Test Loss: 6007.5830078125, Accuracy: 0.2344\n",
      "Epoch 153, Train Loss: 6212.87939453125, Test Loss: 6002.955078125, Accuracy: 0.2344\n",
      "Epoch 154, Train Loss: 6219.798828125, Test Loss: 5998.32421875, Accuracy: 0.2344\n",
      "Epoch 155, Train Loss: 6224.26953125, Test Loss: 5993.6796875, Accuracy: 0.2344\n",
      "Epoch 156, Train Loss: 6189.89794921875, Test Loss: 5989.03515625, Accuracy: 0.2344\n",
      "Epoch 157, Train Loss: 6195.03271484375, Test Loss: 5984.36279296875, Accuracy: 0.2344\n",
      "Epoch 158, Train Loss: 6207.0380859375, Test Loss: 5979.69677734375, Accuracy: 0.2344\n",
      "Epoch 159, Train Loss: 6169.8447265625, Test Loss: 5975.04248046875, Accuracy: 0.2344\n",
      "Epoch 160, Train Loss: 6197.81201171875, Test Loss: 5970.3681640625, Accuracy: 0.2344\n",
      "Epoch 161, Train Loss: 6172.3916015625, Test Loss: 5965.66357421875, Accuracy: 0.2344\n",
      "Epoch 162, Train Loss: 6184.6298828125, Test Loss: 5960.97216796875, Accuracy: 0.2344\n",
      "Epoch 163, Train Loss: 6160.68359375, Test Loss: 5956.267578125, Accuracy: 0.2344\n",
      "Epoch 164, Train Loss: 6171.14208984375, Test Loss: 5951.568359375, Accuracy: 0.2344\n",
      "Epoch 165, Train Loss: 6178.64306640625, Test Loss: 5946.84130859375, Accuracy: 0.2344\n",
      "Epoch 166, Train Loss: 6145.6279296875, Test Loss: 5942.10546875, Accuracy: 0.2344\n",
      "Epoch 167, Train Loss: 6157.6015625, Test Loss: 5937.36962890625, Accuracy: 0.2344\n",
      "Epoch 168, Train Loss: 6160.82177734375, Test Loss: 5932.607421875, Accuracy: 0.2344\n",
      "Epoch 169, Train Loss: 6113.09033203125, Test Loss: 5927.86279296875, Accuracy: 0.2344\n",
      "Epoch 170, Train Loss: 6152.02783203125, Test Loss: 5923.1005859375, Accuracy: 0.2344\n",
      "Epoch 171, Train Loss: 6128.94775390625, Test Loss: 5918.34765625, Accuracy: 0.2344\n",
      "Epoch 172, Train Loss: 6135.65673828125, Test Loss: 5913.57958984375, Accuracy: 0.2344\n",
      "Epoch 173, Train Loss: 6110.46875, Test Loss: 5908.80810546875, Accuracy: 0.2344\n",
      "Epoch 174, Train Loss: 6102.28173828125, Test Loss: 5904.021484375, Accuracy: 0.2344\n",
      "Epoch 175, Train Loss: 6106.150390625, Test Loss: 5899.23828125, Accuracy: 0.2344\n",
      "Epoch 176, Train Loss: 6115.2392578125, Test Loss: 5894.42529296875, Accuracy: 0.2344\n",
      "Epoch 177, Train Loss: 6100.63818359375, Test Loss: 5889.60986328125, Accuracy: 0.2344\n",
      "Epoch 178, Train Loss: 6140.33544921875, Test Loss: 5884.78369140625, Accuracy: 0.2344\n",
      "Epoch 179, Train Loss: 6088.8466796875, Test Loss: 5879.96044921875, Accuracy: 0.2344\n",
      "Epoch 180, Train Loss: 6086.3896484375, Test Loss: 5875.126953125, Accuracy: 0.2344\n",
      "Epoch 181, Train Loss: 6079.83203125, Test Loss: 5870.30224609375, Accuracy: 0.2344\n",
      "Epoch 182, Train Loss: 6098.2744140625, Test Loss: 5865.44189453125, Accuracy: 0.2344\n",
      "Epoch 183, Train Loss: 6088.05419921875, Test Loss: 5860.59130859375, Accuracy: 0.2344\n",
      "Epoch 184, Train Loss: 6073.68359375, Test Loss: 5855.751953125, Accuracy: 0.2344\n",
      "Epoch 185, Train Loss: 6062.3359375, Test Loss: 5850.88525390625, Accuracy: 0.2344\n",
      "Epoch 186, Train Loss: 6055.7890625, Test Loss: 5846.0078125, Accuracy: 0.2344\n",
      "Epoch 187, Train Loss: 6058.26611328125, Test Loss: 5841.13232421875, Accuracy: 0.2344\n",
      "Epoch 188, Train Loss: 6063.6484375, Test Loss: 5836.25, Accuracy: 0.2344\n",
      "Epoch 189, Train Loss: 6081.62890625, Test Loss: 5831.33935546875, Accuracy: 0.2344\n",
      "Epoch 190, Train Loss: 6057.26025390625, Test Loss: 5826.42626953125, Accuracy: 0.2344\n",
      "Epoch 191, Train Loss: 6028.5498046875, Test Loss: 5821.5185546875, Accuracy: 0.2344\n",
      "Epoch 192, Train Loss: 6047.86083984375, Test Loss: 5816.5849609375, Accuracy: 0.2344\n",
      "Epoch 193, Train Loss: 6038.4072265625, Test Loss: 5811.65625, Accuracy: 0.2344\n",
      "Epoch 194, Train Loss: 5986.18408203125, Test Loss: 5806.7412109375, Accuracy: 0.2344\n",
      "Epoch 195, Train Loss: 6030.1083984375, Test Loss: 5801.79638671875, Accuracy: 0.2344\n",
      "Epoch 196, Train Loss: 6021.53955078125, Test Loss: 5796.8603515625, Accuracy: 0.2344\n",
      "Epoch 197, Train Loss: 6021.08251953125, Test Loss: 5791.90771484375, Accuracy: 0.2344\n",
      "Epoch 198, Train Loss: 6020.59033203125, Test Loss: 5786.958984375, Accuracy: 0.2344\n",
      "Epoch 199, Train Loss: 6011.72021484375, Test Loss: 5781.98486328125, Accuracy: 0.2344\n",
      "Epoch 200, Train Loss: 5985.7900390625, Test Loss: 5777.01953125, Accuracy: 0.2344\n",
      "Optimizer: Adadelta\n",
      "Final Test Accuracy: 0.2344\n",
      "Training Time: 10.47 seconds\n",
      "Final Train Loss: 5985.7900\n",
      "Final Test Loss: 5777.0195\n",
      "\n",
      "Training with optimizer: Nadam\n",
      "Epoch 1, Train Loss: 1030.9312744140625, Test Loss: 166.8414306640625, Accuracy: 0.7657\n",
      "Epoch 2, Train Loss: 776.5370483398438, Test Loss: 267.6307067871094, Accuracy: 0.7657\n",
      "Epoch 3, Train Loss: 684.9000854492188, Test Loss: 330.794677734375, Accuracy: 0.7657\n",
      "Epoch 4, Train Loss: 647.091552734375, Test Loss: 376.6369323730469, Accuracy: 0.7658\n",
      "Epoch 5, Train Loss: 605.0469360351562, Test Loss: 398.950927734375, Accuracy: 0.7658\n",
      "Epoch 6, Train Loss: 591.1319580078125, Test Loss: 411.7062072753906, Accuracy: 0.7659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 569.7258911132812, Test Loss: 412.31256103515625, Accuracy: 0.7659\n",
      "Epoch 8, Train Loss: 555.1062622070312, Test Loss: 404.96929931640625, Accuracy: 0.7661\n",
      "Epoch 9, Train Loss: 524.7977294921875, Test Loss: 387.9916076660156, Accuracy: 0.7661\n",
      "Epoch 10, Train Loss: 498.5072937011719, Test Loss: 370.14813232421875, Accuracy: 0.7664\n",
      "Epoch 11, Train Loss: 473.72564697265625, Test Loss: 347.9034423828125, Accuracy: 0.7670\n",
      "Epoch 12, Train Loss: 464.1806945800781, Test Loss: 326.36834716796875, Accuracy: 0.7678\n",
      "Epoch 13, Train Loss: 434.1370849609375, Test Loss: 298.0254821777344, Accuracy: 0.7680\n",
      "Epoch 14, Train Loss: 409.2530517578125, Test Loss: 265.67724609375, Accuracy: 0.7682\n",
      "Epoch 15, Train Loss: 397.9288635253906, Test Loss: 235.9463653564453, Accuracy: 0.7685\n",
      "Epoch 16, Train Loss: 371.743408203125, Test Loss: 206.45437622070312, Accuracy: 0.7686\n",
      "Epoch 17, Train Loss: 353.7148132324219, Test Loss: 180.12850952148438, Accuracy: 0.7689\n",
      "Epoch 18, Train Loss: 334.8004150390625, Test Loss: 159.59646606445312, Accuracy: 0.7695\n",
      "Epoch 19, Train Loss: 316.56011962890625, Test Loss: 146.2117919921875, Accuracy: 0.7700\n",
      "Epoch 20, Train Loss: 305.27081298828125, Test Loss: 134.38748168945312, Accuracy: 0.7705\n",
      "Epoch 21, Train Loss: 290.4088134765625, Test Loss: 124.54039764404297, Accuracy: 0.7711\n",
      "Epoch 22, Train Loss: 275.7483215332031, Test Loss: 115.64771270751953, Accuracy: 0.7716\n",
      "Epoch 23, Train Loss: 259.6781921386719, Test Loss: 110.65389251708984, Accuracy: 0.7718\n",
      "Epoch 24, Train Loss: 250.77127075195312, Test Loss: 103.87188720703125, Accuracy: 0.7722\n",
      "Epoch 25, Train Loss: 239.1673583984375, Test Loss: 98.03255462646484, Accuracy: 0.7723\n",
      "Epoch 26, Train Loss: 228.9521942138672, Test Loss: 92.9177017211914, Accuracy: 0.7729\n",
      "Epoch 27, Train Loss: 219.61700439453125, Test Loss: 84.57530975341797, Accuracy: 0.7732\n",
      "Epoch 28, Train Loss: 207.92076110839844, Test Loss: 79.21340942382812, Accuracy: 0.7734\n",
      "Epoch 29, Train Loss: 197.98779296875, Test Loss: 75.00276184082031, Accuracy: 0.7737\n",
      "Epoch 30, Train Loss: 191.71482849121094, Test Loss: 69.4319839477539, Accuracy: 0.7739\n",
      "Epoch 31, Train Loss: 183.4105987548828, Test Loss: 64.00574493408203, Accuracy: 0.7746\n",
      "Epoch 32, Train Loss: 175.05880737304688, Test Loss: 60.00355529785156, Accuracy: 0.7755\n",
      "Epoch 33, Train Loss: 167.80511474609375, Test Loss: 55.9749641418457, Accuracy: 0.7766\n",
      "Epoch 34, Train Loss: 158.06036376953125, Test Loss: 52.14176559448242, Accuracy: 0.7780\n",
      "Epoch 35, Train Loss: 152.122802734375, Test Loss: 47.02521514892578, Accuracy: 0.7788\n",
      "Epoch 36, Train Loss: 142.6082000732422, Test Loss: 42.36476516723633, Accuracy: 0.7789\n",
      "Epoch 37, Train Loss: 140.5080108642578, Test Loss: 37.82301330566406, Accuracy: 0.7797\n",
      "Epoch 38, Train Loss: 133.8759002685547, Test Loss: 34.86833190917969, Accuracy: 0.7803\n",
      "Epoch 39, Train Loss: 127.68267059326172, Test Loss: 30.61686134338379, Accuracy: 0.7831\n",
      "Epoch 40, Train Loss: 122.61689758300781, Test Loss: 26.079864501953125, Accuracy: 0.7865\n",
      "Epoch 41, Train Loss: 117.49934387207031, Test Loss: 24.48358917236328, Accuracy: 0.7870\n",
      "Epoch 42, Train Loss: 112.00199890136719, Test Loss: 20.71028709411621, Accuracy: 0.7899\n",
      "Epoch 43, Train Loss: 105.45220184326172, Test Loss: 16.345394134521484, Accuracy: 0.7921\n",
      "Epoch 44, Train Loss: 99.77237701416016, Test Loss: 13.669635772705078, Accuracy: 0.7965\n",
      "Epoch 45, Train Loss: 96.13294982910156, Test Loss: 13.893707275390625, Accuracy: 0.7964\n",
      "Epoch 46, Train Loss: 90.19451141357422, Test Loss: 14.746981620788574, Accuracy: 0.7941\n",
      "Epoch 47, Train Loss: 87.74046325683594, Test Loss: 15.110794067382812, Accuracy: 0.7931\n",
      "Epoch 48, Train Loss: 82.68339538574219, Test Loss: 14.920330047607422, Accuracy: 0.7921\n",
      "Epoch 49, Train Loss: 77.8055648803711, Test Loss: 14.657485008239746, Accuracy: 0.7909\n",
      "Epoch 50, Train Loss: 74.01548767089844, Test Loss: 14.804388046264648, Accuracy: 0.7902\n",
      "Epoch 51, Train Loss: 71.86595916748047, Test Loss: 14.982767105102539, Accuracy: 0.7899\n",
      "Epoch 52, Train Loss: 65.63692474365234, Test Loss: 13.788329124450684, Accuracy: 0.7889\n",
      "Epoch 53, Train Loss: 61.43924331665039, Test Loss: 12.493650436401367, Accuracy: 0.7881\n",
      "Epoch 54, Train Loss: 59.02411651611328, Test Loss: 10.579693794250488, Accuracy: 0.7873\n",
      "Epoch 55, Train Loss: 54.8568000793457, Test Loss: 8.539695739746094, Accuracy: 0.7873\n",
      "Epoch 56, Train Loss: 52.31568145751953, Test Loss: 6.565364837646484, Accuracy: 0.7898\n",
      "Epoch 57, Train Loss: 47.45650863647461, Test Loss: 4.786752700805664, Accuracy: 0.7912\n",
      "Epoch 58, Train Loss: 44.00677490234375, Test Loss: 3.1211752891540527, Accuracy: 0.7941\n",
      "Epoch 59, Train Loss: 42.8466911315918, Test Loss: 1.9597676992416382, Accuracy: 0.7943\n",
      "Epoch 60, Train Loss: 38.82551956176758, Test Loss: 1.494240403175354, Accuracy: 0.7922\n",
      "Epoch 61, Train Loss: 36.40744400024414, Test Loss: 1.1315737962722778, Accuracy: 0.7899\n",
      "Epoch 62, Train Loss: 34.734153747558594, Test Loss: 0.8663473129272461, Accuracy: 0.7883\n",
      "Epoch 63, Train Loss: 31.322885513305664, Test Loss: 0.6651711463928223, Accuracy: 0.7860\n",
      "Epoch 64, Train Loss: 29.781137466430664, Test Loss: 0.5548413395881653, Accuracy: 0.7833\n",
      "Epoch 65, Train Loss: 26.73761558532715, Test Loss: 0.552232027053833, Accuracy: 0.7808\n",
      "Epoch 66, Train Loss: 24.878734588623047, Test Loss: 0.6426113247871399, Accuracy: 0.7797\n",
      "Epoch 67, Train Loss: 23.06590461730957, Test Loss: 0.6713484525680542, Accuracy: 0.7790\n",
      "Epoch 68, Train Loss: 21.069116592407227, Test Loss: 0.6704139113426208, Accuracy: 0.7788\n",
      "Epoch 69, Train Loss: 19.53818130493164, Test Loss: 0.6697190403938293, Accuracy: 0.7782\n",
      "Epoch 70, Train Loss: 18.595661163330078, Test Loss: 0.6693108677864075, Accuracy: 0.7773\n",
      "Epoch 71, Train Loss: 17.164087295532227, Test Loss: 0.6687524318695068, Accuracy: 0.7763\n",
      "Epoch 72, Train Loss: 16.367542266845703, Test Loss: 0.6681538820266724, Accuracy: 0.7751\n",
      "Epoch 73, Train Loss: 15.544944763183594, Test Loss: 0.6672168970108032, Accuracy: 0.7747\n",
      "Epoch 74, Train Loss: 14.444271087646484, Test Loss: 0.6661733984947205, Accuracy: 0.7744\n",
      "Epoch 75, Train Loss: 13.33041000366211, Test Loss: 0.6651566624641418, Accuracy: 0.7739\n",
      "Epoch 76, Train Loss: 12.147727966308594, Test Loss: 0.6641237139701843, Accuracy: 0.7739\n",
      "Epoch 77, Train Loss: 11.311408042907715, Test Loss: 0.6632214188575745, Accuracy: 0.7735\n",
      "Epoch 78, Train Loss: 10.444182395935059, Test Loss: 0.6623362898826599, Accuracy: 0.7734\n",
      "Epoch 79, Train Loss: 9.83227825164795, Test Loss: 0.6615048050880432, Accuracy: 0.7732\n",
      "Epoch 80, Train Loss: 9.02400016784668, Test Loss: 0.6606056690216064, Accuracy: 0.7731\n",
      "Epoch 81, Train Loss: 8.57265853881836, Test Loss: 0.6597496271133423, Accuracy: 0.7729\n",
      "Epoch 82, Train Loss: 8.22364330291748, Test Loss: 0.6589163541793823, Accuracy: 0.7728\n",
      "Epoch 83, Train Loss: 8.006418228149414, Test Loss: 0.6581113338470459, Accuracy: 0.7725\n",
      "Epoch 84, Train Loss: 7.727933883666992, Test Loss: 0.6573742628097534, Accuracy: 0.7725\n",
      "Epoch 85, Train Loss: 7.274463653564453, Test Loss: 0.656575083732605, Accuracy: 0.7724\n",
      "Epoch 86, Train Loss: 6.432723522186279, Test Loss: 0.6557985544204712, Accuracy: 0.7723\n",
      "Epoch 87, Train Loss: 6.837438106536865, Test Loss: 0.6549775004386902, Accuracy: 0.7723\n",
      "Epoch 88, Train Loss: 6.588156223297119, Test Loss: 0.654228925704956, Accuracy: 0.7722\n",
      "Epoch 89, Train Loss: 5.9538140296936035, Test Loss: 0.6534050107002258, Accuracy: 0.7721\n",
      "Epoch 90, Train Loss: 5.176304340362549, Test Loss: 0.6527122259140015, Accuracy: 0.7720\n",
      "Epoch 91, Train Loss: 5.81967830657959, Test Loss: 0.651911735534668, Accuracy: 0.7720\n",
      "Epoch 92, Train Loss: 5.445436000823975, Test Loss: 0.6512086987495422, Accuracy: 0.7721\n",
      "Epoch 93, Train Loss: 5.245762825012207, Test Loss: 0.6503903269767761, Accuracy: 0.7720\n",
      "Epoch 94, Train Loss: 4.837319850921631, Test Loss: 0.6497712731361389, Accuracy: 0.7720\n",
      "Epoch 95, Train Loss: 4.789811611175537, Test Loss: 0.648994505405426, Accuracy: 0.7720\n",
      "Epoch 96, Train Loss: 4.624200344085693, Test Loss: 0.6484161019325256, Accuracy: 0.7719\n",
      "Epoch 97, Train Loss: 4.462233543395996, Test Loss: 0.6476938724517822, Accuracy: 0.7717\n",
      "Epoch 98, Train Loss: 4.43375301361084, Test Loss: 0.6469974517822266, Accuracy: 0.7717\n",
      "Epoch 99, Train Loss: 4.578197956085205, Test Loss: 0.6462386846542358, Accuracy: 0.7717\n",
      "Epoch 100, Train Loss: 4.000638484954834, Test Loss: 0.6456232070922852, Accuracy: 0.7717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101, Train Loss: 4.1130051612854, Test Loss: 0.6448564529418945, Accuracy: 0.7716\n",
      "Epoch 102, Train Loss: 4.027729511260986, Test Loss: 0.6442629098892212, Accuracy: 0.7716\n",
      "Epoch 103, Train Loss: 3.9121716022491455, Test Loss: 0.6435182094573975, Accuracy: 0.7716\n",
      "Epoch 104, Train Loss: 3.5618269443511963, Test Loss: 0.6429321765899658, Accuracy: 0.7716\n",
      "Epoch 105, Train Loss: 3.507821559906006, Test Loss: 0.6422054767608643, Accuracy: 0.7716\n",
      "Epoch 106, Train Loss: 3.6311116218566895, Test Loss: 0.6416236758232117, Accuracy: 0.7716\n",
      "Epoch 107, Train Loss: 3.442039966583252, Test Loss: 0.640879213809967, Accuracy: 0.7716\n",
      "Epoch 108, Train Loss: 3.519256830215454, Test Loss: 0.640343427658081, Accuracy: 0.7716\n",
      "Epoch 109, Train Loss: 3.150158643722534, Test Loss: 0.6396867632865906, Accuracy: 0.7716\n",
      "Epoch 110, Train Loss: 3.1511237621307373, Test Loss: 0.63905268907547, Accuracy: 0.7716\n",
      "Epoch 111, Train Loss: 3.2918622493743896, Test Loss: 0.6383917927742004, Accuracy: 0.7716\n",
      "Epoch 112, Train Loss: 3.295980215072632, Test Loss: 0.6378175020217896, Accuracy: 0.7716\n",
      "Epoch 113, Train Loss: 3.4020984172821045, Test Loss: 0.6370905637741089, Accuracy: 0.7716\n",
      "Epoch 114, Train Loss: 3.1492233276367188, Test Loss: 0.636600911617279, Accuracy: 0.7716\n",
      "Epoch 115, Train Loss: 2.8877220153808594, Test Loss: 0.6360315084457397, Accuracy: 0.7716\n",
      "Epoch 116, Train Loss: 2.7159194946289062, Test Loss: 0.6353722810745239, Accuracy: 0.7716\n",
      "Epoch 117, Train Loss: 2.6907482147216797, Test Loss: 0.6348936557769775, Accuracy: 0.7715\n",
      "Epoch 118, Train Loss: 2.6847434043884277, Test Loss: 0.6343167424201965, Accuracy: 0.7715\n",
      "Epoch 119, Train Loss: 2.8795628547668457, Test Loss: 0.6336830854415894, Accuracy: 0.7715\n",
      "Epoch 120, Train Loss: 2.848353862762451, Test Loss: 0.6332036256790161, Accuracy: 0.7715\n",
      "Epoch 121, Train Loss: 2.5845651626586914, Test Loss: 0.6326125264167786, Accuracy: 0.7715\n",
      "Epoch 122, Train Loss: 2.683708429336548, Test Loss: 0.6320583820343018, Accuracy: 0.7715\n",
      "Epoch 123, Train Loss: 2.598541021347046, Test Loss: 0.631500244140625, Accuracy: 0.7715\n",
      "Epoch 124, Train Loss: 2.42480206489563, Test Loss: 0.6309319138526917, Accuracy: 0.7715\n",
      "Epoch 125, Train Loss: 2.422301769256592, Test Loss: 0.630381166934967, Accuracy: 0.7715\n",
      "Epoch 126, Train Loss: 2.6015045642852783, Test Loss: 0.6298346519470215, Accuracy: 0.7715\n",
      "Epoch 127, Train Loss: 2.2781825065612793, Test Loss: 0.6292843222618103, Accuracy: 0.7713\n",
      "Epoch 128, Train Loss: 2.3116939067840576, Test Loss: 0.6287583112716675, Accuracy: 0.7713\n",
      "Epoch 129, Train Loss: 2.4340038299560547, Test Loss: 0.6281755566596985, Accuracy: 0.7713\n",
      "Epoch 130, Train Loss: 2.438676357269287, Test Loss: 0.6277223825454712, Accuracy: 0.7713\n",
      "Epoch 131, Train Loss: 2.1110715866088867, Test Loss: 0.6271983981132507, Accuracy: 0.7713\n",
      "Epoch 132, Train Loss: 2.1559247970581055, Test Loss: 0.626655638217926, Accuracy: 0.7713\n",
      "Epoch 133, Train Loss: 2.0208740234375, Test Loss: 0.6261782050132751, Accuracy: 0.7713\n",
      "Epoch 134, Train Loss: 2.3366401195526123, Test Loss: 0.6255648136138916, Accuracy: 0.7713\n",
      "Epoch 135, Train Loss: 2.378060817718506, Test Loss: 0.6251734495162964, Accuracy: 0.7713\n",
      "Epoch 136, Train Loss: 2.1411590576171875, Test Loss: 0.624726414680481, Accuracy: 0.7713\n",
      "Epoch 137, Train Loss: 1.9897524118423462, Test Loss: 0.6241756081581116, Accuracy: 0.7712\n",
      "Epoch 138, Train Loss: 2.2723188400268555, Test Loss: 0.6237663626670837, Accuracy: 0.7711\n",
      "Epoch 139, Train Loss: 1.9451241493225098, Test Loss: 0.6232914328575134, Accuracy: 0.7711\n",
      "Epoch 140, Train Loss: 1.9571893215179443, Test Loss: 0.6227356195449829, Accuracy: 0.7711\n",
      "Epoch 141, Train Loss: 2.229848861694336, Test Loss: 0.622346043586731, Accuracy: 0.7711\n",
      "Epoch 142, Train Loss: 2.1164488792419434, Test Loss: 0.6219091415405273, Accuracy: 0.7711\n",
      "Epoch 143, Train Loss: 1.9325469732284546, Test Loss: 0.6213622689247131, Accuracy: 0.7711\n",
      "Epoch 144, Train Loss: 1.990912675857544, Test Loss: 0.6209724545478821, Accuracy: 0.7711\n",
      "Epoch 145, Train Loss: 1.8630224466323853, Test Loss: 0.6205461621284485, Accuracy: 0.7711\n",
      "Epoch 146, Train Loss: 1.8706389665603638, Test Loss: 0.6200003027915955, Accuracy: 0.7711\n",
      "Epoch 147, Train Loss: 1.976766586303711, Test Loss: 0.6196128129959106, Accuracy: 0.7711\n",
      "Epoch 148, Train Loss: 1.9019196033477783, Test Loss: 0.6191735863685608, Accuracy: 0.7711\n",
      "Epoch 149, Train Loss: 2.291531801223755, Test Loss: 0.6186716556549072, Accuracy: 0.7711\n",
      "Epoch 150, Train Loss: 2.1601014137268066, Test Loss: 0.6182848811149597, Accuracy: 0.7711\n",
      "Epoch 151, Train Loss: 1.8393597602844238, Test Loss: 0.617838978767395, Accuracy: 0.7711\n",
      "Epoch 152, Train Loss: 1.8721115589141846, Test Loss: 0.6173793077468872, Accuracy: 0.7710\n",
      "Epoch 153, Train Loss: 1.8911734819412231, Test Loss: 0.6169646978378296, Accuracy: 0.7710\n",
      "Epoch 154, Train Loss: 1.7662336826324463, Test Loss: 0.6164464354515076, Accuracy: 0.7710\n",
      "Epoch 155, Train Loss: 1.7858775854110718, Test Loss: 0.6160916686058044, Accuracy: 0.7710\n",
      "Epoch 156, Train Loss: 1.6561001539230347, Test Loss: 0.6156665682792664, Accuracy: 0.7710\n",
      "Epoch 157, Train Loss: 1.730453610420227, Test Loss: 0.6152043342590332, Accuracy: 0.7709\n",
      "Epoch 158, Train Loss: 1.6023986339569092, Test Loss: 0.6148157715797424, Accuracy: 0.7709\n",
      "Epoch 159, Train Loss: 1.6922719478607178, Test Loss: 0.6143625974655151, Accuracy: 0.7709\n",
      "Epoch 160, Train Loss: 1.8421320915222168, Test Loss: 0.6139624118804932, Accuracy: 0.7709\n",
      "Epoch 161, Train Loss: 1.626596212387085, Test Loss: 0.6134824752807617, Accuracy: 0.7709\n",
      "Epoch 162, Train Loss: 1.8263336420059204, Test Loss: 0.6131287813186646, Accuracy: 0.7708\n",
      "Epoch 163, Train Loss: 1.4952287673950195, Test Loss: 0.6126888990402222, Accuracy: 0.7708\n",
      "Epoch 164, Train Loss: 1.677656650543213, Test Loss: 0.6122870445251465, Accuracy: 0.7708\n",
      "Epoch 165, Train Loss: 1.557051420211792, Test Loss: 0.6118574738502502, Accuracy: 0.7708\n",
      "Epoch 166, Train Loss: 1.523647427558899, Test Loss: 0.6114524006843567, Accuracy: 0.7708\n",
      "Epoch 167, Train Loss: 1.7025856971740723, Test Loss: 0.6110140681266785, Accuracy: 0.7708\n",
      "Epoch 168, Train Loss: 1.6122270822525024, Test Loss: 0.6106430292129517, Accuracy: 0.7708\n",
      "Epoch 169, Train Loss: 1.4445770978927612, Test Loss: 0.6102023720741272, Accuracy: 0.7708\n",
      "Epoch 170, Train Loss: 1.683201789855957, Test Loss: 0.6098442673683167, Accuracy: 0.7708\n",
      "Epoch 171, Train Loss: 1.5716872215270996, Test Loss: 0.609458327293396, Accuracy: 0.7708\n",
      "Epoch 172, Train Loss: 1.5993026494979858, Test Loss: 0.6090313196182251, Accuracy: 0.7708\n",
      "Epoch 173, Train Loss: 1.6667823791503906, Test Loss: 0.6086837649345398, Accuracy: 0.7708\n",
      "Epoch 174, Train Loss: 1.4640817642211914, Test Loss: 0.6082518100738525, Accuracy: 0.7708\n",
      "Epoch 175, Train Loss: 1.6037219762802124, Test Loss: 0.6079258322715759, Accuracy: 0.7708\n",
      "Epoch 176, Train Loss: 1.4035277366638184, Test Loss: 0.6075342893600464, Accuracy: 0.7708\n",
      "Epoch 177, Train Loss: 1.3924856185913086, Test Loss: 0.6071690320968628, Accuracy: 0.7708\n",
      "Epoch 178, Train Loss: 1.3981159925460815, Test Loss: 0.6068001389503479, Accuracy: 0.7708\n",
      "Epoch 179, Train Loss: 1.307463526725769, Test Loss: 0.6063929796218872, Accuracy: 0.7708\n",
      "Epoch 180, Train Loss: 1.41421377658844, Test Loss: 0.6060748100280762, Accuracy: 0.7708\n",
      "Epoch 181, Train Loss: 1.4762518405914307, Test Loss: 0.6056568622589111, Accuracy: 0.7707\n",
      "Epoch 182, Train Loss: 1.3021126985549927, Test Loss: 0.6053630113601685, Accuracy: 0.7707\n",
      "Epoch 183, Train Loss: 1.3609776496887207, Test Loss: 0.6049898862838745, Accuracy: 0.7707\n",
      "Epoch 184, Train Loss: 1.37716805934906, Test Loss: 0.604651153087616, Accuracy: 0.7706\n",
      "Epoch 185, Train Loss: 1.4804251194000244, Test Loss: 0.6042513251304626, Accuracy: 0.7706\n",
      "Epoch 186, Train Loss: 1.4344185590744019, Test Loss: 0.6039459705352783, Accuracy: 0.7706\n",
      "Epoch 187, Train Loss: 1.395908236503601, Test Loss: 0.6036247611045837, Accuracy: 0.7706\n",
      "Epoch 188, Train Loss: 1.2949142456054688, Test Loss: 0.6032226085662842, Accuracy: 0.7706\n",
      "Epoch 189, Train Loss: 1.3475425243377686, Test Loss: 0.6029466986656189, Accuracy: 0.7706\n",
      "Epoch 190, Train Loss: 1.342394471168518, Test Loss: 0.6026208996772766, Accuracy: 0.7706\n",
      "Epoch 191, Train Loss: 1.3378500938415527, Test Loss: 0.6022717952728271, Accuracy: 0.7706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192, Train Loss: 1.360485315322876, Test Loss: 0.6019695401191711, Accuracy: 0.7706\n",
      "Epoch 193, Train Loss: 1.3770638704299927, Test Loss: 0.6016109585762024, Accuracy: 0.7706\n",
      "Epoch 194, Train Loss: 1.4377329349517822, Test Loss: 0.6013264060020447, Accuracy: 0.7706\n",
      "Epoch 195, Train Loss: 1.2669659852981567, Test Loss: 0.6010135412216187, Accuracy: 0.7706\n",
      "Epoch 196, Train Loss: 1.2972047328948975, Test Loss: 0.6006584167480469, Accuracy: 0.7705\n",
      "Epoch 197, Train Loss: 1.4086403846740723, Test Loss: 0.6003648042678833, Accuracy: 0.7704\n",
      "Epoch 198, Train Loss: 1.3189783096313477, Test Loss: 0.6000396609306335, Accuracy: 0.7704\n",
      "Epoch 199, Train Loss: 1.2999564409255981, Test Loss: 0.5997444987297058, Accuracy: 0.7704\n",
      "Epoch 200, Train Loss: 1.3630156517028809, Test Loss: 0.5994051694869995, Accuracy: 0.7704\n",
      "Optimizer: Nadam\n",
      "Final Test Accuracy: 0.7704\n",
      "Training Time: 9.87 seconds\n",
      "Final Train Loss: 1.3630\n",
      "Final Test Loss: 0.5994\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Definizione del modello\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)  # Primo strato\n",
    "        self.dropout1 = nn.Dropout(0.2)        # Dropout\n",
    "        self.fc2 = nn.Linear(64, 32)           # Secondo strato\n",
    "        self.dropout2 = nn.Dropout(0.2)        # Secondo Dropout\n",
    "        self.fc3 = nn.Linear(32, 2)            # Strato di output (2 classi)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))            # Funzione di attivazione ReLU\n",
    "        x = self.dropout1(x)                    # Dropout\n",
    "        x = torch.relu(self.fc2(x))            # Funzione di attivazione ReLU\n",
    "        x = self.dropout2(x)                    # Secondo Dropout\n",
    "        x = self.fc3(x)                         # Output senza softmax\n",
    "        return x\n",
    "\n",
    "# Funzione per addestrare il modello\n",
    "def train_model(optimizer, criterion, model, X_train, y_train, X_test, y_test, num_epochs=200):\n",
    "    final_train_loss = None\n",
    "    final_test_loss = None\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Imposta il modello in modalità di addestramento\n",
    "        optimizer.zero_grad()  # Azzerare i gradienti\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "\n",
    "        # Backward pass e ottimizzazione\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Valutazione sul set di test\n",
    "        model.eval()  # Imposta il modello in modalità di valutazione\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test)\n",
    "            test_loss = criterion(test_outputs, y_test)\n",
    "            \n",
    "            # Calcolo dell'accuratezza\n",
    "            _, predicted = torch.max(test_outputs, 1)\n",
    "            accuracy = (predicted == y_test).sum().item() / y_test.size(0)\n",
    "\n",
    "        final_train_loss = loss.item()\n",
    "        final_test_loss = test_loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch + 1}, Train Loss: {loss.item()}, Test Loss: {test_loss.item()}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    return accuracy, final_train_loss, final_test_loss\n",
    "\n",
    "# Caricamento dei dati\n",
    "path1 = 'dataset/train_data.csv'\n",
    "train_data = pd.read_csv(path1)\n",
    "\n",
    "path2 = 'dataset/test_data.csv'\n",
    "test_data = pd.read_csv(path2)\n",
    "\n",
    "# Supponiamo che i dati siano già pre-processati\n",
    "X_train = torch.tensor(train_data.drop(columns='income').values, dtype=torch.float32)\n",
    "y_train = torch.tensor(train_data['income'].values, dtype=torch.long)\n",
    "X_test = torch.tensor(test_data.drop(columns='income').values, dtype=torch.float32)\n",
    "y_test = torch.tensor(test_data['income'].values, dtype=torch.long)\n",
    "\n",
    "# Elenco degli ottimizzatori da provare\n",
    "optimizers = {\n",
    "    \"SGD\": optim.SGD,\n",
    "    \"SGD + Momentum\": lambda params: optim.SGD(params, lr=0.01, momentum=0.9),\n",
    "    \"Adam\": optim.Adam,\n",
    "    \"Adagrad\": optim.Adagrad,\n",
    "    \"Adamax\": optim.Adamax,\n",
    "    \"RMSprop\": optim.RMSprop,\n",
    "    \"Adadelta\": optim.Adadelta,\n",
    "    \"Nadam\": optim.NAdam\n",
    "}\n",
    "\n",
    "# Iterare sugli ottimizzatori\n",
    "for name in optimizers.keys():\n",
    "    print(f\"\\nTraining with optimizer: {name}\")\n",
    "    \n",
    "    # Inizializza un nuovo modello per ogni ottimizzatore\n",
    "    model = SimpleNN(input_size=X_train.shape[1])  # Inizializza un nuovo modello\n",
    "    criterion = nn.CrossEntropyLoss()  # Funzione di perdita\n",
    "\n",
    "    # Inizializza l'ottimizzatore con i parametri del modello\n",
    "    if name == \"SGD + Momentum\":\n",
    "        optimizer_instance = optimizers[name](model.parameters())  # Usa la lambda\n",
    "    else:\n",
    "        optimizer_instance = optimizers[name](model.parameters(), lr=0.001)\n",
    "\n",
    "    # Misura il tempo di addestramento\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Addestra il modello e ottieni i risultati finali\n",
    "    final_accuracy, final_train_loss, final_test_loss = train_model(\n",
    "        optimizer_instance, criterion, model, X_train, y_train, X_test, y_test, num_epochs=200\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    # Stampa i risultati finali\n",
    "    print(f'Optimizer: {name}')\n",
    "    print(f'Final Test Accuracy: {final_accuracy:.4f}')\n",
    "    print(f'Training Time: {training_time:.2f} seconds')\n",
    "    print(f'Final Train Loss: {final_train_loss:.4f}')\n",
    "    print(f'Final Test Loss: {final_test_loss:.4f}')\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
